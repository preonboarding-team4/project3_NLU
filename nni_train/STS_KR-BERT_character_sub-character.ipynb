{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f5eae3b4",
   "metadata": {},
   "source": [
    "사용한 모델: KR-BERT_character_sub-character  \n",
    "모델 repo: https://github.com/snunlp/KR-BERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ecf5268f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader, RandomSampler\n",
    "from torch.nn.utils import clip_grad_norm_\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.optim import AdamW\n",
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "from pathlib import Path\n",
    "from typing import Union\n",
    "from transformers import BertModel, BertForPreTraining, BertTokenizer, BertPreTrainedModel, BertConfig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c5063f03",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "사용한 라이브러리 버전\n",
      "----------------------\n",
      "pytorch: 1.10.2\n",
      "transformers: 4.16.2\n",
      "scikit-learn: 1.0.2\n",
      "numpy: 1.21.5\n",
      "pandas: 1.4.1\n",
      "----------------------\n"
     ]
    }
   ],
   "source": [
    "import sklearn\n",
    "import transformers\n",
    "print(\"사용한 라이브러리 버전\")\n",
    "print(\"-\"*22)\n",
    "print(\"pytorch:\", torch.__version__)\n",
    "print(\"transformers:\", transformers.__version__)\n",
    "print(\"scikit-learn:\", sklearn.__version__)\n",
    "print(\"numpy:\", np.__version__)\n",
    "print(\"pandas:\", pd.__version__)\n",
    "print(\"-\"*22)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ac66ea9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Config:\n",
    "    \"\"\"Config class\"\"\"\n",
    "\n",
    "    def __init__(self, json_path_or_dict: Union[str, dict]) -> None:\n",
    "        \"\"\"Instantiating Config class\n",
    "        Args:\n",
    "            json_path_or_dict (Union[str, dict]): filepath of config or dictionary which has attributes\n",
    "        \"\"\"\n",
    "        if isinstance(json_path_or_dict, dict):\n",
    "            self.__dict__.update(json_path_or_dict)\n",
    "        else:\n",
    "            with open(json_path_or_dict, mode=\"r\") as io:\n",
    "                params = json.loads(io.read())\n",
    "            self.__dict__.update(params)\n",
    "\n",
    "    def save(self, json_path: Union[str, Path]) -> None:\n",
    "        \"\"\"Saving config to json_path\n",
    "        Args:\n",
    "            json_path (Union[str, Path]): filepath of config\n",
    "        \"\"\"\n",
    "        with open(json_path, mode=\"w\") as io:\n",
    "            json.dump(self.__dict__, io, indent=4)\n",
    "\n",
    "    def update(self, json_path_or_dict) -> None:\n",
    "        \"\"\"Updating Config instance\n",
    "        Args:\n",
    "            json_path_or_dict (Union[str, dict]): filepath of config or dictionary which has attributes\n",
    "        \"\"\"\n",
    "        if isinstance(json_path_or_dict, dict):\n",
    "            self.__dict__.update(json_path_or_dict)\n",
    "        else:\n",
    "            with open(json_path_or_dict, mode=\"r\") as io:\n",
    "                params = json.loads(io.read())\n",
    "            self.__dict__.update(params)\n",
    "\n",
    "    @property\n",
    "    def dict(self) -> dict:\n",
    "        return self.__dict__\n",
    "    \n",
    "def data_qc(paragrahp:str):\n",
    "    paragrahp = re.sub(r\"(\\(.*?\\))\", \"\", paragrahp)\n",
    "    paragrahp = re.sub(\"((http|https)\\:\\/\\/)?[a-zA-Z0-9\\.\\/\\?\\:@\\-_=#]+\\.([a-zA-Z]){2,6}([a-zA-Z0-9\\.\\&\\/\\?\\:@\\-_=#])*\", \"\", paragrahp)\n",
    "    paragrahp = re.sub(\"'^[a-zA-Z0-9+-_.]+@[a-zA-Z0-9-]+\\.[a-zA-Z0-9-.]+$'\", \"\", paragrahp)\n",
    "    return paragrahp"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5a857b5",
   "metadata": {},
   "source": [
    "### read data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4790eab0",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"./klue-sts-data/klue-sts-v1.1_train.json\", \"rt\", encoding='utf8') as f:\n",
    "    data = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6376fe57",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'guid': 'klue-sts-v1_train_00000',\n",
       " 'source': 'airbnb-rtt',\n",
       " 'sentence1': '숙소 위치는 찾기 쉽고 일반적인 한국의 반지하 숙소입니다.',\n",
       " 'sentence2': '숙박시설의 위치는 쉽게 찾을 수 있고 한국의 대표적인 반지하 숙박시설입니다.',\n",
       " 'labels': {'label': 3.7, 'real-label': 3.714285714285714, 'binary-label': 1},\n",
       " 'annotations': {'agreement': '0:0:0:2:5:0',\n",
       "  'annotators': ['07', '13', '15', '10', '12', '02', '19'],\n",
       "  'annotations': [3, 4, 4, 4, 3, 4, 4]}}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "426ab701",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "150 {'guid': 'klue-sts-v1_train_00150', 'source': 'policy-rtt', 'sentence1': '먼저 데이터·인공지능(AI)분야에서는\\xa0데이터 활용을 높이기 위해 건강 등 민감한 정보에 대한 가이드라인을 8월까지 마련한다.', 'sentence2': '우선 데이터 및 인공지능(AI) 분야에서는 데이터 활용도를 높이기 위해 8월까지 건강 등 중요 정보에 대한 가이드라인을 마련하기로 했습니다.', 'labels': {'label': 3.7, 'real-label': 3.666666666666667, 'binary-label': 1}, 'annotations': {'agreement': '0:0:1:1:3:1', 'annotators': ['17', '03', '12', '15', '05', '09'], 'annotations': [4, 2, 5, 3, 4, 4]}}\n",
      "159 {'guid': 'klue-sts-v1_train_00159', 'source': 'policy-sampled', 'sentence1': '65세 이상 독거 노인 죽음, 전체\\xa0고독사의 43% 달해', 'sentence2': '여성(51.6%)과 노후준비가 빈약한 고령층(65세 이상, 32.9%)의 고용률 역시 역대 최고치를 기록했습니다.', 'labels': {'label': 0.3, 'real-label': 0.3333333333333333, 'binary-label': 0}, 'annotations': {'agreement': '4:2:0:0:0:0', 'annotators': ['14', '10', '02', '06', '19', '13'], 'annotations': [0, 0, 0, 0, 1, 1]}}\n",
      "276 {'guid': 'klue-sts-v1_train_00276', 'source': 'policy-sampled', 'sentence1': '이러한 정책 여건을 반영, 방통위는\\xa0‘활력있는 방송통신, 신뢰받는 미디어’를 비전으로 설정하고 3개 목표와 9개 과제를 올 한해 중점 추진한다.', 'sentence2': '‘글로벌 벤처캐피탈 펀드’를 2000억 원 규모로 조성하고 온라인 해외 기업설명회와 해외진출사절단 파견 등을 확대한다.', 'labels': {'label': 0.0, 'real-label': 0.0, 'binary-label': 0}, 'annotations': {'agreement': '7:0:0:0:0:0', 'annotators': ['14', '03', '07', '15', '05', '02', '18'], 'annotations': [0, 0, 0, 0, 0, 0, 0]}}\n",
      "507 {'guid': 'klue-sts-v1_train_00507', 'source': 'policy-sampled', 'sentence1': '각국 정상들의\\xa0통화요청도 쇄도 중이다.', 'sentence2': '국민참여 특별 캠페인도 성황리에 진행중이다.', 'labels': {'label': 0.2, 'real-label': 0.1666666666666667, 'binary-label': 0}, 'annotations': {'agreement': '5:1:0:0:0:0', 'annotators': ['17', '09', '16', '12', '06', '08'], 'annotations': [0, 0, 0, 1, 0, 0]}}\n",
      "637 {'guid': 'klue-sts-v1_train_00637', 'source': 'policy-sampled', 'sentence1': '사육시설의 규모가 1000㎡\\xa0이하이고 방역실 내부에 별도의 물품반입 장소를 갖춘 경우에는 설치 예외 대상이 된다.', 'sentence2': '장병들의 사기가 충만한 군대가 강한 군대이고, 아들딸을 군에 보낸 부모가 안심하는 군대가 강한 군대입니다.', 'labels': {'label': 0.0, 'real-label': 0.0, 'binary-label': 0}, 'annotations': {'agreement': '5:0:0:0:0:0', 'annotators': ['03', '16', '05', '18', '10'], 'annotations': [0, 0, 0, 0, 0]}}\n",
      "705 {'guid': 'klue-sts-v1_train_00705', 'source': 'policy-rtt', 'sentence1': '이어\\xa0 ‘특정 분야의 투자집중으로 인한 투자 감소’(40.0%), ‘특정 분야에 대한 정부 지원 집중’(38.8%) 등도 우려하는 요인으로 나타났다.', 'sentence2': \"또한 '특정 분야에 대한 투자 집중에 따른 투자 감소'(40.0%)와 '특정 분야에 대한 정부 지원 집중'(38.8%)도 우려 요인이었습니다.\", 'labels': {'label': 4.3, 'real-label': 4.333333333333333, 'binary-label': 1}, 'annotations': {'agreement': '0:0:0:1:2:3', 'annotators': ['17', '12', '14', '10', '08', '06'], 'annotations': [5, 5, 5, 4, 3, 4]}}\n",
      "733 {'guid': 'klue-sts-v1_train_00733', 'source': 'policy-rtt', 'sentence1': '환경부와 중소벤처기업부는 3일 ‘그린뉴딜 유망기업 100’ 출범식에서 이같은 내용을 포함한 ‘그린 스타트업·벤처 육성 방안’을\\xa0발표했다.', 'sentence2': '환경부와 중소벤처기업부는 3일 그린뉴딜100 출범식에서 이 같은 내용을 담은 녹색창업 및 벤처 육성계획을 발표했습니다.', 'labels': {'label': 4.2, 'real-label': 4.166666666666667, 'binary-label': 1}, 'annotations': {'agreement': '0:0:0:1:3:2', 'annotators': ['09', '04', '16', '10', '18', '06'], 'annotations': [5, 4, 5, 4, 3, 4]}}\n",
      "840 {'guid': 'klue-sts-v1_train_00840', 'source': 'policy-rtt', 'sentence1': '앞선 분기 성장률에서는\\xa01분기(-1.3%)·2분기(-3.2%) 연속 마이너스 성장을 했다.', 'sentence2': '1분기(-1.3%)와 2분기(-3.2%)에는 마이너스 성장을 기록했습니다.', 'labels': {'label': 3.7, 'real-label': 3.666666666666667, 'binary-label': 1}, 'annotations': {'agreement': '0:0:0:2:4:0', 'annotators': ['16', '17', '18', '04', '15', '02'], 'annotations': [3, 4, 4, 4, 3, 4]}}\n",
      "845 {'guid': 'klue-sts-v1_train_00845', 'source': 'policy-rtt', 'sentence1': '아울러 각 지자체는 친환경농산물을 원활히 공급받을 수 있도록 생산자단체 또는 광역단위 산지유통조직, 친환경농산물 취급자 등 유통업체 등과\\xa0공급계약을\\xa0체결한다.', 'sentence2': '또한 각 지방자치단체는 생산자단체, 광역유통단체, 친환경농산물 취급자 등 유통업체와 공급계약을 체결하여 친환경농산물을 원활히 공급받을 수 있도록 할 계획입니다.', 'labels': {'label': 4.1, 'real-label': 4.142857142857143, 'binary-label': 1}, 'annotations': {'agreement': '0:0:0:0:6:1', 'annotators': ['07', '10', '19', '02', '04', '08', '13'], 'annotations': [4, 4, 4, 4, 4, 4, 5]}}\n",
      "931 {'guid': 'klue-sts-v1_train_00931', 'source': 'policy-rtt', 'sentence1': '지난해 제정된 어선안전조업법이 올해부터 시행되면서\\xa0어선에 대한 안전관리가 대폭 강화된다.', 'sentence2': '지난해 제정된 어선안전조업법이 시행됨에 따라 어선에 대한 안전관리가 대폭 강화될 예정입니다.', 'labels': {'label': 4.5, 'real-label': 4.5, 'binary-label': 1}, 'annotations': {'agreement': '0:0:0:0:3:3', 'annotators': ['07', '17', '10', '08', '13', '02'], 'annotations': [4, 5, 4, 4, 5, 5]}}\n",
      "1107 {'guid': 'klue-sts-v1_train_01107', 'source': 'policy-rtt', 'sentence1': '과학기술정보통신부는 6일 ICT 규제 샌드박스 지정기업의 올해 3분기 주요 성과를\\xa0발표했다.', 'sentence2': '과학기술정보통신부는 올해 3분기 ICT 규제 샌드박스로 지정된 주요 성과를 6일 발표했습니다.', 'labels': {'label': 4.6, 'real-label': 4.571428571428571, 'binary-label': 1}, 'annotations': {'agreement': '0:0:0:0:3:4', 'annotators': ['07', '09', '12', '10', '04', '06', '19'], 'annotations': [5, 4, 5, 5, 5, 4, 4]}}\n",
      "1254 {'guid': 'klue-sts-v1_train_01254', 'source': 'policy-sampled', 'sentence1': '하지만 휴원기간 동안 어린이집의 아동 돌봄을 필요로 하는 보호자는 어린이집 긴급보육을 이용할 수 있고, 어린이집 내 방역을 위한 소독\\xa0실시 및 급·간식도 평상시와 같이 제공한다.', 'sentence2': '야간이나 주말 등에 긴급히 돌봄이 필요할 때 이용자가 직접 아이돌보미를 선택하고 연계할 수 있는 ‘일시 연계 서비스’도\\xa03월부터 제공한다.', 'labels': {'label': 1.2, 'real-label': 1.166666666666667, 'binary-label': 0}, 'annotations': {'agreement': '2:1:3:0:0:0', 'annotators': ['07', '02', '05', '19', '08', '13'], 'annotations': [2, 0, 2, 0, 2, 1]}}\n",
      "1355 {'guid': 'klue-sts-v1_train_01355', 'source': 'policy-sampled', 'sentence1': '플랫폼 사업자 등의 배타조건부 거래, 끼워팔기 등 신규 경쟁사업자의 시장 진입을 막는 정보통신기술(ICT) 산업 내 ‘경쟁제한’\\xa0행위도 올해\\xa0중점감시 대상으로 선정됐다.', 'sentence2': '28일 부산, 강릉, 전주, 목포, 안동 등 총 5곳이 방한 도시관광의 선도모델 육성을 위한 ‘관광거점도시’로 선정됐다.', 'labels': {'label': 0.4, 'real-label': 0.4285714285714285, 'binary-label': 0}, 'annotations': {'agreement': '5:1:1:0:0:0', 'annotators': ['05', '17', '03', '15', '12', '10', '18'], 'annotations': [0, 0, 2, 0, 1, 0, 0]}}\n",
      "1358 {'guid': 'klue-sts-v1_train_01358', 'source': 'policy-sampled', 'sentence1': '지난해 혁신도시로 이전한 공공기관의 지역인재 채용률은 25.9%로\\xa0목표를 초과 달성했다.', 'sentence2': '여성과 고령층의 고용률도 각각 51.6%와 32.9%로 역대 최고치를 기록했다.', 'labels': {'label': 0.2, 'real-label': 0.1666666666666667, 'binary-label': 0}, 'annotations': {'agreement': '5:1:0:0:0:0', 'annotators': ['04', '14', '07', '05', '12', '15'], 'annotations': [0, 0, 1, 0, 0, 0]}}\n",
      "1521 {'guid': 'klue-sts-v1_train_01521', 'source': 'policy-sampled', 'sentence1': '또 일반공급에서는 분양가가 6억원 이상인 주택에 생애최초 청약 시\\xa0130%(맞벌이 140%)까지 올려준다.', 'sentence2': '공수처는 판사, 검사, 경무관 이상 경찰관에 대해서는 기소권을 가집니다.', 'labels': {'label': 0.0, 'real-label': 0.0, 'binary-label': 0}, 'annotations': {'agreement': '7:0:0:0:0:0', 'annotators': ['07', '17', '13', '18', '08', '04', '10'], 'annotations': [0, 0, 0, 0, 0, 0, 0]}}\n",
      "1634 {'guid': 'klue-sts-v1_train_01634', 'source': 'policy-sampled', 'sentence1': '최근 대전이 기획하고, 정부가 선정한 ‘마이데이터 기반 교통약자 이동지원 서비스’나 \\xa0‘AI기반 지하철 위험·이상행동 감지 시스템’\\xa0등이\\xa0바로 그 예다.', 'sentence2': '하지만 일본의 경제 보복은 한국 기업의 위기대응 능력을 높이고, 정부 정책 방향을 ‘방어’에서 ‘공세’로 바꾸는\\xa0원동력이 됐다는 평가다.', 'labels': {'label': 0.0, 'real-label': 0.0, 'binary-label': 0}, 'annotations': {'agreement': '6:0:0:0:0:0', 'annotators': ['15', '17', '06', '02', '08', '13'], 'annotations': [0, 0, 0, 0, 0, 0]}}\n",
      "1691 {'guid': 'klue-sts-v1_train_01691', 'source': 'policy-sampled', 'sentence1': '표준단독주택은 전국 단독주택(다가구주택·다중주택·용도혼합 주택 포함)\\xa0418만채 중에서 선정됐으며 지방자치단체가 나머지 개별단독주택의 가격을 산정할 때 기준으로 쓰인다.', 'sentence2': '올해 전국 22만채의 표준단독주택 공시가격이 작년보다 4.47% 오른 것으로 집계됐다.', 'labels': {'label': 0.7, 'real-label': 0.6666666666666666, 'binary-label': 0}, 'annotations': {'agreement': '2:4:0:0:0:0', 'annotators': ['17', '09', '14', '10', '07', '12'], 'annotations': [1, 1, 0, 1, 1, 0]}}\n",
      "1692 {'guid': 'klue-sts-v1_train_01692', 'source': 'policy-rtt', 'sentence1': '문 대통령은 이날 오후\\xa0경기도 평택에 있는 마스크 생산업체 우일씨앤텍을 방문했다.', 'sentence2': '그 날 오후, 문 대통령은 경기도 평택의 마스크 생산업체인 우일 C&T를 방문했습니다.', 'labels': {'label': 4.3, 'real-label': 4.333333333333333, 'binary-label': 1}, 'annotations': {'agreement': '0:0:0:0:4:2', 'annotators': ['07', '10', '15', '08', '19', '13'], 'annotations': [5, 4, 4, 4, 4, 5]}}\n",
      "1719 {'guid': 'klue-sts-v1_train_01719', 'source': 'policy-sampled', 'sentence1': '특수학교는 장애학생, 교직원의 안전 확보를 필수로 등교\\xa0\\xa0 개학 전까지 긴급돌봄을 지속 운영하겠습니다.', 'sentence2': '정부는 우리 기업에 들이닥친 거대한 위기의 파고를 막는 든든한 방파제 역할을 하겠습니다.', 'labels': {'label': 0.2, 'real-label': 0.2, 'binary-label': 0}, 'annotations': {'agreement': '4:1:0:0:0:0', 'annotators': ['19', '04', '12', '08', '09'], 'annotations': [0, 0, 1, 0, 0]}}\n",
      "1742 {'guid': 'klue-sts-v1_train_01742', 'source': 'policy-rtt', 'sentence1': '1단계 사업이 완료되는\\xa0올해 12월 30MW 규모의 태양광 발전시설에서 연간 약 3만9000MWh의 전력이 생산될 예정이다.', 'sentence2': '약 39,000명 정도요.MWh의 전기는 1단계 프로젝트가 완료되는 올해 12월에 30MW 태양광 발전소에서 매년 생산될 예정입니다.', 'labels': {'label': 4.0, 'real-label': 4.0, 'binary-label': 1}, 'annotations': {'agreement': '0:0:0:1:4:1', 'annotators': ['17', '12', '10', '19', '15', '06'], 'annotations': [5, 4, 4, 4, 3, 4]}}\n",
      "1771 {'guid': 'klue-sts-v1_train_01771', 'source': 'policy-rtt', 'sentence1': '농기계종합보험은 기초수급자 및 차상위계층 등 영세농가의 보험료 부담 완화를 위해 올해부터 국고지원을 70%까지\\xa0확대한다.', 'sentence2': '농기계 종합보험은 기초수급자와 차상위계층 등 영세 농가의 보험료 부담을 덜어주기 위해 올해부터 70%까지 국고 지원을 확대하기로 했습니다.', 'labels': {'label': 4.1, 'real-label': 4.142857142857143, 'binary-label': 1}, 'annotations': {'agreement': '0:0:0:1:4:2', 'annotators': ['03', '18', '17', '04', '15', '05', '09'], 'annotations': [4, 5, 4, 4, 4, 3, 5]}}\n",
      "1931 {'guid': 'klue-sts-v1_train_01931', 'source': 'policy-rtt', 'sentence1': '정부는 19일 이 같은 내용의\\xa0‘서민·중산층 주거안정 지원방안’을 발표했다.', 'sentence2': '19일 정부는 서민과 중산층을 위한 주거안정 지원계획을 발표했습니다.', 'labels': {'label': 4.0, 'real-label': 4.0, 'binary-label': 1}, 'annotations': {'agreement': '0:0:1:0:3:2', 'annotators': ['05', '09', '06', '14', '07', '12'], 'annotations': [4, 2, 4, 5, 4, 5]}}\n",
      "1986 {'guid': 'klue-sts-v1_train_01986', 'source': 'policy-sampled', 'sentence1': '이어 내년 4월부터 전자증명서는 건강보험자격확인서와 건강보험료 납부확인서 등 13종으로 늘어나고 사용처도 중앙부처는 물론 은행과 보험사 등으로도\\xa0확대된다.', 'sentence2': '4대 보험료 납부유예 및 감면조치는 4월에 납부해야 하는 3월 보험료부터 적용된다.', 'labels': {'label': 1.0, 'real-label': 1.0, 'binary-label': 0}, 'annotations': {'agreement': '1:4:1:0:0:0', 'annotators': ['07', '09', '10', '03', '06', '19'], 'annotations': [1, 0, 2, 1, 1, 1]}}\n",
      "2225 {'guid': 'klue-sts-v1_train_02225', 'source': 'policy-sampled', 'sentence1': '지속적인 혈당 관리와 인슐린 투여가 필요한 제1형 당뇨 환자들의 편의가 증대될 것으로 기대되는데, 당뇨병 관리기기 구입 지원은\\xa01월 1일부터 시행된다.', 'sentence2': '예비농업인의 신규 영농창업 또는 농업인의 영농 규모화가 활성화 될 수 있도록, 정책자금 지원조건(거치·상환) 제도를 개선한다.', 'labels': {'label': 0.0, 'real-label': 0.0, 'binary-label': 0}, 'annotations': {'agreement': '5:0:0:0:0:0', 'annotators': ['04', '14', '05', '18', '10'], 'annotations': [0, 0, 0, 0, 0]}}\n",
      "2228 {'guid': 'klue-sts-v1_train_02228', 'source': 'policy-rtt', 'sentence1': '아울러\\xa0유관기관과의 협의를 통해 준수의무 이행점검체계도 구축한다.', 'sentence2': '또한, 관련기관과의 협의를 통해 준수 의무 점검체계를 구축하여야 합니다.', 'labels': {'label': 3.4, 'real-label': 3.428571428571428, 'binary-label': 1}, 'annotations': {'agreement': '0:0:0:4:3:0', 'annotators': ['05', '09', '17', '12', '08', '18', '02'], 'annotations': [4, 4, 4, 3, 3, 3, 3]}}\n",
      "2273 {'guid': 'klue-sts-v1_train_02273', 'source': 'policy-sampled', 'sentence1': '탄소중립은 이제 전세계가 거스를 수 없는\\xa0흐름이\\xa0됨과 동시에 우리 경제의 지속 성장을 위한 필수 과제가 된 것이다.', 'sentence2': '탄소중립은 이미 세계적인 대세가 됐다.', 'labels': {'label': 2.3, 'real-label': 2.333333333333333, 'binary-label': 0}, 'annotations': {'agreement': '0:0:4:2:0:0', 'annotators': ['07', '09', '10', '16', '18', '15'], 'annotations': [2, 3, 3, 2, 2, 2]}}\n",
      "2314 {'guid': 'klue-sts-v1_train_02314', 'source': 'policy-rtt', 'sentence1': '특히 축산물이력제를 연 2회 이상\\xa0위반해 벌금 및 과태료 처분이 확정된 업체는 농식품부 등 주요 인터넷 홈페이지에 업체명과 관련 정보를 공개한다.', 'sentence2': '특히 축산물 이력 제도를 1년에 두 번 이상 위반해 벌금과 벌금을 부과받은 업체는 농림축산식품부 등 주요 인터넷 사이트에 이름과 관련 정보를 공개하게 됩니다.', 'labels': {'label': 4.0, 'real-label': 4.0, 'binary-label': 1}, 'annotations': {'agreement': '0:0:0:1:4:1', 'annotators': ['17', '03', '12', '10', '19', '08'], 'annotations': [5, 3, 4, 4, 4, 4]}}\n",
      "2341 {'guid': 'klue-sts-v1_train_02341', 'source': 'policy-sampled', 'sentence1': '특히, 음주운전 처벌을 강화하는 도로교통법인 ‘윤창호법’이 시행된 6월 이후에 오히려 음주운전 적발이\\xa0늘어난 47개소를 선정해 집중단속을 벌인다.', 'sentence2': '존경하는 메콩 정상 여러분, 내년은 ‘한-메콩 협력 10주년’이며, ‘한-메콩 교류의 해’입니다.', 'labels': {'label': 0.0, 'real-label': 0.0, 'binary-label': 0}, 'annotations': {'agreement': '6:0:0:0:0:0', 'annotators': ['04', '03', '15', '18', '02', '12'], 'annotations': [0, 0, 0, 0, 0, 0]}}\n",
      "2396 {'guid': 'klue-sts-v1_train_02396', 'source': 'policy-rtt', 'sentence1': '오는 21일부터\\xa07월 말까지 진행되는 이번 설명회는 코로나19 확산 방지를 위해 온라인으로 개최된다.', 'sentence2': '코로나 19의 확산을 막기 위해 21일부터 7월 말까지 진행되는 설명회가 온라인으로 열릴 예정입니다.', 'labels': {'label': 3.9, 'real-label': 3.857142857142857, 'binary-label': 1}, 'annotations': {'agreement': '0:0:0:3:2:2', 'annotators': ['17', '10', '15', '09', '14', '12', '05'], 'annotations': [5, 4, 3, 4, 5, 3, 3]}}\n",
      "2424 {'guid': 'klue-sts-v1_train_02424', 'source': 'policy-rtt', 'sentence1': '운영 규모는 코로나19 예방 및 확산 방지를 위해\\xa0회당 20명에서 10명으로 축소한다.', 'sentence2': '코로나 19를 방지하고 확산을 방지하기 위해 운영 규모를 세션당 20개에서 10개로 줄입니다.', 'labels': {'label': 3.4, 'real-label': 3.428571428571428, 'binary-label': 1}, 'annotations': {'agreement': '0:0:0:4:3:0', 'annotators': ['14', '10', '03', '18', '15', '12', '04'], 'annotations': [4, 4, 3, 3, 3, 4, 3]}}\n",
      "2567 {'guid': 'klue-sts-v1_train_02567', 'source': 'policy-sampled', 'sentence1': '아울러\\xa0특별공급 추천자를 결정하는 과정에서 장기 재직한 무주택자 우대를 강화할 필요가 있다는 지적도 있었다.', 'sentence2': '검사와 진단, 치료에 꼭 필요한 체온계와 마스크를 기부한 이들도 있다.', 'labels': {'label': 0.0, 'real-label': 0.0, 'binary-label': 0}, 'annotations': {'agreement': '6:0:0:0:0:0', 'annotators': ['13', '04', '12', '05', '02', '09'], 'annotations': [0, 0, 0, 0, 0, 0]}}\n",
      "2615 {'guid': 'klue-sts-v1_train_02615', 'source': 'policy-rtt', 'sentence1': '문 대통령은\\xa0마스크 생산 현장 점검에도 나섰다.', 'sentence2': '문 대통령은 마스크 생산 현장도 시찰하기 시작했습니다.', 'labels': {'label': 3.5, 'real-label': 3.5, 'binary-label': 1}, 'annotations': {'agreement': '0:0:0:3:3:0', 'annotators': ['16', '10', '03', '05', '15', '18'], 'annotations': [3, 4, 3, 4, 4, 3]}}\n",
      "2834 {'guid': 'klue-sts-v1_train_02834', 'source': 'policy-rtt', 'sentence1': '우리는 또한 국제노동기구(ILO)와\\xa0 경제협력개발기구(OECD)가 세계적 대유행이 고용에 미치는 영향을 조사해줄 것을 요청한다.', 'sentence2': '우리는 또한 국제노동기구(ILO)와 경제협력개발기구(OECD)가 세계적인 유행병이 고용에 미치는 영향에 대해 조사해 줄 것을 요청합니다.', 'labels': {'label': 4.3, 'real-label': 4.333333333333333, 'binary-label': 1}, 'annotations': {'agreement': '0:0:1:0:1:4', 'annotators': ['08', '13', '05', '04', '09', '12'], 'annotations': [2, 5, 5, 4, 5, 5]}}\n",
      "2960 {'guid': 'klue-sts-v1_train_02960', 'source': 'policy-rtt', 'sentence1': '디스플레이는 26개월 만에 첫 증가를 기록한\\xa0반면, 석유제품(22개월 연속 감소)과 석유화학(23개월 연속 감소)은 저유가로 부진을 지속했다.', 'sentence2': '디스플레이가 26개월 만에 처음으로 증가세를 기록한 반면, 석유제품(22개월 연속 감소)과 석유화학(23개월 연속 감소)은 저유가로 계속 어려움을 겪고 있습니다.', 'labels': {'label': 3.8, 'real-label': 3.833333333333333, 'binary-label': 1}, 'annotations': {'agreement': '0:0:0:3:1:2', 'annotators': ['03', '15', '14', '05', '18', '02'], 'annotations': [3, 3, 5, 4, 5, 3]}}\n",
      "3010 {'guid': 'klue-sts-v1_train_03010', 'source': 'policy-sampled', 'sentence1': '한편 중앙사고수습본와 중앙방역대책본부는 5일 오전\\xa09시부터 기존의 웹페이지를 개편한 신종코로나바이러스 마이크로페이지를 오픈했다.', 'sentence2': '중앙사고수습본부(이하 ‘중수본’)는 12일 오전 정례 브리핑에서 이 같이 밝혔다.', 'labels': {'label': 0.8, 'real-label': 0.8333333333333334, 'binary-label': 0}, 'annotations': {'agreement': '1:5:0:0:0:0', 'annotators': ['17', '12', '06', '14', '15', '10'], 'annotations': [1, 1, 1, 0, 1, 1]}}\n",
      "3130 {'guid': 'klue-sts-v1_train_03130', 'source': 'policy-rtt', 'sentence1': '첨부:\\xa0대학 비대면 교육 긴급지원사업 지원 대학 명단', 'sentence2': '첨부 : 비대면교육 긴급지원 사업을 지원하는 대학 목록입니다.', 'labels': {'label': 3.4, 'real-label': 3.428571428571428, 'binary-label': 1}, 'annotations': {'agreement': '0:0:0:4:3:0', 'annotators': ['16', '04', '06', '07', '15', '02', '09'], 'annotations': [3, 4, 4, 4, 3, 3, 3]}}\n",
      "3191 {'guid': 'klue-sts-v1_train_03191', 'source': 'policy-sampled', 'sentence1': '신남방 지역에서는 한류 활용 마케팅과 현지 식문화와 연계해\\xa0수요처를 발굴한다.', 'sentence2': '공익직불제는 기본직불제도와 선택직불제도로 구분해 운영한다.', 'labels': {'label': 0.0, 'real-label': 0.0, 'binary-label': 0}, 'annotations': {'agreement': '7:0:0:0:0:0', 'annotators': ['16', '03', '14', '09', '07', '12', '02'], 'annotations': [0, 0, 0, 0, 0, 0, 0]}}\n",
      "3445 {'guid': 'klue-sts-v1_train_03445', 'source': 'policy-rtt', 'sentence1': '정부가 15일 0시부터 프랑스, 독일, 스페인, 영국, 네덜란드 등 유럽 5개국에서 출발해 국내로 들어오는 여행자를 대상으로\\xa0특별입국절차를 시행한다.', 'sentence2': '정부는 15일 자정부터 프랑스, 독일, 스페인, 영국, 네덜란드 등 유럽 5개국에서 온 여행객들을 위한 특별 입국 절차를 시행할 예정입니다.', 'labels': {'label': 4.2, 'real-label': 4.166666666666667, 'binary-label': 1}, 'annotations': {'agreement': '0:0:0:0:5:1', 'annotators': ['07', '05', '03', '06', '10', '09'], 'annotations': [4, 4, 4, 4, 4, 5]}}\n",
      "3562 {'guid': 'klue-sts-v1_train_03562', 'source': 'policy-rtt', 'sentence1': '개정안에 따라 신혼부부와 생애최초 특별공급에 대한\\xa0소득요건이 완화된다.', 'sentence2': '개정안에 따르면, 신혼부부의 소득 요건과 그들의 생애 첫 특별공급이 완화될 것입니다.', 'labels': {'label': 4.2, 'real-label': 4.2, 'binary-label': 1}, 'annotations': {'agreement': '0:0:0:0:4:1', 'annotators': ['14', '04', '05', '19', '12'], 'annotations': [4, 4, 4, 4, 5]}}\n",
      "3613 {'guid': 'klue-sts-v1_train_03613', 'source': 'policy-sampled', 'sentence1': '올해부터 체납액이 2억원 이상인 고액·상습 체납자는 최대 30일간 유치장 등에 감치할 수 있게\\xa0된다.', 'sentence2': '오는 29일부터 코로나19 피해로 대출 상환이 어려운 개인 채무자는 최대 1년까지 가계대출 원금 상환유예를 받을 수 있게 된다.', 'labels': {'label': 0.1, 'real-label': 0.1428571428571428, 'binary-label': 0}, 'annotations': {'agreement': '6:1:0:0:0:0', 'annotators': ['17', '18', '10', '08', '02', '12', '19'], 'annotations': [0, 0, 0, 0, 0, 1, 0]}}\n",
      "3725 {'guid': 'klue-sts-v1_train_03725', 'source': 'policy-rtt', 'sentence1': '문체부는 10일 포용과 혁신의 지역문화를 꽃피우기 위한 ‘제2차 지역문화진흥기본계획(2020~2024)’을\\xa0발표했다.', 'sentence2': '문화체육관광부는 10일 지역 참여와 혁신의 문화를 꽃피우기 위한 제2차 지역문화진흥기본계획(2020~2024년)을 발표했습니다.', 'labels': {'label': 4.3, 'real-label': 4.333333333333333, 'binary-label': 1}, 'annotations': {'agreement': '0:0:0:0:4:2', 'annotators': ['17', '04', '15', '08', '19', '13'], 'annotations': [5, 4, 4, 4, 4, 5]}}\n",
      "3832 {'guid': 'klue-sts-v1_train_03832', 'source': 'policy-sampled', 'sentence1': '1000개를 초과할 경우\\xa0정식수출신고가 필요하다.', 'sentence2': '이 경우 핀테크 고객들도 오픈뱅킹 계좌 등록시 일일이 계좌를 입력할 필요 없이 일괄 등록이 가능하다.', 'labels': {'label': 0.0, 'real-label': 0.0, 'binary-label': 0}, 'annotations': {'agreement': '7:0:0:0:0:0', 'annotators': ['03', '14', '08', '19', '09', '06', '04'], 'annotations': [0, 0, 0, 0, 0, 0, 0]}}\n",
      "3976 {'guid': 'klue-sts-v1_train_03976', 'source': 'policy-sampled', 'sentence1': '지금까지 소·돼지에 대해서만 실시하던\\xa0축산물이력제가 올해부터 닭·오리·계란까지 확대 시행된다.', 'sentence2': '소·돼지에 대해서만 실시하던 축산물이력제가 1월 1일부터 닭·오리·계란까지 확대·시행된다.', 'labels': {'label': 3.6, 'real-label': 3.6, 'binary-label': 1}, 'annotations': {'agreement': '0:0:0:2:3:0', 'annotators': ['17', '03', '10', '09', '02'], 'annotations': [4, 3, 4, 4, 3]}}\n",
      "4107 {'guid': 'klue-sts-v1_train_04107', 'source': 'policy-sampled', 'sentence1': '국민이 위기에 처했을 때, 고난에 닥쳤을 때\\xa0믿고 기댈 수 있는 든든한 언덕.\\xa0‘안전한 대한민국’을 향한 정부의 노력은 내년에도 계속된다.', 'sentence2': '‘위기에 강한 나라, 대한민국’은 서로 연대하고 협력하는 나라입니다.', 'labels': {'label': 0.7, 'real-label': 0.6666666666666666, 'binary-label': 0}, 'annotations': {'agreement': '2:4:0:0:0:0', 'annotators': ['03', '14', '07', '06', '09', '04'], 'annotations': [1, 0, 1, 0, 1, 1]}}\n",
      "4149 {'guid': 'klue-sts-v1_train_04149', 'source': 'policy-rtt', 'sentence1': '실제로 교통사고 사망자 수는 2017년 4185명에서\\xa02018년 3781명,\\xa02019년\\xa02402명으로 계속 감소 추세에 있다.', 'sentence2': '실제로 교통사고 사망자 수는 2017년 4,185명에서 2018년 3,781명, 2019년 2,402명으로 계속 감소하고 있습니다.', 'labels': {'label': 4.1, 'real-label': 4.142857142857143, 'binary-label': 1}, 'annotations': {'agreement': '0:0:0:1:4:2', 'annotators': ['16', '03', '17', '15', '04', '18', '10'], 'annotations': [5, 3, 5, 4, 4, 4, 4]}}\n",
      "4246 {'guid': 'klue-sts-v1_train_04246', 'source': 'policy-sampled', 'sentence1': '또 소부장 생태계 활성화의 구심점 역할을 위한 ‘강소기업 100 협의회’가\\xa0발족됐다.', 'sentence2': '기업가치가 1조원을 넘은 국내 ‘유니콘기업’이\\xa020개인 것으로\\xa0조사됐다.', 'labels': {'label': 0.0, 'real-label': 0.0, 'binary-label': 0}, 'annotations': {'agreement': '6:0:0:0:0:0', 'annotators': ['09', '07', '05', '06', '15', '13'], 'annotations': [0, 0, 0, 0, 0, 0]}}\n",
      "4290 {'guid': 'klue-sts-v1_train_04290', 'source': 'policy-sampled', 'sentence1': '정부는\\xa0이달 12일 사회적 거리두기 단계의 하향조치와 코로나19 발생 상황 등을 고려, 방역당국과 협의 후 이날 중대본 회의에서\\xa0외식 활성화 캠페인을 재개하기로 결정했다.', 'sentence2': '정부는 먼저 지리정보시스템(GIS) 통합상황판을 활용, 중대본과 각 시·도, 시·군·구에서 3중으로 자가격리자 이탈여부를 24시간 실시간으로 모니터링하기로 했다.', 'labels': {'label': 0.1, 'real-label': 0.1428571428571428, 'binary-label': 0}, 'annotations': {'agreement': '6:1:0:0:0:0', 'annotators': ['14', '12', '17', '19', '13', '02', '04'], 'annotations': [0, 1, 0, 0, 0, 0, 0]}}\n",
      "4320 {'guid': 'klue-sts-v1_train_04320', 'source': 'policy-sampled', 'sentence1': '한편, 올해에는\\xa0사관학교 체험점포 중 일부를 기존 점포체험 외에 상품화·기술교육·네트워킹·상담 등이 가능한 시설(드림 스퀘어)로 구축할 계획이다.', 'sentence2': '한편, 경기도는 민감·취약계층 이용시설 217곳에 사물인터넷(IoT) 기반 미세먼지 측정센서 1085개를 구축했다.', 'labels': {'label': 0.0, 'real-label': 0.0, 'binary-label': 0}, 'annotations': {'agreement': '7:0:0:0:0:0', 'annotators': ['04', '13', '19', '17', '12', '15', '05'], 'annotations': [0, 0, 0, 0, 0, 0, 0]}}\n",
      "4410 {'guid': 'klue-sts-v1_train_04410', 'source': 'policy-sampled', 'sentence1': '국토부는 향후\\xa0교육수요를\\xa0감안, 지정교육기관의 규모를 적정수준으로 확대할 계획이다.', 'sentence2': '문체부와 국어원은 공공 용어의 외국어 번역과 국제 교류 업무를 추진하는 정부 부처와 지자체, 공공기관 등의 담당자들에게 안내서를 배포할 계획이다.', 'labels': {'label': 0.1, 'real-label': 0.1428571428571428, 'binary-label': 0}, 'annotations': {'agreement': '6:1:0:0:0:0', 'annotators': ['07', '14', '17', '12', '19', '15', '10'], 'annotations': [1, 0, 0, 0, 0, 0, 0]}}\n",
      "4571 {'guid': 'klue-sts-v1_train_04571', 'source': 'policy-sampled', 'sentence1': '스튜디오 크로스컬쳐는 기존의 ‘부모사랑 효돌’ 서비스 경험을 토대로 정부의 응급안심시스템과 연계해 어르신과 보호자 모두 만족하는 복지 서비스를 구현을 목표로\\xa0한다.', 'sentence2': '정부는 내달부터 ‘부품기업 사업재편 지원단’을 가동해 산업생태계를 보호한다.', 'labels': {'label': 0.0, 'real-label': 0.0, 'binary-label': 0}, 'annotations': {'agreement': '7:0:0:0:0:0', 'annotators': ['02', '19', '04', '12', '18', '08', '06'], 'annotations': [0, 0, 0, 0, 0, 0, 0]}}\n",
      "4572 {'guid': 'klue-sts-v1_train_04572', 'source': 'policy-rtt', 'sentence1': '이러한\\xa0그린뉴딜 정책은 최근 친환경 에너지 정책을 중시하는 조 바이든 미국 대통령 당선인이\\xa0‘탄소 제로’를 선언하면서 더욱 탄력을 받을 것으로 보인다.', 'sentence2': '친환경 에너지 정책을 중시하는 미국 대통령 당선자 조 바이든이 최근 \"탄소 제로\"를 선언함에 따라 이 그린 뉴딜 정책은 더욱 탄력을 받을 것으로 예상됩니다.', 'labels': {'label': 4.3, 'real-label': 4.333333333333333, 'binary-label': 1}, 'annotations': {'agreement': '0:0:0:0:4:2', 'annotators': ['02', '19', '09', '04', '18', '13'], 'annotations': [5, 4, 5, 4, 4, 4]}}\n",
      "4609 {'guid': 'klue-sts-v1_train_04609', 'source': 'policy-sampled', 'sentence1': '오늘 이 자리가 방역과 경제의 동반 성공, 두 마리 토끼를 기필코 잡아낼 것을\\xa0함께 다짐하는 자리가 되었으면 합니다.', 'sentence2': '국난 극복의 의지를 모으고 있는 국민들께 입법으로 화답하는 국회가 되길 기대합니다.', 'labels': {'label': 0.0, 'real-label': 0.0, 'binary-label': 0}, 'annotations': {'agreement': '6:0:0:0:0:0', 'annotators': ['07', '17', '13', '15', '18', '02'], 'annotations': [0, 0, 0, 0, 0, 0]}}\n",
      "4620 {'guid': 'klue-sts-v1_train_04620', 'source': 'policy-sampled', 'sentence1': '정부가 코로나19로 어려움에 처한 소득하위 70%인 1400만 가구에\\xa0긴급재난지원금으로 9조1000억원을 푼다.', 'sentence2': '앞서 기재부는 소득 하위 70%에 긴급재난지원금을 지급하기 위한 2차 추경안을 지난 16일 국회에 제출한 바 있다.', 'labels': {'label': 1.0, 'real-label': 1.0, 'binary-label': 0}, 'annotations': {'agreement': '3:2:1:1:0:0', 'annotators': ['05', '04', '09', '18', '19', '08', '06'], 'annotations': [3, 2, 1, 1, 0, 0, 0]}}\n",
      "4740 {'guid': 'klue-sts-v1_train_04740', 'source': 'policy-sampled', 'sentence1': '즉 일본 지향이 아닌 세계지향, 현재 공급망 안정에서 미래공급망 창출의\\xa0투 트랙\\xa0RD를 추진한다', 'sentence2': '이에 따르면 먼저 2021년 800곳, 2025년까지 4000개의 스마트슈퍼를\\xa0육성한다.', 'labels': {'label': 0.0, 'real-label': 0.0, 'binary-label': 0}, 'annotations': {'agreement': '6:0:0:0:0:0', 'annotators': ['02', '17', '03', '13', '18', '05'], 'annotations': [0, 0, 0, 0, 0, 0]}}\n",
      "4791 {'guid': 'klue-sts-v1_train_04791', 'source': 'policy-sampled', 'sentence1': '개정안에 따르면\\xa0규제지역(투기과열지구·조정대상지역) 내 주택 거래 신고 시 ‘주택 취득자금 조달 및 입주계획서(자금조달계획서)’ 제출이 의무화된다.', 'sentence2': '이에 따라 기존의 쌀·밭 직불제 등은 ‘농업·농촌공익증진직불제(공익직불제)’로 통합된다.', 'labels': {'label': 0.0, 'real-label': 0.0, 'binary-label': 0}, 'annotations': {'agreement': '6:0:0:0:0:0', 'annotators': ['17', '07', '16', '05', '02', '13'], 'annotations': [0, 0, 0, 0, 0, 0]}}\n",
      "4846 {'guid': 'klue-sts-v1_train_04846', 'source': 'policy-sampled', 'sentence1': '학교 밖 청소년에게는 학습부터 진로 및 건강까지 종합 지원을 강화하기 위해\\xa0▲급식지원 실시 ▲전용공간 20곳 설치 ▲공공분야 차별사례 발굴 및 대국민 인식개선 등을 추진한다.', 'sentence2': '한편 고용부는 택배기사의 안전과 건강에 대한 택배사의 책임을 강화하기 위해 산업안전보건법에 택배사의 안전조치 및 보건조치 의무신설을 추진한다.', 'labels': {'label': 0.0, 'real-label': 0.0, 'binary-label': 0}, 'annotations': {'agreement': '7:0:0:0:0:0', 'annotators': ['16', '09', '15', '06', '08', '10', '02'], 'annotations': [0, 0, 0, 0, 0, 0, 0]}}\n",
      "4918 {'guid': 'klue-sts-v1_train_04918', 'source': 'policy-rtt', 'sentence1': '2025년까지 총 460만(주택 232만+ 금융96만 + 주거급여 130만 등)의\\xa0 고령 또는 일반 저소득 가구가 지원 받게 됨', 'sentence2': '2025년까지 총 460만 가구(예: 232만 가구 + 96만 가구 + 130만 가구)가 지원될 예정입니다.', 'labels': {'label': 3.2, 'real-label': 3.166666666666667, 'binary-label': 1}, 'annotations': {'agreement': '0:0:1:3:2:0', 'annotators': ['08', '12', '05', '13', '18', '09'], 'annotations': [2, 4, 4, 3, 3, 3]}}\n",
      "4956 {'guid': 'klue-sts-v1_train_04956', 'source': 'policy-sampled', 'sentence1': '수출입기업은 중국해관의 정상근무 여부(야간·비상시 임시개청 여부 포함),\\xa0공항만 정상운영 여부, 검역강화에 따른 통관지연 등 중국 현지에 대한 정보를 확인할 수 있다.', 'sentence2': '한편, ‘2020 온라인 과학축제’에 대한 자세한 정보는 과학문화 누리집 사이언스올(www.scienceall.com)에서 확인할 수 있다.', 'labels': {'label': 0.2, 'real-label': 0.1666666666666667, 'binary-label': 0}, 'annotations': {'agreement': '5:1:0:0:0:0', 'annotators': ['17', '12', '06', '19', '08', '13'], 'annotations': [0, 1, 0, 0, 0, 0]}}\n",
      "5361 {'guid': 'klue-sts-v1_train_05361', 'source': 'policy-rtt', 'sentence1': '지원을 원하는 임산부는 임신확인서나 출생증명서를\\xa0주민센터에 제출하면 된다.', 'sentence2': '지원을 원하는 임산부는 주민센터에 임신증명서나 출생증명서를 제출할 수 있습니다.', 'labels': {'label': 4.2, 'real-label': 4.166666666666667, 'binary-label': 1}, 'annotations': {'agreement': '0:0:0:1:3:2', 'annotators': ['12', '16', '15', '05', '18', '06'], 'annotations': [5, 4, 3, 4, 4, 5]}}\n",
      "5563 {'guid': 'klue-sts-v1_train_05563', 'source': 'policy-sampled', 'sentence1': '11일부터\\xa0국내 증시에서 공매도 과열종목으로 지정되면\\xa02주간(10거래일) 공매도가 금지된다.', 'sentence2': '이번 조치는 다음달 1일부터 시행하며 비수도권에서는 14일까지 2주간, 수도권에서는 7일까지 1주간 각각 적용된다.', 'labels': {'label': 0.6, 'real-label': 0.5714285714285714, 'binary-label': 0}, 'annotations': {'agreement': '6:0:0:0:1:0', 'annotators': ['07', '14', '13', '05', '15', '02', '18'], 'annotations': [0, 0, 0, 4, 0, 0, 0]}}\n",
      "5642 {'guid': 'klue-sts-v1_train_05642', 'source': 'policy-rtt', 'sentence1': '포스코케미칼은 이차전지 음극재 공장 건립에 2021년까지 2500억원을 투자하는 등\\xa0배터리 관련 3개 기업이 3350억원을 투자하기로 했다.', 'sentence2': '포스코케미칼은 2021년까지 2500억원 등 배터리 관련 3개사가 3,350억원을 투자해 2차 배터리 음극재 공장을 건설하기로 했습니다.', 'labels': {'label': 3.7, 'real-label': 3.714285714285714, 'binary-label': 1}, 'annotations': {'agreement': '0:0:0:3:3:1', 'annotators': ['09', '02', '13', '07', '03', '18', '10'], 'annotations': [4, 5, 4, 3, 3, 3, 4]}}\n",
      "5687 {'guid': 'klue-sts-v1_train_05687', 'source': 'policy-sampled', 'sentence1': '우리는\\xa0 보건장관들에게 각국의 모범사례를 공유하고, 4월 장관회의에서 이 세계적 대유행에 대한 G20 차원의 공동 긴급조치를 마련하는 임무를 부여한다.', 'sentence2': '우선, 우한시에서 입국하는 항공편에 대한 검역 강화 조치를 지속 실시하고 공항 내 주의 안내문 통보를 확대한다.', 'labels': {'label': 0.0, 'real-label': 0.0, 'binary-label': 0}, 'annotations': {'agreement': '6:0:0:0:0:0', 'annotators': ['16', '03', '09', '15', '02', '06'], 'annotations': [0, 0, 0, 0, 0, 0]}}\n",
      "5688 {'guid': 'klue-sts-v1_train_05688', 'source': 'policy-rtt', 'sentence1': '이와함께 1차 소상공인 긴급대출을 받았거나 기존 채무 연체 및\\xa0국세·지방세 체납자 등도\\xa0 2차 긴급대출 지원 대상에서 제외된다.', 'sentence2': '이와 함께 1차 중소기업자로부터 긴급대출을 받거나 이미 채무 및 국세와 지방세를 체납한 자도 2차 긴급대출 지원 대상에서 제외됩니다.', 'labels': {'label': 4.2, 'real-label': 4.166666666666667, 'binary-label': 1}, 'annotations': {'agreement': '0:0:0:1:3:2', 'annotators': ['03', '08', '13', '10', '06', '18'], 'annotations': [4, 3, 4, 4, 5, 5]}}\n",
      "5753 {'guid': 'klue-sts-v1_train_05753', 'source': 'policy-rtt', 'sentence1': '미래를 선제적으로 준비해야 하는\\xa0절체절명의 시간입니다.', 'sentence2': '미래를 위해 능동적으로 준비하기 위한 절박한 시기입니다.', 'labels': {'label': 3.3, 'real-label': 3.285714285714286, 'binary-label': 1}, 'annotations': {'agreement': '0:0:0:5:2:0', 'annotators': ['17', '16', '12', '08', '07', '13', '04'], 'annotations': [4, 3, 3, 3, 3, 3, 4]}}\n",
      "5949 {'guid': 'klue-sts-v1_train_05949', 'source': 'policy-sampled', 'sentence1': '또 노후경유차인 화물차 13만 5000대와 통학차 8만 8000대는 LPG·전기차로 전환하도록\\xa0지원한다.', 'sentence2': '정부는 그야말로 비상 정부체제로 전환하였습니다.', 'labels': {'label': 0.1, 'real-label': 0.1428571428571428, 'binary-label': 0}, 'annotations': {'agreement': '6:1:0:0:0:0', 'annotators': ['08', '16', '17', '05', '09', '18', '03'], 'annotations': [1, 0, 0, 0, 0, 0, 0]}}\n",
      "5997 {'guid': 'klue-sts-v1_train_05997', 'source': 'policy-rtt', 'sentence1': '정부가 어린이집·유치원 개원 연기, 온라인 개학에 대응해 가족돌봄비용을 최대 10일,\\xa050만원으로 2배 확대한다.', 'sentence2': '정부는 어린이집과 유치원의 개원과 온라인 학교의 개학을 연기하는 것에 대응하여 가족 보호 비용을 최대 10일인 50만 원으로 두 배로 늘릴 예정입니다.', 'labels': {'label': 3.6, 'real-label': 3.6, 'binary-label': 1}, 'annotations': {'agreement': '0:0:0:2:3:0', 'annotators': ['14', '06', '03', '12', '08'], 'annotations': [4, 3, 3, 4, 4]}}\n",
      "6027 {'guid': 'klue-sts-v1_train_06027', 'source': 'policy-rtt', 'sentence1': '마스크 생산 확대를 위해\\xa0생산설비 확충, MB필터 확보, 인력·운송 지원, 규제 완화 등 전방위적 지원에 나선다.', 'sentence2': '마스크 생산 확대를 위해 생산시설 확충, MB필터 확보, 인력 및 운송 지원, 규제 완화 등 전방위 지원을 할 예정입니다.', 'labels': {'label': 4.7, 'real-label': 4.666666666666667, 'binary-label': 1}, 'annotations': {'agreement': '0:0:0:0:2:4', 'annotators': ['09', '04', '13', '05', '07', '18'], 'annotations': [5, 4, 5, 5, 4, 5]}}\n",
      "6044 {'guid': 'klue-sts-v1_train_06044', 'source': 'policy-rtt', 'sentence1': '혁신성장예산에는 전년보다 49%\\xa0늘어난 15조8000억원으로 책정하는 등 예산·세제·조달·공공기관 등 정책수단을 활용한 총력 지원할 예정이다.', 'sentence2': '정부는 예산, 세금, 조달, 공공기관과 같은 정책 수단을 사용하여 예산을 전년보다 49% 증가한 15조 8천억 원으로 책정함으로써 총력을 기울일 계획입니다.', 'labels': {'label': 3.3, 'real-label': 3.333333333333333, 'binary-label': 1}, 'annotations': {'agreement': '1:0:0:2:1:2', 'annotators': ['14', '13', '05', '08', '19', '04'], 'annotations': [5, 5, 3, 4, 0, 3]}}\n",
      "6092 {'guid': 'klue-sts-v1_train_06092', 'source': 'policy-rtt', 'sentence1': '중기부가 214개 식당에서 7700만원을, 11개 공공기관이\\xa0622개 식당에서 1억 7200만원을 각각 선결제했다.', 'sentence2': '중소벤처기업부는 214개 식당에서 7700만원, 공공기관 622곳에서 1억1700만원을 각각 지급했습니다.', 'labels': {'label': 3.7, 'real-label': 3.714285714285714, 'binary-label': 1}, 'annotations': {'agreement': '0:0:0:3:3:1', 'annotators': ['03', '14', '05', '15', '18', '12', '06'], 'annotations': [3, 3, 4, 4, 3, 5, 4]}}\n",
      "6100 {'guid': 'klue-sts-v1_train_06100', 'source': 'policy-rtt', 'sentence1': '축산물이력제는 가축의 출생부터 도축·유통까지의 정보를 기록·관리해 축산물 유통의 투명성을 확보하기 위한\\xa0제도다.', 'sentence2': '축산물 이력 제도는 가축의 탄생부터 도축과 유통에 이르는 정보를 기록, 관리함으로써 축산물 유통의 투명성을 확보하기 위한 제도입니다.', 'labels': {'label': 4.0, 'real-label': 4.0, 'binary-label': 1}, 'annotations': {'agreement': '0:0:0:2:2:2', 'annotators': ['03', '17', '05', '19', '13', '12'], 'annotations': [3, 4, 3, 4, 5, 5]}}\n",
      "6141 {'guid': 'klue-sts-v1_train_06141', 'source': 'policy-sampled', 'sentence1': '아울러 중국의 케이팝(K-POP) 스타 온라인 버스킹, 홈트레이닝 동영상 플랫폼(KEEP) 등을 통해 떡볶이·스낵류 등 휴게식품과 인삼·건강식품·에너지음료 등을\\xa0홍보한다.', 'sentence2': '주택 소유자와 그 배우자의 직계존비속(그 배우자를 포함한다) 및 형제·자매 등', 'labels': {'label': 0.0, 'real-label': 0.0, 'binary-label': 0}, 'annotations': {'agreement': '7:0:0:0:0:0', 'annotators': ['15', '06', '07', '16', '14', '19', '10'], 'annotations': [0, 0, 0, 0, 0, 0, 0]}}\n",
      "6143 {'guid': 'klue-sts-v1_train_06143', 'source': 'policy-sampled', 'sentence1': '대학생과 미취업 청년들이 실질적인 혜택을 받을 수 있도록 ‘청년 버팀목 전세대출’의\\xa0조건을 개선한다.', 'sentence2': '피해 기업이 경영 애로나 법률 상담을 받을 수 있도록 예술경영지원센터 안에 ‘코로나19 전담창구’도 운영한다.', 'labels': {'label': 0.0, 'real-label': 0.0, 'binary-label': 0}, 'annotations': {'agreement': '7:0:0:0:0:0', 'annotators': ['09', '07', '15', '04', '19', '06', '10'], 'annotations': [0, 0, 0, 0, 0, 0, 0]}}\n",
      "6151 {'guid': 'klue-sts-v1_train_06151', 'source': 'policy-sampled', 'sentence1': '플랫폼 택시\\xa0출시를 지원하는 등 드론·자율주행·플랫폼을 통한 모빌리티 혁신도 꾀할 계획이다.', 'sentence2': '선박금융 지원규모도 1000억원 확대할 계획이다.', 'labels': {'label': 0.3, 'real-label': 0.3333333333333333, 'binary-label': 0}, 'annotations': {'agreement': '5:0:1:0:0:0', 'annotators': ['04', '05', '19', '03', '06', '02'], 'annotations': [0, 0, 0, 2, 0, 0]}}\n",
      "6177 {'guid': 'klue-sts-v1_train_06177', 'source': 'policy-rtt', 'sentence1': '청사 방역 작업은 코로나19가 종식될 때까지 수시로, 꾸준히\\xa0실시할 계획이다.', 'sentence2': '정부는 코로나 19년 말까지 이 건물에서 때때로 격리 작업을 수행할 계획입니다.', 'labels': {'label': 2.0, 'real-label': 2.0, 'binary-label': 0}, 'annotations': {'agreement': '1:1:2:3:0:0', 'annotators': ['03', '16', '08', '02', '06', '12', '19'], 'annotations': [2, 2, 3, 0, 1, 3, 3]}}\n",
      "6638 {'guid': 'klue-sts-v1_train_06638', 'source': 'policy-rtt', 'sentence1': '중기부는\\xa0제도에 참여를 희망하는 중소기업이 창업기업 여부를 확인하는 데 필요한 창업기업 확인 업무의 절차도 구체화했다.', 'sentence2': '중소벤처기업부는 또한 이 제도에 참여하고자 하는 중소기업이 창업기업인지를 확인하기 위해 필요한 창업기업 점검절차를 구체화하였습니다.', 'labels': {'label': 4.0, 'real-label': 4.0, 'binary-label': 1}, 'annotations': {'agreement': '0:0:0:2:2:2', 'annotators': ['07', '14', '13', '03', '08', '04'], 'annotations': [4, 5, 5, 3, 3, 4]}}\n",
      "6678 {'guid': 'klue-sts-v1_train_06678', 'source': 'policy-rtt', 'sentence1': '정부는\\xa022일부터 위험도가 낮은 야외공간인 자연휴양림, 수목원 등 시설에 순차적으로 입장을 허용할 계획이다.', 'sentence2': '정부는 22일부터 자연휴양림과 위험도가 낮은 야외수목원 등 시설 출입을 순차적으로 허용할 계획입니다.', 'labels': {'label': 4.0, 'real-label': 4.0, 'binary-label': 1}, 'annotations': {'agreement': '0:0:0:1:3:1', 'annotators': ['04', '12', '03', '02', '10'], 'annotations': [4, 4, 3, 5, 4]}}\n",
      "6742 {'guid': 'klue-sts-v1_train_06742', 'source': 'policy-sampled', 'sentence1': '이날 퇴소한 교민들은 미리 준비된 버스 20대를\\xa0이용해 5개권역(서울, 대구·영남, 충북·대전·호남, 경기, 충남)으로 이송됐다.', 'sentence2': '지난달은 조업일수를 고려한 하루 평균 수출액도 6.3% 증가한 것으로 집계됐다.', 'labels': {'label': 0.0, 'real-label': 0.0, 'binary-label': 0}, 'annotations': {'agreement': '7:0:0:0:0:0', 'annotators': ['17', '07', '04', '16', '12', '18', '09'], 'annotations': [0, 0, 0, 0, 0, 0, 0]}}\n",
      "6762 {'guid': 'klue-sts-v1_train_06762', 'source': 'policy-sampled', 'sentence1': '민간임대주택법 시행규칙을 개정해 오피스텔 임대사업자의\\xa0실제거주 확인방식을 다양화한다.', 'sentence2': '관광진흥법 개정을 통해 관광특구 지정 요건도 완화한다.', 'labels': {'label': 0.0, 'real-label': 0.0, 'binary-label': 0}, 'annotations': {'agreement': '7:0:0:0:0:0', 'annotators': ['02', '03', '16', '15', '08', '05', '10'], 'annotations': [0, 0, 0, 0, 0, 0, 0]}}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6968 {'guid': 'klue-sts-v1_train_06968', 'source': 'policy-rtt', 'sentence1': '청약신청은 한국토지주택공사, 서울주택도시공사, 경기주택도시공사 등 공공주택사업자별 입주자모집 공고를 확인한 후\\xa0누리집 또는\\xa0현장접수 등으로 가능하다.', 'sentence2': '청약접수는 한국토지주택공사, 서울주택도시공사, 경기주택도시공사 등 공공주택사업자를 확인한 후 홈페이지 또는 현장 신청을 통해 가능합니다.', 'labels': {'label': 3.9, 'real-label': 3.857142857142857, 'binary-label': 1}, 'annotations': {'agreement': '0:0:0:2:4:1', 'annotators': ['17', '03', '07', '16', '19', '15', '04'], 'annotations': [5, 4, 4, 3, 4, 3, 4]}}\n",
      "7093 {'guid': 'klue-sts-v1_train_07093', 'source': 'policy-sampled', 'sentence1': '또\\xa0하루 300~400여명에 달하는\\xa0외부 방문객 출입을 전면 금지하는 한편, 직원과의 대면 업무도\\xa0금지하는 등 사회적 거리두기를 적극 실천중이다.', 'sentence2': '외교부는 주한 외교단과 함께 코로나19의 확산 억제를 위해 실시하는 범정부적인 ‘사회적 거리두기’를 적극 실천한다.', 'labels': {'label': 1.3, 'real-label': 1.333333333333333, 'binary-label': 0}, 'annotations': {'agreement': '1:3:1:1:0:0', 'annotators': ['12', '02', '06', '19', '04', '10'], 'annotations': [1, 1, 1, 3, 2, 0]}}\n",
      "7184 {'guid': 'klue-sts-v1_train_07184', 'source': 'policy-sampled', 'sentence1': '최근\\xa0한밭협동조합연합회 동구지회와 대전 동구는\\xa0중앙시장 상인들에게 수제 천 마스크 제작 주문을 의뢰했다.', 'sentence2': '평안북도는 12일 이북5도청 소회의실에서 오영찬 평북도지사, 평북 명예시장·군수, 평북 명예읍·면·동장 등이 참석한 가운데 사랑의 마스크 전달식을 가졌다.', 'labels': {'label': 0.3, 'real-label': 0.3333333333333333, 'binary-label': 0}, 'annotations': {'agreement': '4:2:0:0:0:0', 'annotators': ['13', '05', '09', '08', '06', '19'], 'annotations': [1, 0, 0, 1, 0, 0]}}\n",
      "7262 {'guid': 'klue-sts-v1_train_07262', 'source': 'policy-rtt', 'sentence1': '한편,\\xa0동계체전 종목 중 컬링(혼성 결승)과 빙상 스피드스케이팅(남녀 500m) 경기는 KBS 1TV를 통해 중계된다.', 'sentence2': '한편, 컬링 (혼합 결승)과 아이스 스피드 스케이팅 (남녀 500m) 경기는 KBS 1TV를 통해 방송될 예정입니다.', 'labels': {'label': 3.8, 'real-label': 3.833333333333333, 'binary-label': 1}, 'annotations': {'agreement': '0:0:0:2:3:1', 'annotators': ['03', '02', '17', '12', '13', '07'], 'annotations': [3, 4, 4, 5, 4, 3]}}\n",
      "7289 {'guid': 'klue-sts-v1_train_07289', 'source': 'policy-sampled', 'sentence1': '기후·환경 문제를 해결하는 녹색산업에 대한 집중 투자로\\xa0생산유발 효과 4조 5000억 원, 녹색 일자리 1만 9000개를 창출할 예정이다.', 'sentence2': '청정대기 산업, 스마트 물산업, 기후·에너지 산업, 생태서비스 산업에 대한 집중 투자로 생산유발 효과 4조 5000억 원, 녹색 일자리 1만 9000개를 창출할 계획이다.', 'labels': {'label': 3.6, 'real-label': 3.571428571428572, 'binary-label': 1}, 'annotations': {'agreement': '0:1:0:2:2:2', 'annotators': ['17', '04', '10', '06', '12', '08', '09'], 'annotations': [1, 3, 4, 4, 5, 3, 5]}}\n",
      "7342 {'guid': 'klue-sts-v1_train_07342', 'source': 'policy-sampled', 'sentence1': '이와 관련\\xa0한국산업기술진흥원(KIAT)과 헝가리 국가연구개발혁신청(NRDI)은 ‘산업기술 협력에 관한 양해각서(MOU)’를 체결했다.', 'sentence2': '이와 함께 방대본은 ‘집단시설·다중이용시설 소독 안내(제3-2판)’도 개정·배포했다.', 'labels': {'label': 0.0, 'real-label': 0.0, 'binary-label': 0}, 'annotations': {'agreement': '7:0:0:0:0:0', 'annotators': ['02', '07', '12', '05', '19', '04', '09'], 'annotations': [0, 0, 0, 0, 0, 0, 0]}}\n",
      "7427 {'guid': 'klue-sts-v1_train_07427', 'source': 'policy-rtt', 'sentence1': '논의 내용은\\xa0 신종 코로나바이러스 관련 업계 현황, 마스크상품 판매 관련 업계 애로사항 청취 및 지원방안 논의 등이었다.', 'sentence2': '논의에는 새로운 코로나 바이러스 관련 산업의 현황, 마스크 제품 판매와 관련된 산업 애로사항 청취, 지원 방법 논의 등이 포함되었습니다.', 'labels': {'label': 3.7, 'real-label': 3.666666666666667, 'binary-label': 1}, 'annotations': {'agreement': '0:0:0:3:2:1', 'annotators': ['03', '19', '07', '12', '15', '08'], 'annotations': [3, 5, 4, 4, 3, 3]}}\n",
      "7451 {'guid': 'klue-sts-v1_train_07451', 'source': 'policy-rtt', 'sentence1': '이날 킥오프 회의에서는 이번\\xa0화재의 주요 원인으로 지목된 가연성 건축자재와 폭발 우려가 높은 뿜칠 작업의 관리 방안이 검토 과제로 제시됐다.', 'sentence2': '발차 회의에서, 폭발로 우려되는 가연성 건축 자재와 공사의 관리가 화재의 주요 원인으로 제시되었습니다.', 'labels': {'label': 3.0, 'real-label': 3.0, 'binary-label': 1}, 'annotations': {'agreement': '1:0:0:3:1:1', 'annotators': ['17', '14', '12', '09', '19', '06'], 'annotations': [3, 5, 3, 4, 3, 0]}}\n",
      "7617 {'guid': 'klue-sts-v1_train_07617', 'source': 'policy-sampled', 'sentence1': '지자체-지역 특화 산업-참여 기업,\\xa0함께 만들어가는 산업관광', 'sentence2': '경제, 산업, 교육, 보건, 안전 등 많은 분야에서새로운 세계적 규범과 표준을 만들어낼 수 있을 것입니다.', 'labels': {'label': 0.3, 'real-label': 0.2857142857142857, 'binary-label': 0}, 'annotations': {'agreement': '6:0:1:0:0:0', 'annotators': ['04', '07', '15', '12', '05', '06', '08'], 'annotations': [2, 0, 0, 0, 0, 0, 0]}}\n",
      "7666 {'guid': 'klue-sts-v1_train_07666', 'source': 'policy-rtt', 'sentence1': '올해 35개 기업연구소가\\xa0공모 결과 우수 기업연구소로 선정됐다.', 'sentence2': '올해, 35개의 기업 연구 기관들이 콘테스트의 결과로 우수한 기업 연구 기관으로 선정되었습니다.', 'labels': {'label': 3.5, 'real-label': 3.5, 'binary-label': 1}, 'annotations': {'agreement': '0:0:0:3:3:0', 'annotators': ['17', '03', '06', '19', '12', '15'], 'annotations': [4, 4, 3, 3, 4, 3]}}\n",
      "7671 {'guid': 'klue-sts-v1_train_07671', 'source': 'policy-rtt', 'sentence1': '우선 신천지 대구교회 신도를 대상으로 코로나19 전수검사와 격리 해제 전까지 전수 확진검사를 시행할 계획으로, 민간 의료기관 4개소를\\xa0 추가 지정했다.', 'sentence2': '우선 신천지 대구교회 신도들을 대상으로 코로나 19호 검진과 격리 해제 전 전면 확인 검사를 실시할 계획으로 민간 의료기관 4곳이 추가로 지정됐습니다.', 'labels': {'label': 4.3, 'real-label': 4.285714285714286, 'binary-label': 1}, 'annotations': {'agreement': '0:0:0:0:5:2', 'annotators': ['17', '03', '10', '06', '05', '19', '13'], 'annotations': [5, 4, 4, 4, 4, 4, 5]}}\n",
      "7857 {'guid': 'klue-sts-v1_train_07857', 'source': 'policy-sampled', 'sentence1': '크레디트스위스도 아시아 국가 중 내년에 주당순이익(당기 순 이익을 주식수로 나눈 값)의\\xa043% 성장이 기대되는 한국을 최선호 국가로 꼽았다.', 'sentence2': '전국 6개 지역에 운영 중인 보훈요양원도 올해 11월 강원권 요양원을 시작으로 내년 전북권에 개원을 목표로 건립 진행 중이다.', 'labels': {'label': 0.0, 'real-label': 0.0, 'binary-label': 0}, 'annotations': {'agreement': '6:0:0:0:0:0', 'annotators': ['03', '16', '17', '19', '04', '14'], 'annotations': [0, 0, 0, 0, 0, 0]}}\n",
      "8136 {'guid': 'klue-sts-v1_train_08136', 'source': 'policy-rtt', 'sentence1': '조달청 정부조달콜센터가 코로나19 집단 감염 및 확산 방지를 위해\\xa0단계적으로 재택상담을 확대한다.', 'sentence2': '조달청 정부구매콜센터는 코로나19 감염 및 확산을 막기 위해 원격조달시설을 점차 확대할 예정입니다.', 'labels': {'label': 3.0, 'real-label': 3.0, 'binary-label': 1}, 'annotations': {'agreement': '0:0:2:2:2:0', 'annotators': ['03', '07', '14', '09', '13', '12'], 'annotations': [3, 3, 2, 4, 2, 4]}}\n",
      "8150 {'guid': 'klue-sts-v1_train_08150', 'source': 'policy-sampled', 'sentence1': '그 외 대구(스마트웰니스), 세종(자율주행), 강원(디지털헬스케어), 충북(스마트안전제어), 전남(e-모빌리티) 등 나머지 5개 특구는 ‘보통’\\xa0평가를 받았다.', 'sentence2': '반대 응답자(13.2%) 중에서는 ‘인권침해 소지’를 문제 삼은 게 가장 많았다', 'labels': {'label': 0.1, 'real-label': 0.1428571428571428, 'binary-label': 0}, 'annotations': {'agreement': '6:1:0:0:0:0', 'annotators': ['02', '09', '04', '03', '07', '18', '06'], 'annotations': [0, 0, 0, 1, 0, 0, 0]}}\n",
      "8296 {'guid': 'klue-sts-v1_train_08296', 'source': 'policy-sampled', 'sentence1': '지역별로도 우리 수출의 66%를 차지하는 4대(중국과\\xa0미국, EU, 아세안) 시장의 하루 평균 수출액이 25개월만에 모두 플러스로 전환됐다.', 'sentence2': '세계 인구와 무역 규모가 전 세계에서 차지하는 비중이 30%에 달하는 세계 최대 FTA(자유무역협정) 시장이 탄생했다.', 'labels': {'label': 0.0, 'real-label': 0.0, 'binary-label': 0}, 'annotations': {'agreement': '7:0:0:0:0:0', 'annotators': ['16', '17', '10', '02', '19', '08', '06'], 'annotations': [0, 0, 0, 0, 0, 0, 0]}}\n",
      "8409 {'guid': 'klue-sts-v1_train_08409', 'source': 'policy-rtt', 'sentence1': '아울러 소상공인 점포 선결제에 동참한 기업에는 소득세와 법인세에 세액공제 1%를 적용하는 내용으로 법 개정도\\xa0추진 중이다.', 'sentence2': '또한, 영세 자영업자의 선납에 참여하는 기업에 대해서는 소득세와 법인세의 1%를 공제하도록 법이 개정되고 있습니다.', 'labels': {'label': 3.7, 'real-label': 3.714285714285714, 'binary-label': 1}, 'annotations': {'agreement': '0:0:0:3:3:1', 'annotators': ['02', '04', '03', '10', '05', '06', '07'], 'annotations': [3, 4, 3, 4, 3, 5, 4]}}\n",
      "8440 {'guid': 'klue-sts-v1_train_08440', 'source': 'policy-sampled', 'sentence1': '이는 영유아수 감소 등 여건변화를 고려한 것으로, 농촌지역 소규모 어린이집을 지원하는 ‘농촌공동아이돌봄 센터’ 사업의 대상자를 사회복지법인어린이집까지 추가한\\xa0것이다.', 'sentence2': '2025년까지 그린분야 창업기업 2000개를 발굴해 교육, 사업화, 투자유치 등을 지원하는 ‘그린 스타트업 2000’ 프로그램을 신설한다.', 'labels': {'label': 0.2, 'real-label': 0.1666666666666667, 'binary-label': 0}, 'annotations': {'agreement': '5:1:0:0:0:0', 'annotators': ['17', '15', '05', '18', '12', '04'], 'annotations': [0, 1, 0, 0, 0, 0]}}\n",
      "8469 {'guid': 'klue-sts-v1_train_08469', 'source': 'policy-rtt', 'sentence1': '중국의 식품 전문 인플루언서와 함께 현지 최대 온라인몰인 티몰과 징동몰에서 다음달부터 ‘한국인삼대전’을\\xa0연다.', 'sentence2': \"중국의 식품 전문업체인 인플루언서와 함께, 이 지역에서 가장 큰 온라인 쇼핑몰인 티몰과 징동몰이 다음 달부터 '한국 삼전'을 열 예정입니다.\", 'labels': {'label': 3.6, 'real-label': 3.6, 'binary-label': 1}, 'annotations': {'agreement': '0:0:1:0:4:0', 'annotators': ['12', '08', '10', '04', '19'], 'annotations': [4, 2, 4, 4, 4]}}\n",
      "8545 {'guid': 'klue-sts-v1_train_08545', 'source': 'policy-rtt', 'sentence1': '또한 최근에는\\xa0요양원이나 요양병원, 방문판매업체, 어린이집 등에서도 감염원이 불분명한 사례가 발생했다.', 'sentence2': '최근, 요양원, 요양병원, 방문판매업자, 어린이집에서 불명확한 감염 사례가 발생하고 있습니다.', 'labels': {'label': 4.2, 'real-label': 4.2, 'binary-label': 1}, 'annotations': {'agreement': '0:0:0:1:2:2', 'annotators': ['14', '15', '02', '18', '08'], 'annotations': [5, 4, 3, 4, 5]}}\n",
      "8569 {'guid': 'klue-sts-v1_train_08569', 'source': 'policy-rtt', 'sentence1': '이는\\xa02015년 중동호흡기증후군(MERS·메르스)사태 당시 11조6000억원과 유사한 규모의 수준이다.', 'sentence2': '이 금액은 2015년 중동호흡기증후군 사건 당시 11조 6천억 원과 비슷합니다.', 'labels': {'label': 4.0, 'real-label': 4.0, 'binary-label': 1}, 'annotations': {'agreement': '0:0:0:1:5:1', 'annotators': ['02', '07', '19', '18', '06', '04', '08'], 'annotations': [5, 4, 4, 4, 4, 3, 4]}}\n",
      "8649 {'guid': 'klue-sts-v1_train_08649', 'source': 'policy-sampled', 'sentence1': '아울러 농식품부는\\xa0철새도래지의 사람·차량 통제와 소독, 거점소독시설 운영실태에 대해 대대적인 점검을 실시한다.', 'sentence2': '아울러 농식품부는 화훼농가의 어려움을 감안해 농가에 대한 자금지원을 확대한다.', 'labels': {'label': 1.3, 'real-label': 1.285714285714286, 'binary-label': 0}, 'annotations': {'agreement': '1:4:1:1:0:0', 'annotators': ['09', '12', '02', '05', '10', '18', '08'], 'annotations': [2, 1, 3, 0, 1, 1, 1]}}\n",
      "8706 {'guid': 'klue-sts-v1_train_08706', 'source': 'policy-rtt', 'sentence1': '의료기관에 마스크를 최우선으로 공급할\\xa0정부 대책이 없다?', 'sentence2': '의료 기관에 마스크를 먼저 공급하는 정부 대책이 없나요?', 'labels': {'label': 4.0, 'real-label': 4.0, 'binary-label': 1}, 'annotations': {'agreement': '0:0:0:2:2:2', 'annotators': ['09', '03', '04', '19', '06', '14'], 'annotations': [5, 4, 3, 4, 3, 5]}}\n",
      "8816 {'guid': 'klue-sts-v1_train_08816', 'source': 'policy-sampled', 'sentence1': '정부가 5일 고위공직자범죄수사처(공수처) 설립준비단장에 남기명 전 법제처장을 위촉하고 오는 7월로 예정된\\xa0공수처 출범을 위한 본격적인 준비작업에 돌입한다.', 'sentence2': '지난해 법무부는 고위공직자범죄수사처(공수처) 설치와 수사권개혁 법령을 제·개정 함으로써 새로운 형사사법제도 정립을 위한 제도적 기반을 마련했다.', 'labels': {'label': 1.7, 'real-label': 1.666666666666667, 'binary-label': 0}, 'annotations': {'agreement': '1:1:3:1:0:0', 'annotators': ['05', '14', '07', '06', '08', '19'], 'annotations': [2, 2, 2, 1, 3, 0]}}\n",
      "8843 {'guid': 'klue-sts-v1_train_08843', 'source': 'policy-rtt', 'sentence1': '홍남기 부총리 겸 기획재정부 장관은 12일 오전 정부서울청사에서 주재한\\xa0코로나19 대응 경제관계장관회의 겸 경제활력대책회의 모두 발언에서 이같이 밝혔다.', 'sentence2': '홍남기 부총리 겸 기획재정부 장관이 12일 오전 정부서울청사에서 열린 코로나19 국무회의 경제활력대책회의에서 이같이 밝혔습니다.', 'labels': {'label': 4.2, 'real-label': 4.166666666666667, 'binary-label': 1}, 'annotations': {'agreement': '0:0:0:2:1:3', 'annotators': ['17', '14', '15', '03', '18', '12'], 'annotations': [5, 5, 3, 3, 5, 4]}}\n",
      "8899 {'guid': 'klue-sts-v1_train_08899', 'source': 'policy-rtt', 'sentence1': '이러한 불편해소를 위해\\xa0국내외 영업을 동시에 수행할 수 있는 국내외여행업이 신설된다.', 'sentence2': '이러한 불편함을 해소하기 위해 국내외 여행사를 설립하여 국내외 영업을 동시에 수행할 수 있도록 할 것입니다.', 'labels': {'label': 3.2, 'real-label': 3.2, 'binary-label': 1}, 'annotations': {'agreement': '0:0:0:4:1:0', 'annotators': ['02', '14', '05', '13', '18'], 'annotations': [3, 3, 3, 4, 3]}}\n",
      "8908 {'guid': 'klue-sts-v1_train_08908', 'source': 'policy-rtt', 'sentence1': '또\\xa0사과와 배 등 설 명절 16개 성수품의 공급을 최대 4.3배 늘리고 직거래 장터를 확대 개설한다.', 'sentence2': '그것은 또한 설 연휴 동안 16개의 고품질 제품의 공급을 최대 4.3배 늘리고 직접적인 시장을 확장할 예정입니다.', 'labels': {'label': 3.7, 'real-label': 3.666666666666667, 'binary-label': 1}, 'annotations': {'agreement': '0:0:0:2:4:0', 'annotators': ['17', '03', '19', '05', '13', '08'], 'annotations': [4, 3, 4, 4, 4, 3]}}\n",
      "8938 {'guid': 'klue-sts-v1_train_08938', 'source': 'policy-rtt', 'sentence1': '농림축산식품부가 27일\\xa0발표한 ‘김장채소 수급안정 대책’에 따르면 올해 4인 가구 기준 김장 규모는 21.9포기로 지난해 22.3포기보다 감소할 것으로\\xa0예상된다.', 'sentence2': \"농림축산식품부가 27일 발표한 '김장 채소 수급안정대책'에 따르면 올해 4인 가구 기준 김치 규모는 지난해 22.3개에서 21.9개로 줄어들 것으로 전망됩니다.\", 'labels': {'label': 4.2, 'real-label': 4.2, 'binary-label': 1}, 'annotations': {'agreement': '0:0:0:1:2:2', 'annotators': ['15', '02', '06', '18', '10'], 'annotations': [4, 3, 5, 5, 4]}}\n",
      "8972 {'guid': 'klue-sts-v1_train_08972', 'source': 'policy-sampled', 'sentence1': '이전 검사법(판코로나 검사)는 모든 코로나 바이러스를 먼저 선별한 후 신종코로나 바이러스 여부를 확인하는 2단계 절차로서\\xa0 소요시간이 길고(1~2일) 사용이 불편합니다.', 'sentence2': '이와 함께 기존의 유통업체(병협), 자체 판매 Mall(의협, 한의협), 택배(치협)를 활용하여 조달하는 방법이 병행될 예정', 'labels': {'label': 0.0, 'real-label': 0.0, 'binary-label': 0}, 'annotations': {'agreement': '5:0:0:0:0:0', 'annotators': ['09', '16', '04', '17', '03'], 'annotations': [0, 0, 0, 0, 0]}}\n",
      "9008 {'guid': 'klue-sts-v1_train_09008', 'source': 'policy-rtt', 'sentence1': '유흥시설 집합금지명령과 감염검사\\xa0명령 등 2종류의 행정명령을 모두 시행하고 있는 시·도는 인천, 대전, 울산, 세종, 경기, 충북, 충남, 경남 등 총 8개 지자체다.', 'sentence2': '인천, 대전, 울산, 세종, 경기, 충북, 충남, 경남 등 총 8개 지자체가 유흥업소 수거 금지 명령과 감염 검사를 포함한 2가지 유형의 행정명령을 시행하고 있습니다.', 'labels': {'label': 3.7, 'real-label': 3.666666666666667, 'binary-label': 1}, 'annotations': {'agreement': '0:0:1:1:3:1', 'annotators': ['03', '04', '07', '08', '10', '06'], 'annotations': [2, 3, 4, 5, 4, 4]}}\n",
      "9046 {'guid': 'klue-sts-v1_train_09046', 'source': 'policy-rtt', 'sentence1': '성능인증 및 시범구매제도 신청은 ‘공공구매 종합정보망(http://www.smpp.go.kr)’에서\\xa0신청할 수 있다.', 'sentence2': \"성과인증 및 시험구매 신청은 '공공구매정보망(http://www.smpp.go.kr)'을 통해 할 수 있습니다.\", 'labels': {'label': 3.6, 'real-label': 3.571428571428572, 'binary-label': 1}, 'annotations': {'agreement': '0:0:1:3:1:2', 'annotators': ['16', '12', '07', '03', '15', '18', '02'], 'annotations': [3, 5, 4, 3, 2, 3, 5]}}\n",
      "9172 {'guid': 'klue-sts-v1_train_09172', 'source': 'policy-rtt', 'sentence1': '1인당 연간\\xa048만원 범위 내에서 친환경농산물을 받을 수 있다.', 'sentence2': '1인당 연간 48만원 이내의 친환경 농산물을 받을 수 있습니다.', 'labels': {'label': 4.8, 'real-label': 4.833333333333333, 'binary-label': 1}, 'annotations': {'agreement': '0:0:0:0:1:5', 'annotators': ['16', '03', '15', '12', '10', '18'], 'annotations': [5, 5, 5, 5, 5, 4]}}\n",
      "9305 {'guid': 'klue-sts-v1_train_09305', 'source': 'policy-sampled', 'sentence1': '자상한 기업 7호인 삼성전자는 지난해 10월 소재·부품·장비 중심 스마트공장 고도화를 위한 업무협약을\\xa0중기부·중소기업중앙회와 체결한 바 있다.', 'sentence2': '또 국내기업과의 상생협력이나 국내 소재·부품·장비 산업경쟁력을 강화하는 데도 기여할 전망이다.', 'labels': {'label': 1.2, 'real-label': 1.166666666666667, 'binary-label': 0}, 'annotations': {'agreement': '2:1:3:0:0:0', 'annotators': ['14', '12', '15', '09', '08', '06'], 'annotations': [0, 1, 2, 2, 2, 0]}}\n",
      "9346 {'guid': 'klue-sts-v1_train_09346', 'source': 'policy-rtt', 'sentence1': '과학기술정보통신부와 개인정보보호위원회가 13일\\xa0‘안전한 데이터 활용과 디지털 뉴딜의 성공을 위한 업무협약식’을 개최했다.', 'sentence2': \"과학기술정보통신부와 개인정보보호위원회는 13일 '안전한 데이터 활용과 디지털 뉴딜의 성공을 위한 업무협약식'을 개최했습니다.\", 'labels': {'label': 4.7, 'real-label': 4.666666666666667, 'binary-label': 1}, 'annotations': {'agreement': '0:0:0:0:2:4', 'annotators': ['07', '13', '05', '18', '12', '06'], 'annotations': [5, 5, 4, 5, 5, 4]}}\n",
      "9503 {'guid': 'klue-sts-v1_train_09503', 'source': 'policy-sampled', 'sentence1': '유럽발(發) 입국자 검역 강화조치가 시행된\\xa0첫 날인 22일\\xa0유증상자 152명이 공항 격리시설에서 격리 및 진단검사를 받았다.', 'sentence2': '이 경우 격리 면제된 해외 기업인이 국내 입국 시 임시격리시설(1박 2일)에서 검사를 받은 후 검사결과 음성으로 판정될 경우 최종적으로 격리 면제가 이뤄진다.', 'labels': {'label': 1.2, 'real-label': 1.2, 'binary-label': 0}, 'annotations': {'agreement': '1:2:2:0:0:0', 'annotators': ['07', '15', '12', '10', '04'], 'annotations': [2, 1, 1, 2, 0]}}\n",
      "9551 {'guid': 'klue-sts-v1_train_09551', 'source': 'policy-rtt', 'sentence1': '대상은\\xa0 원양어선을 제외한 전체 어선이다.', 'sentence2': '대상은 심해 어선을 제외한 모든 어선입니다.', 'labels': {'label': 4.2, 'real-label': 4.2, 'binary-label': 1}, 'annotations': {'agreement': '0:0:0:1:2:2', 'annotators': ['14', '06', '10', '02', '12'], 'annotations': [4, 5, 3, 5, 4]}}\n",
      "9568 {'guid': 'klue-sts-v1_train_09568', 'source': 'policy-sampled', 'sentence1': '조사결과 우선\\xa0 신성약품·디엘팜에서의 보관 과정은 적정온도(2~8℃)가 유지된 것으로 확인됐다.', 'sentence2': '지급 방식은 지자체가 활용 중인 지역상품권이나 전자화폐 등으로 현금은 배제됐다', 'labels': {'label': 0.0, 'real-label': 0.0, 'binary-label': 0}, 'annotations': {'agreement': '7:0:0:0:0:0', 'annotators': ['07', '14', '02', '09', '10', '06', '19'], 'annotations': [0, 0, 0, 0, 0, 0, 0]}}\n",
      "9615 {'guid': 'klue-sts-v1_train_09615', 'source': 'policy-rtt', 'sentence1': '아파트 등 공동주택의 날림, 부실 마감공사로 인한\\xa0하자를 줄이기\\xa0위해 감리자의 공정 관리가 강화된다.', 'sentence2': '아파트 건설과 부실 마감으로 인한 결함을 줄이기 위해 감독관들의 공정 관리가 강화될 것입니다.', 'labels': {'label': 3.7, 'real-label': 3.714285714285714, 'binary-label': 1}, 'annotations': {'agreement': '0:0:0:3:3:1', 'annotators': ['14', '03', '05', '18', '04', '08', '10'], 'annotations': [5, 3, 3, 4, 4, 3, 4]}}\n",
      "9782 {'guid': 'klue-sts-v1_train_09782', 'source': 'policy-sampled', 'sentence1': '이번 방안에 따라 우선\\xa0비상장 벤처기업의 창업주에게 1주당 최대 10개의 복수의결권 발행을 허용한다.', 'sentence2': '또 벤처기업이 상장하면 복수의결권 주식이 보통주로 전환된다.', 'labels': {'label': 0.9, 'real-label': 0.8571428571428571, 'binary-label': 0}, 'annotations': {'agreement': '2:4:1:0:0:0', 'annotators': ['17', '12', '04', '07', '19', '14', '05'], 'annotations': [0, 1, 2, 1, 1, 0, 1]}}\n",
      "9791 {'guid': 'klue-sts-v1_train_09791', 'source': 'policy-rtt', 'sentence1': '한편\\xa0유럽 등 해외 입국자 증가를 대비해 해외 입국 경증 확진자를 위한 생활치료센터 2개소(경기국제1, 경기국제2)를 25일부터 운영한다.', 'sentence2': '한편 유럽 등 외국인 입국자 증가에 대비해 25일부터 생활치료센터 2곳(경기국제1, 경기국제2)을 운영합니다.', 'labels': {'label': 3.7, 'real-label': 3.666666666666667, 'binary-label': 1}, 'annotations': {'agreement': '0:0:0:2:4:0', 'annotators': ['16', '13', '17', '06', '09', '12'], 'annotations': [3, 3, 4, 4, 4, 4]}}\n",
      "9795 {'guid': 'klue-sts-v1_train_09795', 'source': 'policy-rtt', 'sentence1': '교육부는 정부의 ‘강력한 사회적 거리두기’의 후속조치로\\xa0이 같은 내용의 ‘학교 안팎 고강도 사회적 거리두기’ 추진방안을 24일 발표했다.', 'sentence2': '교육부는 정부의 \"강력한 사회적 거리\"에 대한 후속 조치로 \"고강도 학교 내외의 사회적 거리\"를 홍보할 계획을 24일 발표했습니다.', 'labels': {'label': 3.5, 'real-label': 3.5, 'binary-label': 1}, 'annotations': {'agreement': '0:0:0:3:3:0', 'annotators': ['07', '03', '15', '10', '08', '19'], 'annotations': [3, 3, 3, 4, 4, 4]}}\n",
      "9822 {'guid': 'klue-sts-v1_train_09822', 'source': 'policy-sampled', 'sentence1': '이는 코로나19 확산에 따른 재택근무, 자가격리 등의 이유로 과제계획 수립 등 준비가 원활하지 않은 창업기업의 애로를 해소하기 위한\\xa0조치다.', 'sentence2': '공공조달에서 중소기업이 우대받는 생태계를 조성하고, 창업기업의 초기 판로 확보를 지원하기 위한 것입니다.', 'labels': {'label': 0.8, 'real-label': 0.8333333333333334, 'binary-label': 0}, 'annotations': {'agreement': '3:1:2:0:0:0', 'annotators': ['02', '13', '14', '03', '05', '18'], 'annotations': [0, 2, 0, 2, 0, 1]}}\n",
      "9834 {'guid': 'klue-sts-v1_train_09834', 'source': 'policy-sampled', 'sentence1': '원격수업: 실시간 쌍방향 수업, 콘텐츠 활용 중심 수업, 과제 중심 수업 등\\xa0', 'sentence2': '콘텐츠 활용 중심 수업과 과제 수행 중심은 LMS(학습관리시스템) 등을 활용하여 진도율, 접속 기록 등으로 확인합니다.', 'labels': {'label': 1.7, 'real-label': 1.666666666666667, 'binary-label': 0}, 'annotations': {'agreement': '1:0:5:0:0:0', 'annotators': ['17', '13', '10', '02', '09', '15'], 'annotations': [0, 2, 2, 2, 2, 2]}}\n",
      "10010 {'guid': 'klue-sts-v1_train_10010', 'source': 'policy-sampled', 'sentence1': '대전의\\xa0지역대표 제과업체인 ‘성심당’과 서울 광진구의 평양냉면 전문식당 ‘서북면옥’이 백년가게로 선정됐다.', 'sentence2': '이로써 전국의 백년가게는 모두 636개로 늘어났다.', 'labels': {'label': 0.5, 'real-label': 0.5, 'binary-label': 0}, 'annotations': {'agreement': '4:1:1:0:0:0', 'annotators': ['02', '16', '17', '06', '03', '13'], 'annotations': [0, 0, 0, 0, 2, 1]}}\n",
      "10020 {'guid': 'klue-sts-v1_train_10020', 'source': 'policy-rtt', 'sentence1': '정부가 2021~2022년\\xa0전국 11만 4000가구, 수도권 7만가구의 전세형 주택을 추가공급 하기로 했다.', 'sentence2': '정부는 2021년에서 2022년 사이에 전국 11만 4천 가구와 수도권 7만 가구에 임대주택을 추가로 공급하기로 결정했습니다.', 'labels': {'label': 3.4, 'real-label': 3.428571428571428, 'binary-label': 1}, 'annotations': {'agreement': '0:0:2:1:3:1', 'annotators': ['03', '13', '19', '16', '10', '09', '12'], 'annotations': [2, 4, 2, 3, 4, 4, 5]}}\n",
      "10307 {'guid': 'klue-sts-v1_train_10307', 'source': 'policy-sampled', 'sentence1': '예비 데이터베이스에 포함된 소상공인에게는\\xa0이날 14시부터 순차적으로 문자메시지를 발송, 확인지급 신청을 안내할 계획이다.', 'sentence2': '또 고혈압과 당뇨병 복합질환자에게는 혈압계와 혈당계를 모두 지급할 계획이다.', 'labels': {'label': 0.0, 'real-label': 0.0, 'binary-label': 0}, 'annotations': {'agreement': '6:0:0:0:0:0', 'annotators': ['17', '04', '19', '05', '08', '13'], 'annotations': [0, 0, 0, 0, 0, 0]}}\n",
      "10335 {'guid': 'klue-sts-v1_train_10335', 'source': 'policy-rtt', 'sentence1': '전라남도는\\xa0지역균형 뉴딜 모델로 ‘신안 8.2GW\\xa0해상풍력 발전단지 조성을 통한 그린뉴딜 전남형 상생일자리 사업’을\\xa0전면에 내세웠다.', 'sentence2': '전라남도는 신안 8.2 창출을 통해 전남형 녹색 뉴딜 상생 일자리 사업을 추진했습니다.GW 해상 풍력 발전 단지는 지역 균형잡힌 뉴딜 모델로서 선두에 서 있습니다.', 'labels': {'label': 3.3, 'real-label': 3.333333333333333, 'binary-label': 1}, 'annotations': {'agreement': '0:0:1:2:3:0', 'annotators': ['02', '03', '05', '12', '08', '15'], 'annotations': [4, 4, 3, 4, 3, 2]}}\n",
      "10438 {'guid': 'klue-sts-v1_train_10438', 'source': 'policy-sampled', 'sentence1': '예상되는 주요 혜택으로는 ▲주요 수출품 관세 인하\\xa0 ▲단일 원산지 기준으로 관리 용이 ▲우리기업 지재권 보호 등을 들 수 있다.', 'sentence2': '진단검사는 7일 기준으로 124개의 보건소에서 받을 수 있다.', 'labels': {'label': 0.0, 'real-label': 0.0, 'binary-label': 0}, 'annotations': {'agreement': '6:0:0:0:0:0', 'annotators': ['19', '09', '08', '18', '13', '07'], 'annotations': [0, 0, 0, 0, 0, 0]}}\n",
      "10495 {'guid': 'klue-sts-v1_train_10495', 'source': 'policy-rtt', 'sentence1': '앞으로 보험회사가 금리인하요구권을 알리지 않은 경우 그 보험회사에\\xa0최고 1000만원의 과태료가 부과된다.', 'sentence2': '앞으로 보험사가 요금인하요구권을 알리지 않으면 1000만 원 이하의 과태료가 부과됩니다.', 'labels': {'label': 3.8, 'real-label': 3.833333333333333, 'binary-label': 1}, 'annotations': {'agreement': '0:0:0:2:3:1', 'annotators': ['13', '03', '05', '04', '06', '09'], 'annotations': [5, 3, 4, 4, 3, 4]}}\n",
      "10497 {'guid': 'klue-sts-v1_train_10497', 'source': 'policy-rtt', 'sentence1': '이\\xa0마스크는 사회적 약자와 현장 업무를 수행하는 근무자 등에게 우선 배부될 예정이다.', 'sentence2': '마스크는 먼저 사회적 약자와 현장 작업을 수행하는 근로자에게 배포될 것입니다.', 'labels': {'label': 4.2, 'real-label': 4.166666666666667, 'binary-label': 1}, 'annotations': {'agreement': '0:0:0:2:1:3', 'annotators': ['07', '13', '19', '09', '18', '06'], 'annotations': [4, 5, 5, 5, 3, 3]}}\n",
      "10505 {'guid': 'klue-sts-v1_train_10505', 'source': 'policy-sampled', 'sentence1': '우선 국토부는 지방의 대학과 철도역세권 등 잠재적인 성장거점에 산업과 주거, 문화가 융복합된 거점을 조성하는 ‘지방도심형 기업혁신특구(가칭)’을 새롭게\\xa0추진한다.', 'sentence2': '기업가치 1000억원 이상 규모인 ‘예비 유니콘’ 기업에 대해서는 최대 100억원까지 특례보증을 제공하는 등 ‘K-유니콘 프로젝트’를\\xa0본격 추진한다.', 'labels': {'label': 0.2, 'real-label': 0.1666666666666667, 'binary-label': 0}, 'annotations': {'agreement': '5:1:0:0:0:0', 'annotators': ['17', '19', '10', '09', '08', '12'], 'annotations': [0, 0, 0, 0, 1, 0]}}\n",
      "10552 {'guid': 'klue-sts-v1_train_10552', 'source': 'policy-rtt', 'sentence1': '대책반은 종합상황반, 항공반, 철도반, 대중·화물반, 도로반\\xa0등 5개 반으로 구성됐다.', 'sentence2': '대책반은 종합상황팀, 항공팀, 철도팀, 공공 및 화물팀, 도로팀 등 5개반으로 구성되어 있습니다.', 'labels': {'label': 4.4, 'real-label': 4.4, 'binary-label': 1}, 'annotations': {'agreement': '0:0:0:0:3:2', 'annotators': ['19', '15', '06', '08', '13'], 'annotations': [5, 4, 4, 4, 5]}}\n",
      "10626 {'guid': 'klue-sts-v1_train_10626', 'source': 'policy-rtt', 'sentence1': '경남 통영 연명어촌체험휴양마을은\\xa0다양한 생선요리가 자랑거리이다.', 'sentence2': '경상남도 통영의 연명 어촌은 다양한 생선 요리를 자랑합니다.', 'labels': {'label': 3.8, 'real-label': 3.833333333333333, 'binary-label': 1}, 'annotations': {'agreement': '0:0:0:2:3:1', 'annotators': ['17', '07', '12', '04', '02', '08'], 'annotations': [4, 3, 5, 4, 4, 3]}}\n",
      "10630 {'guid': 'klue-sts-v1_train_10630', 'source': 'policy-rtt', 'sentence1': '또한 정보통신 산업 도메인 특성을 반영한 테마별 컨퍼런스 및 포럼이\\xa0플랫폼을 통해 온라인으로 동시 개최된다.', 'sentence2': '또한, 정보통신 산업의 영역 특성을 반영한 주제별 컨퍼런스 및 포럼이 플랫폼을 통해 동시에 온라인 상에서 개최될 예정입니다.', 'labels': {'label': 4.2, 'real-label': 4.166666666666667, 'binary-label': 1}, 'annotations': {'agreement': '0:0:0:1:3:2', 'annotators': ['15', '03', '13', '06', '08', '10'], 'annotations': [5, 3, 5, 4, 4, 4]}}\n",
      "10721 {'guid': 'klue-sts-v1_train_10721', 'source': 'policy-rtt', 'sentence1': '지난 1990년 핀란드에서 처음 도입한 ‘탄소세’를 온실가스 저감\\xa0수단으로 활용하려는 각국의 움직임도 활발하다.', 'sentence2': \"각국은 또한 온실 가스 배출을 줄이기 위한 수단으로 1990년 핀란드에서 처음 도입된 '탄소 세금'을 적극적으로 사용하려고 하고 있습니다.\", 'labels': {'label': 2.1, 'real-label': 2.142857142857143, 'binary-label': 0}, 'annotations': {'agreement': '2:0:1:3:1:0', 'annotators': ['05', '02', '04', '12', '06', '08', '10'], 'annotations': [0, 3, 3, 3, 4, 2, 0]}}\n",
      "11156 {'guid': 'klue-sts-v1_train_11156', 'source': 'policy-rtt', 'sentence1': '이에 따라\\xa018일부터 내년 3월말까지 종이문서 발급양이 가장 많은 주민등록등초본을 대상으로 발급·제출 시범서비스를 시행한다.', 'sentence2': '이에 따라 18일부터 내년 3월말까지 주민등록초본에 종이문서가 가장 많이 발급되는 시범서비스가 발급되어 제출될 예정입니다.', 'labels': {'label': 4.4, 'real-label': 4.4, 'binary-label': 1}, 'annotations': {'agreement': '0:0:0:0:3:2', 'annotators': ['02', '06', '12', '10', '19'], 'annotations': [5, 4, 5, 4, 4]}}\n",
      "11195 {'guid': 'klue-sts-v1_train_11195', 'source': 'policy-rtt', 'sentence1': '최근 코로나19로 원격학습의 필요성이 늘어나면서 저소득층 학생 대상 교육콘텐츠 지원 사업의 대상과 범위가\\xa0확대된다.', 'sentence2': '최근 코로나19와 함께 원격학습의 필요성이 증대됨에 따라 저소득층 학생들을 위한 교육 콘텐츠 지원 사업의 대상과 범위가 확대될 것입니다.', 'labels': {'label': 4.3, 'real-label': 4.285714285714286, 'binary-label': 1}, 'annotations': {'agreement': '0:0:0:1:3:3', 'annotators': ['07', '03', '02', '09', '19', '05', '08'], 'annotations': [5, 4, 5, 5, 4, 4, 3]}}\n",
      "11225 {'guid': 'klue-sts-v1_train_11225', 'source': 'policy-sampled', 'sentence1': '중소벤처기업부 등 17개 부처가 마련한\\xa0방안은\\xa0코로나19 피해기업 지원과 농업·신산업 등 업종별 자금조달 및 상생협력 등\\xa0단계별 기업활동 지원 대책이 담겼다.', 'sentence2': '문체부 등 각 부처 지원 사업 안내…코로나19 피해 상담 등 통합창구 개설', 'labels': {'label': 0.7, 'real-label': 0.7142857142857143, 'binary-label': 0}, 'annotations': {'agreement': '3:3:1:0:0:0', 'annotators': ['04', '06', '05', '03', '15', '13', '10'], 'annotations': [0, 2, 0, 1, 1, 1, 0]}}\n",
      "11231 {'guid': 'klue-sts-v1_train_11231', 'source': 'policy-sampled', 'sentence1': '올해는 도로교통법 개정을 추진해\\xa0어린이 관련 시설에서 운영하는 차량의 통학버스 신고의무 대상에 적극 포함시킨다.', 'sentence2': '대의명분을 중요하게 여긴 유비의 덕치와 제갈량의 충의는 동양의 정신입니다.', 'labels': {'label': 0.0, 'real-label': 0.0, 'binary-label': 0}, 'annotations': {'agreement': '7:0:0:0:0:0', 'annotators': ['17', '03', '04', '06', '18', '08', '10'], 'annotations': [0, 0, 0, 0, 0, 0, 0]}}\n",
      "11358 {'guid': 'klue-sts-v1_train_11358', 'source': 'policy-rtt', 'sentence1': '외교부가 3일 국민 생명과 안전을 보호하는 내용의\\xa02020년 주요업무 추진계획을 발표했다.', 'sentence2': '외교부는 국민의 생명과 안전을 보호하기 위해 2020년에 주요 업무를 수행할 계획이라고 3일 발표했습니다.', 'labels': {'label': 4.3, 'real-label': 4.285714285714286, 'binary-label': 1}, 'annotations': {'agreement': '0:0:0:0:5:2', 'annotators': ['10', '19', '14', '05', '02', '06', '09'], 'annotations': [4, 4, 5, 4, 5, 4, 4]}}\n",
      "11362 {'guid': 'klue-sts-v1_train_11362', 'source': 'policy-rtt', 'sentence1': '우리 경제가 어려울 때마다\\xa0늘 마지막 파수꾼이었던 재정이 이번에도\\xa0코로나19의 거센 파고를 막는 방파제 역할을 하겠다는 강한 의지를 담았다는 설명이다.', 'sentence2': '한국 경제가 어려울 때마다 항상 마지막 감시탑이었던 금융은 코로나19의 거센 물결을 막기 위한 방파제 역할을 하겠다는 의지가 강하다는 설명입니다.', 'labels': {'label': 3.7, 'real-label': 3.666666666666667, 'binary-label': 1}, 'annotations': {'agreement': '0:0:0:3:2:1', 'annotators': ['17', '04', '09', '03', '02', '19'], 'annotations': [4, 3, 3, 3, 5, 4]}}\n",
      "11556 {'guid': 'klue-sts-v1_train_11556', 'source': 'policy-sampled', 'sentence1': '대전시가 제시한\\xa0인공지능 기반 K-지능형도시 모델이 지역균형 뉴딜의 우수 사례로 선정됐습니다.', 'sentence2': '충북 단양군의 역사문화길과 충남\\xa0서천군의 장항도시탐험역이 올해 지역정책 최우수사업으로 선정됐다.', 'labels': {'label': 0.4, 'real-label': 0.4285714285714285, 'binary-label': 0}, 'annotations': {'agreement': '4:3:0:0:0:0', 'annotators': ['09', '14', '13', '05', '12', '19', '10'], 'annotations': [0, 0, 1, 0, 1, 1, 0]}}\n",
      "11581 {'guid': 'klue-sts-v1_train_11581', 'source': 'policy-rtt', 'sentence1': '약\\xa0230만명의 저임금 근로자를 계속 고용하는 영세사업장에는 4개월 동안 한시적으로 임금을 보조해 경영부담 완화 및 근로자 고용안정을 도모한다.', 'sentence2': '약 230만 명의 저임금 노동자를 계속 고용하고 있는 중소기업들은 경영 부담을 완화하고 근로자의 고용을 안정시키기 위해 4개월 동안 일시적으로 임금을 보조할 예정입니다.', 'labels': {'label': 3.9, 'real-label': 3.857142857142857, 'binary-label': 1}, 'annotations': {'agreement': '0:0:0:2:4:1', 'annotators': ['15', '19', '02', '09', '18', '06', '08'], 'annotations': [4, 4, 3, 4, 5, 4, 3]}}\n"
     ]
    }
   ],
   "source": [
    "for idx, i in enumerate(data):\n",
    "    if \"\\xa0\" in i['sentence1']:\n",
    "        print(idx, i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "66366000",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'올해 35개 기업연구소가\\xa0공모 결과 우수 기업연구소로 선정됐다.'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "re.sub(r'\\[a-z0-9]+', '', data[7666]['sentence1'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9901c301",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'올해 35개 기업연구소가공모 결과 우수 기업연구소로 선정됐다.'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "re.sub(r'\\xa0', '', data[7666]['sentence1'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cd56f4aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import unicodedata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ab649885",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'올해 35개 기업연구소가 공모 결과 우수 기업연구소로 선정됐다.'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unicodedata.normalize(\"NFKD\", data[7666]['sentence1'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "085e91b7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7e24118a",
   "metadata": {},
   "outputs": [],
   "source": [
    "shape = np.full([len(data), 3], np.nan)\n",
    "df = pd.DataFrame(shape, columns=['sentence1', 'sentence2', 'label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7e7d92da",
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx, el in enumerate(data):\n",
    "    df.loc[idx] = [el['sentence1'], el['sentence2'], el['labels']['real-label']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fbb7a360",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence1</th>\n",
       "      <th>sentence2</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>사례집은 국립환경과학원 누리집(ecolibrary.me.go.kr)에서 12일부터 ...</td>\n",
       "      <td>주말을 제외한 평일 오후 12시 30분부터 문예회관 공식 페이스북과 유튜브에서는 지...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           sentence1  \\\n",
       "7  사례집은 국립환경과학원 누리집(ecolibrary.me.go.kr)에서 12일부터 ...   \n",
       "\n",
       "                                           sentence2  label  \n",
       "7  주말을 제외한 평일 오후 12시 30분부터 문예회관 공식 페이스북과 유튜브에서는 지...    0.0  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.loc[7:7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "017ef7d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[['sentence1', 'sentence2']] = df[['sentence1', 'sentence2']].applymap(data_qc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "cda9a376",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence1</th>\n",
       "      <th>sentence2</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>사례집은 국립환경과학원 누리집에서 12일부터 볼 수 있다.</td>\n",
       "      <td>주말을 제외한 평일 오후 12시 30분부터 문예회관 공식 페이스북과 유튜브에서는 지...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          sentence1  \\\n",
       "7  사례집은 국립환경과학원 누리집에서 12일부터 볼 수 있다.   \n",
       "\n",
       "                                           sentence2  label  \n",
       "7  주말을 제외한 평일 오후 12시 30분부터 문예회관 공식 페이스북과 유튜브에서는 지...    0.0  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.loc[7:7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2366a501",
   "metadata": {},
   "outputs": [],
   "source": [
    "train, valid = train_test_split(df, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "db183d7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "del data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef8934a2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "54ec634e",
   "metadata": {},
   "source": [
    "### read config files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25fb0fbe",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5fd18e7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "conf_info = Config(f\"./config_files/config_subchar12367_bert.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a2ffdf9b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "with open(\"./config_files/config_subchar12367_bert.json\", \"rt\", encoding=\"utf8\") as f:\n",
    "    conf_subchar = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1bcfd6bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'config': 'config_files/bert_config_subchar12367.json',\n",
       " 'bert': 'torch_model/pytorch_model_subchar12367_bert.bin',\n",
       " 'tokenizer': 'config_files/vocab_snu_subchar12367.txt',\n",
       " 'vocab': 'config_files/vocab_snu_subchar12367.pkl'}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conf_subchar"
   ]
  },
  {
   "cell_type": "raw",
   "id": "9e242058",
   "metadata": {},
   "source": [
    "conf_subchar['bert'] = 'torch_model/pytorch_model_subchar12367_bert.bin'"
   ]
  },
  {
   "cell_type": "raw",
   "id": "22c8f769",
   "metadata": {},
   "source": [
    "conf_subchar"
   ]
  },
  {
   "cell_type": "raw",
   "id": "922a3c29",
   "metadata": {},
   "source": [
    "with open(\"./config_files/config_subchar12367_bert.json\", \"wt\", encoding=\"utf8\") as f:\n",
    "    json.dump(conf_subchar, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1553fe78",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e060c1ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HwaLang\\miniconda3\\envs\\wanted\\lib\\site-packages\\transformers\\tokenization_utils_base.py:1643: FutureWarning: Calling BertTokenizer.from_pretrained() with the path to a single file or url is deprecated and won't be possible anymore in v5. Use a model identifier or the path to a directory instead.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "tokenizer_krbert_sub = BertTokenizer.from_pretrained(f\"{conf_info.tokenizer}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "409c3bf0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['숙소',\n",
       " '위치',\n",
       " '##는',\n",
       " '찾기',\n",
       " '쉬',\n",
       " '##ᆸ',\n",
       " '##고',\n",
       " '일반적인',\n",
       " '한국의',\n",
       " '반',\n",
       " '##지',\n",
       " '##하',\n",
       " '숙소',\n",
       " '##입니다',\n",
       " '.']"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer_krbert_sub.tokenize(df['sentence1'].loc[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfd112aa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb4f7af4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "7f763144",
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_collate_fn(batch):\n",
    "    input_list, target_list = [], []\n",
    "    \n",
    "    for _input, _target in batch:\n",
    "        input_list.append(_input)\n",
    "        target_list.append(_target)\n",
    "    \n",
    "    tensorized_input = tokenizer_krbert_sub(\n",
    "        input_list,\n",
    "        add_special_tokens=True,\n",
    "        padding=\"longest\",\n",
    "        truncation=True,\n",
    "        max_length=128,\n",
    "        return_tensors='pt'\n",
    "    )\n",
    "    \n",
    "    tensorized_label = torch.tensor(target_list, dtype = torch.float)\n",
    "    \n",
    "    return tensorized_input, tensorized_label\n",
    "\n",
    "\n",
    "class CustomDataset(Dataset):\n",
    "    \"\"\"\n",
    "    - input_data: list of string\n",
    "    - target_data: list of int\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, input_data:list, target_data:list) -> None:\n",
    "        self.X = input_data\n",
    "        self.Y = target_data\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        X = self.X[index]\n",
    "        Y = self.Y[index]\n",
    "        return X, Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ec84aa08",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FCLayer(torch.nn.Module):\n",
    "    def __init__(self, input_dim, output_dim, dropout_rate=0.0, use_activation=None):\n",
    "        super(FCLayer, self).__init__()\n",
    "        self.use_activation = use_activation\n",
    "        self.dropout = torch.nn.Dropout(dropout_rate)\n",
    "        self.linear = torch.nn.Linear(input_dim, output_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.dropout(x)\n",
    "        if self.use_activation:\n",
    "            x = self.use_activation(x)\n",
    "        return self.linear(x)\n",
    "\n",
    "\n",
    "class BertSts(BertPreTrainedModel):\n",
    "    def __init__(self, config) -> None:\n",
    "        super(BertSts, self).__init__(config)\n",
    "        self.bert = BertModel(config)\n",
    "        self.Dense = FCLayer(config.hidden_size, config.hidden_size, config.hidden_dropout_prob)\n",
    "        self.output_layer = FCLayer(config.hidden_size, 1)\n",
    "\n",
    "\n",
    "    def forward(self, input_ids=None, attention_mask=None, token_type_ids=None):\n",
    "        bert_outputs = self.bert(input_ids=input_ids, attention_mask=attention_mask, token_type_ids=token_type_ids)\n",
    "        dense_outputs = self.Dense(bert_outputs['pooler_output'])\n",
    "        sim_score = self.output_layer(dense_outputs)\n",
    "        return sim_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "7c4cfa47",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'torch_model/pytorch_model_subchar12367_bert.bin'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conf_info.bert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "25982eb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = BertConfig(conf_info.bert)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "8048191a",
   "metadata": {},
   "outputs": [],
   "source": [
    "config.vocab_size = 12367"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "9d42be61",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = BertSts(config = config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "400bea88",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BertSts(\n",
       "  (bert): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(12367, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (1): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (2): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (3): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (4): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (5): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (6): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (7): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (8): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (9): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (10): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (11): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): BertPooler(\n",
       "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (Dense): FCLayer(\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "    (linear): Linear(in_features=768, out_features=768, bias=True)\n",
       "  )\n",
       "  (output_layer): FCLayer(\n",
       "    (dropout): Dropout(p=0.0, inplace=False)\n",
       "    (linear): Linear(in_features=768, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6aee73e0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "783c83f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = torch.load(conf_info.bert)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "83fc8c7d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('사례집은 국립환경과학원 누리집에서 12일부터 볼 수 있다.',\n",
       " '주말을 제외한 평일 오후 12시 30분부터 문예회관 공식 페이스북과 유튜브에서는 지역 예술인들이 중심이 된 서양음악, 국악, 댄스 등의 공연을 실시간으로 감상할 수 있다.')"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.loc[7]['sentence1'], df.loc[7]['sentence2']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "eb2de616",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': [2, 2238, 518, 17, 2591, 3641, 3552, 80, 4891, 518, 23, 181, 828, 594, 33, 30, 5, 3, 3141, 6, 3634, 967, 22, 244, 181, 50, 281, 171, 230, 268, 615, 129, 187, 991, 2561, 24, 5641, 282, 463, 2329, 4809, 1818, 12, 698, 7052, 5401, 8, 644, 1329, 8, 5822, 646, 1078, 6, 4998, 28, 1509, 160, 49, 33, 30, 5, 3], 'token_type_ids': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer_krbert_sub(df.loc[7]['sentence1'], df.loc[7]['sentence2'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "b5d2cd7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "param_names = []\n",
    "\n",
    "for name, param in model.named_parameters():\n",
    "    param_names.append(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19353113",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "98293521",
   "metadata": {},
   "outputs": [],
   "source": [
    "from copy import deepcopy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "b8163c3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "weight_dict = deepcopy(model.state_dict())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "cf3190b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "for name, weight in weights.items():\n",
    "    if name in param_names:\n",
    "        weight_dict[name] = weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "5bba4bed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.load_state_dict(weight_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "8356bed7",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "226193bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = CustomDataset(train.iloc[:, :2].values.tolist(), train['label'].tolist())\n",
    "valid_dataset = CustomDataset(valid.iloc[:, :2].values.tolist(), valid['label'].tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "2af962cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader = DataLoader(train_dataset,\n",
    "                              batch_size = batch_size,\n",
    "                              sampler = RandomSampler(train_dataset),\n",
    "                              collate_fn = custom_collate_fn)\n",
    "\n",
    "valid_dataloader = DataLoader(valid_dataset,\n",
    "                              batch_size = batch_size,\n",
    "                              sampler = RandomSampler(valid_dataset),\n",
    "                              collate_fn = custom_collate_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdaa01a1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "ab461bb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fct = torch.nn.MSELoss()\n",
    "\n",
    "def train(model, train_dataloader, valid_dataloader=None, epochs=2):\n",
    "        global loss_fct, scheduler\n",
    "        \n",
    "        for epoch in range(epochs):\n",
    "            print(f\"*****Epoch {epoch} Train Start*****\")\n",
    "            \n",
    "            total_loss, batch_loss, batch_count = 0,0,0\n",
    "        \n",
    "            model.train()\n",
    "            model.to(device)\n",
    "            \n",
    "            for step, batch in enumerate(train_dataloader):\n",
    "                batch_count+=1\n",
    "                \n",
    "                batch = tuple(item.to(device) for item in batch)\n",
    "            \n",
    "                batch_input, batch_label = batch\n",
    "                \n",
    "                model.zero_grad()\n",
    "            \n",
    "                logits = model(**batch_input)\n",
    "\n",
    "                loss = loss_fct(logits.view(-1), batch_label.view(-1))\n",
    "                \n",
    "                batch_loss += loss.item()\n",
    "                total_loss += loss.item()\n",
    "            \n",
    "                loss.backward()\n",
    "                \n",
    "                clip_grad_norm_(model.parameters(), 1.0)\n",
    "                \n",
    "                optimizer.step()\n",
    "                scheduler.step()\n",
    "                \n",
    "                if (step % 10 == 0 and step != 0):\n",
    "                    learning_rate = optimizer.param_groups[0]['lr']\n",
    "                    print(f\"Epoch: {epoch}, Step : {step}, LR : {learning_rate}, Avg Loss : {batch_loss / batch_count:.4f}\")\n",
    "\n",
    "                    batch_loss, batch_count = 0,0\n",
    "\n",
    "            print(f\"Epoch {epoch} Total Mean Loss : {total_loss/(step+1):.4f}\")\n",
    "            print(f\"*****Epoch {epoch} Train Finish*****\\n\")\n",
    "            \n",
    "            if valid_dataloader:\n",
    "                print(f\"*****Epoch {epoch} Valid Start*****\")\n",
    "                valid_loss = validate(model, valid_dataloader)\n",
    "                print(f\"Epoch {epoch} Valid Loss : {valid_loss:.4f}\")\n",
    "                print(f\"*****Epoch {epoch} Valid Finish*****\\n\")\n",
    "            \n",
    "#             save_checkpoint(\".\", model, optimizer, scheduler, epoch, total_loss/(step+1))\n",
    "                \n",
    "        print(\"Train Completed. End Program.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "58051576",
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate(model, valid_dataloader):\n",
    "   \n",
    "    # 모델을 evaluate 모드로 설정 & device 할당\n",
    "    model.eval()\n",
    "    model.to(device)\n",
    "    \n",
    "    total_loss = 0\n",
    "        \n",
    "    for step, batch in enumerate(valid_dataloader):\n",
    "        \n",
    "        # tensor 연산 전, 각 tensor에 device 할당\n",
    "        batch = tuple(item.to(device) for item in batch)\n",
    "            \n",
    "        batch_input, batch_label = batch\n",
    "            \n",
    "        # gradient 계산하지 않음\n",
    "        with torch.no_grad():\n",
    "            logits = model(**batch_input)\n",
    "            \n",
    "        # loss\n",
    "        loss = loss_fct(logits.view(-1), batch_label.view(-1))\n",
    "        total_loss += loss.item()\n",
    "        \n",
    "    total_loss = total_loss/(step+1)\n",
    "\n",
    "    return total_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "ed191fab",
   "metadata": {},
   "outputs": [],
   "source": [
    "def initializer(train_dataloader, epochs=2):\n",
    "    \"\"\"\n",
    "    모델, 옵티마이저, 스케쥴러 초기화\n",
    "    \"\"\"\n",
    "\n",
    "    optimizer = AdamW(\n",
    "        model.parameters(),\n",
    "        lr=2e-5,\n",
    "        eps=1e-8\n",
    "    )\n",
    "    \n",
    "    total_steps = len(train_dataloader) * epochs\n",
    "    print(f\"Total train steps with {epochs} epochs: {total_steps}\")\n",
    "\n",
    "    scheduler = get_cosine_with_hard_restarts_schedule_with_warmup(\n",
    "        optimizer, \n",
    "        num_warmup_steps = 0,\n",
    "        num_training_steps = total_steps\n",
    "    )\n",
    "\n",
    "    return optimizer, scheduler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "641e93a4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# available GPUs : 1\n",
      "GPU name : GeForce RTX 3070\n",
      "cuda\n"
     ]
    }
   ],
   "source": [
    "# device type\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "    print(f\"# available GPUs : {torch.cuda.device_count()}\")\n",
    "    print(f\"GPU name : {torch.cuda.get_device_name()}\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "4542e210",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import get_linear_schedule_with_warmup, get_constant_schedule, get_cosine_with_hard_restarts_schedule_with_warmup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "fb1b40a4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total train steps with 2 epochs: 584\n",
      "*****Epoch 0 Train Start*****\n",
      "Epoch: 0, Step : 10, LR : 1.9982497394784285e-05, Avg Loss : 6.6261\n",
      "Epoch: 0, Step : 20, LR : 1.9936258727371667e-05, Avg Loss : 1.3261\n",
      "Epoch: 0, Step : 30, LR : 1.9861273081163116e-05, Avg Loss : 0.8416\n",
      "Epoch: 0, Step : 40, LR : 1.9757757400064857e-05, Avg Loss : 0.5864\n",
      "Epoch: 0, Step : 50, LR : 1.9626011169343043e-05, Avg Loss : 0.4091\n",
      "Epoch: 0, Step : 60, LR : 1.9466415549171235e-05, Avg Loss : 0.4376\n",
      "Epoch: 0, Step : 70, LR : 1.9279432271880972e-05, Avg Loss : 0.3990\n",
      "Epoch: 0, Step : 80, LR : 1.9065602306105914e-05, Avg Loss : 0.4192\n",
      "Epoch: 0, Step : 90, LR : 1.8825544291684332e-05, Avg Loss : 0.3561\n",
      "Epoch: 0, Step : 100, LR : 1.855995274984798e-05, Avg Loss : 0.3343\n",
      "Epoch: 0, Step : 110, LR : 1.8269596073875555e-05, Avg Loss : 0.3021\n",
      "Epoch: 0, Step : 120, LR : 1.7955314306024055e-05, Avg Loss : 0.3402\n",
      "Epoch: 0, Step : 130, LR : 1.7618016707169658e-05, Avg Loss : 0.3046\n",
      "Epoch: 0, Step : 140, LR : 1.7258679126189515e-05, Avg Loss : 0.3057\n",
      "Epoch: 0, Step : 150, LR : 1.6878341176695196e-05, Avg Loss : 0.3582\n",
      "Epoch: 0, Step : 160, LR : 1.6478103229285868e-05, Avg Loss : 0.3148\n",
      "Epoch: 0, Step : 170, LR : 1.60591232280231e-05, Avg Loss : 0.2823\n",
      "Epoch: 0, Step : 180, LR : 1.5622613340337575e-05, Avg Loss : 0.2628\n",
      "Epoch: 0, Step : 190, LR : 1.5169836450060106e-05, Avg Loss : 0.2576\n",
      "Epoch: 0, Step : 200, LR : 1.4702102503723004e-05, Avg Loss : 0.2713\n",
      "Epoch: 0, Step : 210, LR : 1.4220764720702536e-05, Avg Loss : 0.3103\n",
      "Epoch: 0, Step : 220, LR : 1.3727215678167015e-05, Avg Loss : 0.3008\n",
      "Epoch: 0, Step : 230, LR : 1.3222883282157315e-05, Avg Loss : 0.2917\n",
      "Epoch: 0, Step : 240, LR : 1.270922663645606e-05, Avg Loss : 0.2620\n",
      "Epoch: 0, Step : 250, LR : 1.2187731821197377e-05, Avg Loss : 0.2338\n",
      "Epoch: 0, Step : 260, LR : 1.1659907593430354e-05, Avg Loss : 0.3021\n",
      "Epoch: 0, Step : 270, LR : 1.112728102207498e-05, Avg Loss : 0.2883\n",
      "Epoch: 0, Step : 280, LR : 1.059139306989935e-05, Avg Loss : 0.3050\n",
      "Epoch: 0, Step : 290, LR : 1.0053794135299953e-05, Avg Loss : 0.2495\n",
      "Epoch 0 Total Mean Loss : 0.6150\n",
      "*****Epoch 0 Train Finish*****\n",
      "\n",
      "*****Epoch 0 Valid Start*****\n",
      "Epoch 0 Valid Loss : 0.2373\n",
      "*****Epoch 0 Valid Finish*****\n",
      "\n",
      "*****Epoch 1 Train Start*****\n",
      "Epoch: 1, Step : 10, LR : 9.408606930100655e-06, Avg Loss : 0.1673\n",
      "Epoch: 1, Step : 20, LR : 8.872718977925023e-06, Avg Loss : 0.1880\n",
      "Epoch: 1, Step : 30, LR : 8.340092406569648e-06, Avg Loss : 0.1957\n",
      "Epoch: 1, Step : 40, LR : 7.812268178802627e-06, Avg Loss : 0.1931\n",
      "Epoch: 1, Step : 50, LR : 7.290773363543946e-06, Avg Loss : 0.1989\n",
      "Epoch: 1, Step : 60, LR : 6.777116717842686e-06, Avg Loss : 0.1646\n",
      "Epoch: 1, Step : 70, LR : 6.27278432183299e-06, Avg Loss : 0.1859\n",
      "Epoch: 1, Step : 80, LR : 5.779235279297467e-06, Avg Loss : 0.1638\n",
      "Epoch: 1, Step : 90, LR : 5.297897496276998e-06, Avg Loss : 0.1644\n",
      "Epoch: 1, Step : 100, LR : 4.830163549939899e-06, Avg Loss : 0.1752\n",
      "Epoch: 1, Step : 110, LR : 4.3773866596624244e-06, Avg Loss : 0.1506\n",
      "Epoch: 1, Step : 120, LR : 3.940876771976905e-06, Avg Loss : 0.2057\n",
      "Epoch: 1, Step : 130, LR : 3.521896770714134e-06, Avg Loss : 0.1676\n",
      "Epoch: 1, Step : 140, LR : 3.1216588233048073e-06, Avg Loss : 0.2125\n",
      "Epoch: 1, Step : 150, LR : 2.741320873810487e-06, Avg Loss : 0.1668\n",
      "Epoch: 1, Step : 160, LR : 2.381983292830343e-06, Avg Loss : 0.1876\n",
      "Epoch: 1, Step : 170, LR : 2.0446856939759473e-06, Avg Loss : 0.1569\n",
      "Epoch: 1, Step : 180, LR : 1.73040392612445e-06, Avg Loss : 0.1837\n",
      "Epoch: 1, Step : 190, LR : 1.4400472501520224e-06, Avg Loss : 0.1460\n",
      "Epoch: 1, Step : 200, LR : 1.1744557083156705e-06, Avg Loss : 0.1656\n",
      "Epoch: 1, Step : 210, LR : 9.343976938940869e-07, Avg Loss : 0.1704\n",
      "Epoch: 1, Step : 220, LR : 7.205677281190304e-07, Avg Loss : 0.1555\n",
      "Epoch: 1, Step : 230, LR : 5.335844508287679e-07, Avg Loss : 0.1918\n",
      "Epoch: 1, Step : 240, LR : 3.7398883065695724e-07, Avg Loss : 0.1841\n",
      "Epoch: 1, Step : 250, LR : 2.422425999351463e-07, Avg Loss : 0.1376\n",
      "Epoch: 1, Step : 260, LR : 1.3872691883688673e-07, Avg Loss : 0.1776\n",
      "Epoch: 1, Step : 270, LR : 6.374127262833485e-08, Avg Loss : 0.1690\n",
      "Epoch: 1, Step : 280, LR : 1.7502605215715672e-08, Avg Loss : 0.1322\n",
      "Epoch: 1, Step : 290, LR : 1.4469149641538338e-10, Avg Loss : 0.1486\n",
      "Epoch 1 Total Mean Loss : 0.1725\n",
      "*****Epoch 1 Train Finish*****\n",
      "\n",
      "*****Epoch 1 Valid Start*****\n",
      "Epoch 1 Valid Loss : 0.2396\n",
      "*****Epoch 1 Valid Finish*****\n",
      "\n",
      "Train Completed. End Program.\n"
     ]
    }
   ],
   "source": [
    "epochs = 2\n",
    "optimizer, scheduler = initializer(train_dataloader, epochs=epochs)\n",
    "\n",
    "train(model, train_dataloader, valid_dataloader, epochs = epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "8999ed74",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(model, test_dataloader):\n",
    "    \"\"\"\n",
    "    test_dataloader의 label별 확률값과 실제 label 값을 반환\n",
    "    \"\"\"\n",
    "\n",
    "    model.eval()\n",
    "    model.to(device)\n",
    "\n",
    "    all_logits = []\n",
    "    all_labels = []\n",
    "\n",
    "    for step, batch in enumerate(test_dataloader):\n",
    "        print(f\"{step+1}/{len(test_dataloader)}\\r\", end = \"\")\n",
    "        \n",
    "        batch_input, batch_label = batch\n",
    "        \n",
    "        batch_input = batch_input.to(device)\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            logits = model(**batch_input)\n",
    "            all_logits.append(logits)\n",
    "        all_labels.extend(batch_label)\n",
    "\n",
    "    all_logits = torch.cat(all_logits, dim=0)\n",
    "    probs = torch.tensor(all_logits).cpu().numpy()\n",
    "    all_labels = np.array(all_labels)\n",
    "\n",
    "    return probs, all_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "684d8005",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "73/73\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HwaLang\\AppData\\Local\\Temp/ipykernel_1936/3166901217.py:25: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  probs = torch.tensor(all_logits).cpu().numpy()\n"
     ]
    }
   ],
   "source": [
    "probs, labels = predict(model, valid_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "04fe2e61",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "probs: -0.03,  label:  0.00,  diff: -0.03\n",
      "probs:  4.31,  label:  4.20,  diff:  0.11\n",
      "probs: -0.06,  label:  0.00,  diff: -0.06\n",
      "probs:  0.04,  label:  0.71,  diff: -0.67\n",
      "probs:  0.03,  label:  0.00,  diff:  0.03\n",
      "probs:  3.34,  label:  2.00,  diff:  1.34\n",
      "probs:  0.12,  label:  0.00,  diff:  0.12\n",
      "probs:  3.53,  label:  2.43,  diff:  1.10\n",
      "probs:  0.01,  label:  0.14,  diff: -0.14\n",
      "probs:  0.23,  label:  0.33,  diff: -0.10\n",
      "probs:  3.95,  label:  2.67,  diff:  1.29\n",
      "probs:  3.74,  label:  3.71,  diff:  0.03\n",
      "probs: -0.00,  label:  0.00,  diff: -0.00\n",
      "probs:  0.67,  label:  0.86,  diff: -0.18\n",
      "probs:  3.76,  label:  2.00,  diff:  1.76\n",
      "probs:  3.69,  label:  3.29,  diff:  0.41\n",
      "probs:  3.14,  label:  2.20,  diff:  0.94\n",
      "probs:  0.57,  label:  0.57,  diff: -0.01\n",
      "probs:  4.55,  label:  4.71,  diff: -0.16\n",
      "probs:  4.02,  label:  4.00,  diff:  0.02\n",
      "probs:  3.61,  label:  3.43,  diff:  0.18\n",
      "probs:  3.78,  label:  4.00,  diff: -0.22\n",
      "probs:  0.23,  label:  0.00,  diff:  0.23\n",
      "probs:  0.33,  label:  0.00,  diff:  0.33\n",
      "probs: -0.05,  label:  0.00,  diff: -0.05\n",
      "probs:  0.27,  label:  0.71,  diff: -0.45\n",
      "probs:  4.39,  label:  4.57,  diff: -0.18\n",
      "probs:  0.13,  label:  0.29,  diff: -0.16\n",
      "probs:  4.29,  label:  3.57,  diff:  0.72\n",
      "probs:  4.00,  label:  3.40,  diff:  0.60\n",
      "probs:  0.97,  label:  2.00,  diff: -1.03\n",
      "probs:  3.43,  label:  4.33,  diff: -0.90\n",
      "probs:  0.05,  label:  0.00,  diff:  0.05\n",
      "probs:  0.29,  label:  0.33,  diff: -0.04\n",
      "probs:  3.58,  label:  3.00,  diff:  0.58\n",
      "probs:  4.27,  label:  4.00,  diff:  0.27\n",
      "probs:  3.73,  label:  3.29,  diff:  0.44\n",
      "probs:  0.08,  label:  0.17,  diff: -0.08\n",
      "probs:  0.06,  label:  0.00,  diff:  0.06\n",
      "probs:  1.67,  label:  0.50,  diff:  1.17\n",
      "probs:  3.99,  label:  3.57,  diff:  0.42\n",
      "probs:  4.38,  label:  4.14,  diff:  0.24\n",
      "probs:  1.58,  label:  0.71,  diff:  0.87\n",
      "probs:  1.08,  label:  0.29,  diff:  0.79\n",
      "probs:  2.27,  label:  1.14,  diff:  1.12\n",
      "probs:  0.41,  label:  0.43,  diff: -0.02\n",
      "probs:  1.70,  label:  2.20,  diff: -0.50\n",
      "probs:  4.34,  label:  4.29,  diff:  0.05\n",
      "probs:  3.64,  label:  3.14,  diff:  0.50\n",
      "probs:  3.97,  label:  4.20,  diff: -0.23\n",
      "probs:  2.97,  label:  2.43,  diff:  0.54\n",
      "probs:  4.02,  label:  4.17,  diff: -0.15\n",
      "probs:  3.93,  label:  4.00,  diff: -0.07\n",
      "probs:  3.75,  label:  3.67,  diff:  0.09\n",
      "probs:  4.20,  label:  4.43,  diff: -0.23\n",
      "probs:  0.08,  label:  0.14,  diff: -0.07\n",
      "probs:  0.37,  label:  0.14,  diff:  0.23\n",
      "probs:  2.78,  label:  3.33,  diff: -0.56\n",
      "probs:  4.16,  label:  4.17,  diff: -0.00\n",
      "probs:  3.47,  label:  2.86,  diff:  0.61\n",
      "probs:  2.05,  label:  2.83,  diff: -0.78\n",
      "probs:  3.91,  label:  4.33,  diff: -0.42\n",
      "probs:  4.39,  label:  3.83,  diff:  0.55\n",
      "probs:  0.04,  label:  0.00,  diff:  0.04\n",
      "probs:  3.69,  label:  3.00,  diff:  0.69\n",
      "probs:  4.07,  label:  3.71,  diff:  0.35\n",
      "probs:  1.19,  label:  0.57,  diff:  0.62\n",
      "probs:  0.61,  label:  1.43,  diff: -0.82\n",
      "probs:  2.55,  label:  2.50,  diff:  0.05\n",
      "probs:  3.82,  label:  3.20,  diff:  0.62\n",
      "probs:  2.63,  label:  2.67,  diff: -0.04\n",
      "probs:  3.51,  label:  2.67,  diff:  0.84\n",
      "probs:  4.35,  label:  3.67,  diff:  0.69\n",
      "probs:  3.38,  label:  3.14,  diff:  0.24\n",
      "probs:  3.25,  label:  4.71,  diff: -1.46\n",
      "probs:  1.15,  label:  0.00,  diff:  1.15\n",
      "probs:  4.32,  label:  4.00,  diff:  0.32\n",
      "probs:  3.15,  label:  2.14,  diff:  1.00\n",
      "probs:  4.04,  label:  4.20,  diff: -0.16\n",
      "probs: -0.01,  label:  0.14,  diff: -0.15\n",
      "probs:  3.42,  label:  3.67,  diff: -0.25\n",
      "probs:  4.38,  label:  4.17,  diff:  0.21\n",
      "probs: -0.06,  label:  0.00,  diff: -0.06\n",
      "probs:  4.21,  label:  3.50,  diff:  0.71\n",
      "probs:  4.22,  label:  3.86,  diff:  0.36\n",
      "probs:  4.51,  label:  4.00,  diff:  0.51\n",
      "probs:  3.66,  label:  4.00,  diff: -0.34\n",
      "probs:  3.44,  label:  3.29,  diff:  0.15\n",
      "probs:  4.20,  label:  3.57,  diff:  0.63\n",
      "probs:  3.68,  label:  3.86,  diff: -0.18\n",
      "probs: -0.00,  label:  0.20,  diff: -0.20\n",
      "probs:  0.10,  label:  0.00,  diff:  0.10\n",
      "probs:  4.29,  label:  4.17,  diff:  0.13\n",
      "probs:  4.37,  label:  4.00,  diff:  0.37\n",
      "probs:  0.59,  label:  0.40,  diff:  0.19\n",
      "probs:  3.93,  label:  4.29,  diff: -0.36\n",
      "probs:  4.59,  label:  4.80,  diff: -0.21\n",
      "probs:  0.11,  label:  0.33,  diff: -0.23\n",
      "probs:  3.65,  label:  3.50,  diff:  0.15\n",
      "probs:  0.52,  label:  0.86,  diff: -0.33\n",
      "probs:  4.34,  label:  4.33,  diff:  0.01\n",
      "probs:  4.37,  label:  4.50,  diff: -0.13\n",
      "probs:  4.22,  label:  4.00,  diff:  0.22\n",
      "probs:  3.60,  label:  2.71,  diff:  0.89\n",
      "probs:  0.11,  label:  0.60,  diff: -0.49\n",
      "probs:  0.19,  label:  0.29,  diff: -0.10\n",
      "probs:  4.35,  label:  3.57,  diff:  0.77\n",
      "probs:  4.37,  label:  4.17,  diff:  0.21\n",
      "probs:  0.02,  label:  0.00,  diff:  0.02\n",
      "probs:  4.18,  label:  3.00,  diff:  1.18\n",
      "probs:  4.15,  label:  3.50,  diff:  0.65\n",
      "probs: -0.12,  label:  0.00,  diff: -0.12\n",
      "probs:  3.60,  label:  4.00,  diff: -0.40\n",
      "probs:  4.34,  label:  4.57,  diff: -0.24\n",
      "probs:  0.28,  label:  0.14,  diff:  0.13\n",
      "probs:  0.80,  label:  0.29,  diff:  0.52\n",
      "probs:  0.70,  label:  1.17,  diff: -0.46\n",
      "probs:  3.31,  label:  3.20,  diff:  0.11\n",
      "probs:  2.69,  label:  3.50,  diff: -0.81\n",
      "probs:  0.05,  label:  0.00,  diff:  0.05\n",
      "probs:  0.72,  label:  1.00,  diff: -0.28\n",
      "probs: -0.06,  label:  0.00,  diff: -0.06\n",
      "probs:  4.46,  label:  4.14,  diff:  0.32\n",
      "probs:  4.16,  label:  3.29,  diff:  0.87\n",
      "probs:  3.31,  label:  2.86,  diff:  0.45\n",
      "probs:  4.51,  label:  5.00,  diff: -0.49\n",
      "probs: -0.14,  label:  0.00,  diff: -0.14\n",
      "probs:  3.56,  label:  3.80,  diff: -0.24\n",
      "probs:  3.99,  label:  3.67,  diff:  0.32\n",
      "probs:  0.12,  label:  0.17,  diff: -0.05\n",
      "probs:  0.42,  label:  0.29,  diff:  0.14\n",
      "probs:  3.17,  label:  2.50,  diff:  0.67\n",
      "probs:  0.08,  label:  0.00,  diff:  0.08\n",
      "probs:  2.78,  label:  0.71,  diff:  2.07\n",
      "probs:  1.86,  label:  2.00,  diff: -0.14\n",
      "probs:  3.60,  label:  4.00,  diff: -0.40\n",
      "probs:  0.14,  label:  0.00,  diff:  0.14\n",
      "probs:  4.45,  label:  4.33,  diff:  0.11\n",
      "probs:  1.30,  label:  0.83,  diff:  0.46\n",
      "probs:  3.89,  label:  4.33,  diff: -0.44\n",
      "probs:  3.08,  label:  2.86,  diff:  0.22\n",
      "probs:  0.05,  label:  0.00,  diff:  0.05\n",
      "probs:  4.52,  label:  4.20,  diff:  0.32\n",
      "probs:  4.01,  label:  3.83,  diff:  0.18\n",
      "probs:  4.18,  label:  4.17,  diff:  0.01\n",
      "probs:  0.14,  label:  0.00,  diff:  0.14\n",
      "probs:  3.60,  label:  3.33,  diff:  0.26\n",
      "probs:  0.26,  label:  0.00,  diff:  0.26\n",
      "probs:  2.91,  label:  3.00,  diff: -0.09\n",
      "probs:  4.21,  label:  4.17,  diff:  0.04\n",
      "probs:  4.50,  label:  4.40,  diff:  0.10\n",
      "probs:  0.25,  label:  0.50,  diff: -0.25\n",
      "probs:  0.51,  label:  0.50,  diff:  0.01\n",
      "probs:  4.24,  label:  3.14,  diff:  1.10\n",
      "probs:  4.30,  label:  4.00,  diff:  0.30\n",
      "probs:  0.21,  label:  0.00,  diff:  0.21\n",
      "probs:  2.49,  label:  2.57,  diff: -0.08\n",
      "probs:  0.13,  label:  0.17,  diff: -0.04\n",
      "probs:  3.77,  label:  3.67,  diff:  0.11\n",
      "probs:  2.07,  label:  1.14,  diff:  0.93\n",
      "probs:  1.89,  label:  2.00,  diff: -0.11\n",
      "probs:  0.58,  label:  0.43,  diff:  0.15\n",
      "probs:  0.02,  label:  0.14,  diff: -0.12\n",
      "probs:  4.21,  label:  4.14,  diff:  0.07\n",
      "probs:  1.43,  label:  0.60,  diff:  0.83\n",
      "probs:  0.02,  label:  0.17,  diff: -0.14\n",
      "probs:  0.21,  label:  0.00,  diff:  0.21\n",
      "probs:  0.15,  label:  0.50,  diff: -0.35\n",
      "probs:  3.42,  label:  3.67,  diff: -0.24\n",
      "probs:  3.76,  label:  3.17,  diff:  0.59\n",
      "probs:  3.73,  label:  2.57,  diff:  1.16\n",
      "probs:  4.38,  label:  4.00,  diff:  0.38\n",
      "probs:  0.77,  label:  1.20,  diff: -0.43\n",
      "probs:  4.07,  label:  4.00,  diff:  0.07\n",
      "probs:  0.37,  label:  0.00,  diff:  0.37\n",
      "probs:  3.92,  label:  3.83,  diff:  0.08\n",
      "probs:  4.52,  label:  4.50,  diff:  0.02\n",
      "probs:  2.27,  label:  2.50,  diff: -0.23\n",
      "probs:  0.17,  label:  0.14,  diff:  0.02\n",
      "probs:  1.29,  label:  0.14,  diff:  1.15\n",
      "probs: -0.04,  label:  0.00,  diff: -0.04\n",
      "probs:  4.51,  label:  4.50,  diff:  0.01\n",
      "probs:  3.30,  label:  1.57,  diff:  1.73\n",
      "probs:  3.69,  label:  4.33,  diff: -0.64\n",
      "probs:  4.51,  label:  4.00,  diff:  0.51\n",
      "probs:  0.47,  label:  1.00,  diff: -0.53\n",
      "probs:  4.41,  label:  4.33,  diff:  0.07\n",
      "probs:  4.29,  label:  3.43,  diff:  0.86\n",
      "probs:  3.83,  label:  3.43,  diff:  0.40\n",
      "probs:  4.14,  label:  4.29,  diff: -0.14\n",
      "probs:  4.22,  label:  4.00,  diff:  0.22\n",
      "probs:  0.08,  label:  0.14,  diff: -0.06\n",
      "probs:  0.18,  label:  0.17,  diff:  0.01\n",
      "probs:  2.57,  label:  2.43,  diff:  0.15\n",
      "probs:  0.03,  label:  0.00,  diff:  0.03\n",
      "probs:  4.45,  label:  3.60,  diff:  0.85\n",
      "probs: -0.03,  label:  0.00,  diff: -0.03\n",
      "probs:  0.31,  label:  0.50,  diff: -0.19\n",
      "probs:  4.19,  label:  4.00,  diff:  0.19\n",
      "probs:  0.04,  label:  0.14,  diff: -0.10\n",
      "probs:  4.54,  label:  4.00,  diff:  0.54\n",
      "probs:  4.29,  label:  3.83,  diff:  0.46\n",
      "probs:  2.36,  label:  2.50,  diff: -0.14\n",
      "probs:  4.31,  label:  3.83,  diff:  0.48\n",
      "probs:  4.11,  label:  3.33,  diff:  0.78\n",
      "probs:  3.98,  label:  3.50,  diff:  0.48\n",
      "probs:  1.61,  label:  2.29,  diff: -0.68\n",
      "probs:  4.38,  label:  3.67,  diff:  0.71\n",
      "probs:  0.27,  label:  0.00,  diff:  0.27\n",
      "probs:  4.51,  label:  4.80,  diff: -0.29\n",
      "probs:  0.16,  label:  0.43,  diff: -0.27\n",
      "probs:  0.95,  label:  0.67,  diff:  0.28\n",
      "probs:  4.40,  label:  4.17,  diff:  0.23\n",
      "probs:  0.01,  label:  0.00,  diff:  0.01\n",
      "probs:  2.17,  label:  1.50,  diff:  0.67\n",
      "probs:  0.02,  label:  0.00,  diff:  0.02\n",
      "probs:  3.90,  label:  4.17,  diff: -0.27\n",
      "probs:  3.67,  label:  4.00,  diff: -0.33\n",
      "probs:  4.15,  label:  3.71,  diff:  0.44\n",
      "probs:  4.20,  label:  4.00,  diff:  0.20\n",
      "probs:  4.05,  label:  3.60,  diff:  0.45\n",
      "probs:  4.13,  label:  4.00,  diff:  0.13\n",
      "probs:  4.22,  label:  3.57,  diff:  0.65\n",
      "probs: -0.00,  label:  0.43,  diff: -0.43\n",
      "probs:  3.97,  label:  3.29,  diff:  0.68\n",
      "probs:  0.28,  label:  0.00,  diff:  0.28\n",
      "probs: -0.14,  label:  0.00,  diff: -0.14\n",
      "probs:  3.83,  label:  3.67,  diff:  0.16\n",
      "probs:  2.82,  label:  2.40,  diff:  0.42\n",
      "probs:  0.07,  label:  0.29,  diff: -0.21\n",
      "probs:  3.61,  label:  2.80,  diff:  0.81\n",
      "probs:  3.75,  label:  4.00,  diff: -0.25\n",
      "probs:  4.22,  label:  4.33,  diff: -0.11\n",
      "probs:  4.45,  label:  4.33,  diff:  0.12\n",
      "probs: -0.03,  label:  0.00,  diff: -0.03\n",
      "probs:  4.35,  label:  4.00,  diff:  0.35\n",
      "probs:  0.34,  label:  0.20,  diff:  0.14\n",
      "probs:  4.31,  label:  4.33,  diff: -0.02\n",
      "probs:  0.65,  label:  1.00,  diff: -0.35\n",
      "probs:  0.27,  label:  0.71,  diff: -0.44\n",
      "probs:  0.05,  label:  0.57,  diff: -0.52\n",
      "probs:  1.87,  label:  1.67,  diff:  0.20\n",
      "probs:  0.32,  label:  0.43,  diff: -0.11\n",
      "probs: -0.02,  label:  0.00,  diff: -0.02\n",
      "probs:  4.54,  label:  4.29,  diff:  0.25\n",
      "probs:  4.37,  label:  4.17,  diff:  0.20\n",
      "probs:  0.12,  label:  0.29,  diff: -0.16\n",
      "probs:  4.34,  label:  3.00,  diff:  1.34\n",
      "probs: -0.00,  label:  0.43,  diff: -0.43\n",
      "probs:  4.25,  label:  3.40,  diff:  0.85\n",
      "probs:  0.09,  label:  0.00,  diff:  0.09\n",
      "probs:  0.88,  label:  0.83,  diff:  0.05\n",
      "probs:  4.24,  label:  4.14,  diff:  0.10\n",
      "probs:  4.36,  label:  4.33,  diff:  0.03\n",
      "probs:  3.84,  label:  4.00,  diff: -0.16\n",
      "probs:  0.71,  label:  0.43,  diff:  0.28\n",
      "probs:  0.03,  label:  0.00,  diff:  0.03\n",
      "probs:  4.24,  label:  4.00,  diff:  0.24\n",
      "probs: -0.02,  label:  0.17,  diff: -0.19\n",
      "probs:  3.90,  label:  4.14,  diff: -0.24\n",
      "probs:  0.55,  label:  0.00,  diff:  0.55\n",
      "probs:  4.11,  label:  2.83,  diff:  1.27\n",
      "probs: -0.04,  label:  0.17,  diff: -0.21\n",
      "probs:  4.00,  label:  3.86,  diff:  0.14\n",
      "probs:  0.33,  label:  0.29,  diff:  0.05\n",
      "probs:  0.01,  label:  0.00,  diff:  0.01\n",
      "probs:  4.40,  label:  4.17,  diff:  0.23\n",
      "probs:  0.06,  label:  0.00,  diff:  0.06\n",
      "probs:  1.38,  label:  1.33,  diff:  0.05\n",
      "probs:  1.11,  label:  1.20,  diff: -0.09\n",
      "probs:  4.47,  label:  4.71,  diff: -0.24\n",
      "probs:  4.50,  label:  4.33,  diff:  0.17\n",
      "probs:  4.04,  label:  3.83,  diff:  0.20\n",
      "probs:  0.30,  label:  0.00,  diff:  0.30\n",
      "probs:  2.16,  label:  3.00,  diff: -0.84\n",
      "probs:  3.97,  label:  3.50,  diff:  0.47\n",
      "probs:  0.36,  label:  0.00,  diff:  0.36\n",
      "probs:  0.07,  label:  0.00,  diff:  0.07\n",
      "probs:  4.14,  label:  3.67,  diff:  0.48\n",
      "probs:  3.87,  label:  3.43,  diff:  0.44\n",
      "probs:  4.31,  label:  4.29,  diff:  0.03\n",
      "probs:  0.29,  label:  0.57,  diff: -0.28\n",
      "probs:  0.05,  label:  0.14,  diff: -0.10\n",
      "probs:  3.72,  label:  3.83,  diff: -0.11\n",
      "probs:  4.06,  label:  4.20,  diff: -0.14\n",
      "probs:  0.12,  label:  0.00,  diff:  0.12\n",
      "probs: -0.00,  label:  0.00,  diff: -0.00\n",
      "probs:  2.10,  label:  2.17,  diff: -0.07\n",
      "probs:  1.91,  label:  1.67,  diff:  0.25\n",
      "probs:  3.57,  label:  3.86,  diff: -0.28\n",
      "probs:  0.20,  label:  0.00,  diff:  0.20\n",
      "probs:  3.93,  label:  3.67,  diff:  0.26\n",
      "probs:  3.92,  label:  3.20,  diff:  0.72\n",
      "probs:  0.21,  label:  0.00,  diff:  0.21\n",
      "probs:  1.73,  label:  0.17,  diff:  1.57\n",
      "probs:  0.12,  label:  0.14,  diff: -0.02\n",
      "probs:  3.84,  label:  3.14,  diff:  0.69\n",
      "probs:  0.21,  label:  0.29,  diff: -0.08\n",
      "probs:  3.44,  label:  3.29,  diff:  0.15\n",
      "probs:  4.48,  label:  4.67,  diff: -0.19\n",
      "probs:  4.00,  label:  3.67,  diff:  0.33\n",
      "probs:  4.42,  label:  4.43,  diff: -0.01\n",
      "probs:  3.75,  label:  2.67,  diff:  1.08\n",
      "probs:  3.83,  label:  4.00,  diff: -0.17\n",
      "probs:  0.03,  label:  0.00,  diff:  0.03\n",
      "probs:  2.17,  label:  1.17,  diff:  1.01\n",
      "probs: -0.03,  label:  0.00,  diff: -0.03\n",
      "probs:  0.21,  label:  0.00,  diff:  0.21\n",
      "probs:  4.56,  label:  4.57,  diff: -0.01\n",
      "probs:  4.16,  label:  4.17,  diff: -0.01\n",
      "probs:  1.65,  label:  3.67,  diff: -2.02\n",
      "probs:  2.90,  label:  3.00,  diff: -0.10\n",
      "probs:  3.86,  label:  3.86,  diff:  0.01\n",
      "probs:  0.13,  label:  0.50,  diff: -0.37\n",
      "probs:  4.20,  label:  4.50,  diff: -0.30\n",
      "probs:  4.07,  label:  4.20,  diff: -0.13\n",
      "probs:  3.39,  label:  3.40,  diff: -0.01\n",
      "probs:  2.94,  label:  1.29,  diff:  1.66\n",
      "probs:  4.42,  label:  4.50,  diff: -0.08\n",
      "probs:  2.21,  label:  1.57,  diff:  0.64\n",
      "probs:  4.13,  label:  3.86,  diff:  0.28\n",
      "probs:  3.37,  label:  3.67,  diff: -0.30\n",
      "probs:  4.49,  label:  4.71,  diff: -0.23\n",
      "probs:  4.09,  label:  4.00,  diff:  0.09\n",
      "probs:  0.33,  label:  0.67,  diff: -0.33\n",
      "probs:  0.13,  label:  0.00,  diff:  0.13\n",
      "probs:  4.03,  label:  4.00,  diff:  0.03\n",
      "probs:  0.00,  label:  0.00,  diff:  0.00\n",
      "probs:  0.12,  label:  0.57,  diff: -0.46\n",
      "probs:  0.13,  label:  0.00,  diff:  0.13\n",
      "probs:  4.20,  label:  3.60,  diff:  0.60\n",
      "probs:  3.64,  label:  4.33,  diff: -0.70\n",
      "probs:  3.75,  label:  3.80,  diff: -0.05\n",
      "probs:  4.48,  label:  4.33,  diff:  0.15\n",
      "probs:  3.79,  label:  3.71,  diff:  0.08\n",
      "probs:  0.94,  label:  0.67,  diff:  0.27\n",
      "probs:  0.26,  label:  0.00,  diff:  0.26\n",
      "probs:  0.07,  label:  0.00,  diff:  0.07\n",
      "probs:  3.70,  label:  3.50,  diff:  0.20\n",
      "probs:  0.17,  label:  0.86,  diff: -0.68\n",
      "probs:  0.12,  label:  0.00,  diff:  0.12\n",
      "probs:  0.54,  label:  0.14,  diff:  0.40\n",
      "probs:  4.28,  label:  3.83,  diff:  0.45\n",
      "probs:  0.18,  label:  0.00,  diff:  0.18\n",
      "probs:  3.63,  label:  3.83,  diff: -0.20\n",
      "probs:  0.31,  label:  0.14,  diff:  0.16\n",
      "probs:  0.28,  label:  0.17,  diff:  0.11\n",
      "probs:  0.04,  label:  0.14,  diff: -0.11\n",
      "probs:  4.19,  label:  3.83,  diff:  0.36\n",
      "probs:  0.23,  label:  0.14,  diff:  0.09\n",
      "probs:  0.21,  label:  0.00,  diff:  0.21\n",
      "probs:  0.69,  label:  0.29,  diff:  0.40\n",
      "probs:  1.61,  label:  1.33,  diff:  0.27\n",
      "probs:  0.13,  label:  0.57,  diff: -0.44\n",
      "probs:  0.01,  label:  0.00,  diff:  0.01\n",
      "probs:  0.18,  label:  1.00,  diff: -0.82\n",
      "probs:  4.17,  label:  3.00,  diff:  1.17\n",
      "probs:  1.03,  label:  1.20,  diff: -0.17\n",
      "probs:  4.37,  label:  3.57,  diff:  0.80\n",
      "probs: -0.00,  label:  0.00,  diff: -0.00\n",
      "probs:  3.88,  label:  4.00,  diff: -0.12\n",
      "probs:  0.37,  label:  0.00,  diff:  0.37\n",
      "probs:  0.24,  label:  0.00,  diff:  0.24\n",
      "probs: -0.05,  label:  0.00,  diff: -0.05\n",
      "probs:  3.85,  label:  3.17,  diff:  0.68\n",
      "probs:  3.92,  label:  3.86,  diff:  0.07\n",
      "probs:  4.29,  label:  4.57,  diff: -0.28\n",
      "probs:  2.46,  label:  1.71,  diff:  0.75\n",
      "probs:  0.07,  label:  0.17,  diff: -0.09\n",
      "probs:  3.96,  label:  3.71,  diff:  0.24\n",
      "probs:  4.23,  label:  3.67,  diff:  0.56\n",
      "probs:  2.89,  label:  3.00,  diff: -0.11\n",
      "probs:  0.43,  label:  0.67,  diff: -0.24\n",
      "probs:  0.25,  label:  0.14,  diff:  0.10\n",
      "probs:  3.56,  label:  3.00,  diff:  0.56\n",
      "probs:  0.53,  label:  1.17,  diff: -0.64\n",
      "probs:  4.16,  label:  3.83,  diff:  0.33\n",
      "probs:  4.40,  label:  4.33,  diff:  0.06\n",
      "probs:  2.37,  label:  2.00,  diff:  0.37\n",
      "probs:  3.48,  label:  4.00,  diff: -0.52\n",
      "probs:  3.66,  label:  3.50,  diff:  0.16\n",
      "probs:  3.25,  label:  3.20,  diff:  0.05\n",
      "probs:  4.11,  label:  3.71,  diff:  0.40\n",
      "probs:  0.23,  label:  0.43,  diff: -0.20\n",
      "probs: -0.07,  label:  0.00,  diff: -0.07\n",
      "probs:  4.19,  label:  3.67,  diff:  0.52\n",
      "probs: -0.03,  label:  0.00,  diff: -0.03\n",
      "probs:  0.35,  label:  0.50,  diff: -0.15\n",
      "probs:  1.79,  label:  1.43,  diff:  0.36\n",
      "probs:  2.88,  label:  2.50,  diff:  0.38\n",
      "probs: -0.15,  label:  0.17,  diff: -0.32\n",
      "probs:  4.18,  label:  3.86,  diff:  0.32\n",
      "probs:  0.16,  label:  0.00,  diff:  0.16\n",
      "probs:  1.20,  label:  1.57,  diff: -0.37\n",
      "probs:  1.07,  label:  1.00,  diff:  0.07\n",
      "probs:  0.18,  label:  0.33,  diff: -0.15\n",
      "probs:  4.07,  label:  3.43,  diff:  0.64\n",
      "probs:  0.08,  label:  0.17,  diff: -0.09\n",
      "probs:  3.81,  label:  4.00,  diff: -0.19\n",
      "probs:  3.09,  label:  2.71,  diff:  0.37\n",
      "probs:  4.39,  label:  4.67,  diff: -0.27\n",
      "probs:  0.34,  label:  0.50,  diff: -0.16\n",
      "probs:  1.30,  label:  0.50,  diff:  0.80\n",
      "probs:  4.05,  label:  3.50,  diff:  0.55\n",
      "probs:  3.22,  label:  1.83,  diff:  1.39\n",
      "probs:  1.14,  label:  0.67,  diff:  0.48\n",
      "probs:  4.08,  label:  4.00,  diff:  0.08\n",
      "probs:  4.28,  label:  3.80,  diff:  0.48\n",
      "probs: -0.07,  label:  0.00,  diff: -0.07\n",
      "probs:  4.31,  label:  4.29,  diff:  0.03\n",
      "probs:  4.13,  label:  4.17,  diff: -0.04\n",
      "probs:  0.20,  label:  0.00,  diff:  0.20\n",
      "probs:  3.65,  label:  4.00,  diff: -0.35\n",
      "probs:  3.85,  label:  3.80,  diff:  0.05\n",
      "probs: -0.02,  label:  0.14,  diff: -0.16\n",
      "probs:  0.26,  label:  0.00,  diff:  0.26\n",
      "probs:  4.16,  label:  3.50,  diff:  0.66\n",
      "probs:  2.22,  label:  3.17,  diff: -0.95\n",
      "probs:  4.35,  label:  4.50,  diff: -0.15\n",
      "probs:  0.13,  label:  0.29,  diff: -0.16\n",
      "probs: -0.03,  label:  0.00,  diff: -0.03\n",
      "probs:  4.22,  label:  4.43,  diff: -0.20\n",
      "probs:  0.61,  label:  0.83,  diff: -0.22\n",
      "probs:  4.01,  label:  3.50,  diff:  0.51\n",
      "probs:  0.24,  label:  0.17,  diff:  0.07\n",
      "probs:  4.05,  label:  3.60,  diff:  0.45\n",
      "probs:  3.39,  label:  3.14,  diff:  0.25\n",
      "probs:  0.05,  label:  0.00,  diff:  0.05\n",
      "probs:  3.98,  label:  3.83,  diff:  0.14\n",
      "probs:  4.49,  label:  3.83,  diff:  0.66\n",
      "probs:  4.31,  label:  3.83,  diff:  0.47\n",
      "probs:  3.82,  label:  3.00,  diff:  0.82\n",
      "probs:  4.39,  label:  4.00,  diff:  0.39\n",
      "probs:  0.29,  label:  0.67,  diff: -0.38\n",
      "probs:  4.22,  label:  4.00,  diff:  0.22\n",
      "probs:  2.77,  label:  1.43,  diff:  1.34\n",
      "probs:  3.82,  label:  3.71,  diff:  0.10\n",
      "probs:  3.76,  label:  3.29,  diff:  0.47\n",
      "probs:  0.39,  label:  0.00,  diff:  0.39\n",
      "probs:  4.37,  label:  4.50,  diff: -0.13\n",
      "probs:  4.24,  label:  4.50,  diff: -0.26\n",
      "probs:  4.29,  label:  3.50,  diff:  0.79\n",
      "probs:  1.35,  label:  2.00,  diff: -0.65\n",
      "probs: -0.12,  label:  0.00,  diff: -0.12\n",
      "probs:  4.46,  label:  4.33,  diff:  0.12\n",
      "probs:  0.32,  label:  0.14,  diff:  0.18\n",
      "probs:  4.01,  label:  4.17,  diff: -0.15\n",
      "probs:  4.29,  label:  4.67,  diff: -0.38\n",
      "probs:  3.96,  label:  3.57,  diff:  0.39\n",
      "probs:  3.46,  label:  3.50,  diff: -0.04\n",
      "probs:  4.28,  label:  3.83,  diff:  0.45\n",
      "probs:  0.23,  label:  0.67,  diff: -0.44\n",
      "probs:  0.22,  label:  0.00,  diff:  0.22\n",
      "probs:  3.72,  label:  4.00,  diff: -0.28\n",
      "probs:  0.98,  label:  0.17,  diff:  0.81\n",
      "probs:  4.09,  label:  3.83,  diff:  0.26\n",
      "probs:  0.92,  label:  0.20,  diff:  0.72\n",
      "probs:  2.49,  label:  1.17,  diff:  1.32\n",
      "probs:  0.84,  label:  2.29,  diff: -1.45\n",
      "probs:  1.34,  label:  0.50,  diff:  0.84\n",
      "probs:  2.56,  label:  2.00,  diff:  0.56\n",
      "probs:  3.96,  label:  3.17,  diff:  0.80\n",
      "probs:  0.01,  label:  0.00,  diff:  0.01\n",
      "probs:  3.09,  label:  2.00,  diff:  1.09\n",
      "probs:  0.08,  label:  0.00,  diff:  0.08\n",
      "probs:  4.33,  label:  3.71,  diff:  0.61\n",
      "probs:  3.36,  label:  3.17,  diff:  0.20\n",
      "probs:  3.49,  label:  2.83,  diff:  0.66\n",
      "probs: -0.06,  label:  0.33,  diff: -0.39\n",
      "probs:  4.16,  label:  4.43,  diff: -0.27\n",
      "probs:  3.93,  label:  3.83,  diff:  0.09\n",
      "probs:  3.79,  label:  2.57,  diff:  1.22\n",
      "probs:  0.27,  label:  0.17,  diff:  0.10\n",
      "probs:  0.32,  label:  2.00,  diff: -1.68\n",
      "probs:  0.99,  label:  0.29,  diff:  0.71\n",
      "probs: -0.11,  label:  0.00,  diff: -0.11\n",
      "probs:  0.86,  label:  1.43,  diff: -0.57\n",
      "probs:  4.24,  label:  4.29,  diff: -0.04\n",
      "probs:  3.86,  label:  4.14,  diff: -0.29\n",
      "probs:  0.33,  label:  0.33,  diff: -0.00\n",
      "probs:  1.69,  label:  0.60,  diff:  1.09\n",
      "probs:  3.94,  label:  4.17,  diff: -0.22\n",
      "probs:  4.11,  label:  3.00,  diff:  1.11\n",
      "probs:  0.14,  label:  0.00,  diff:  0.14\n",
      "probs:  4.49,  label:  4.17,  diff:  0.33\n",
      "probs:  0.04,  label:  0.17,  diff: -0.13\n",
      "probs:  1.72,  label:  1.67,  diff:  0.05\n",
      "probs:  0.25,  label:  0.00,  diff:  0.25\n",
      "probs:  0.09,  label:  0.14,  diff: -0.05\n",
      "probs:  0.18,  label:  0.71,  diff: -0.54\n",
      "probs:  4.33,  label:  3.83,  diff:  0.50\n",
      "probs:  2.58,  label:  2.67,  diff: -0.08\n",
      "probs:  0.14,  label:  0.00,  diff:  0.14\n",
      "probs:  1.31,  label:  0.86,  diff:  0.45\n",
      "probs: -0.05,  label:  0.00,  diff: -0.05\n",
      "probs:  4.44,  label:  4.33,  diff:  0.10\n",
      "probs:  3.57,  label:  3.50,  diff:  0.07\n",
      "probs:  0.83,  label:  2.29,  diff: -1.46\n",
      "probs:  3.84,  label:  4.14,  diff: -0.30\n",
      "probs:  4.11,  label:  4.00,  diff:  0.11\n",
      "probs:  1.78,  label:  2.17,  diff: -0.39\n",
      "probs:  3.35,  label:  3.50,  diff: -0.15\n",
      "probs:  0.06,  label:  0.00,  diff:  0.06\n",
      "probs:  3.64,  label:  4.00,  diff: -0.36\n",
      "probs:  1.31,  label:  1.71,  diff: -0.41\n",
      "probs:  4.01,  label:  3.50,  diff:  0.51\n",
      "probs:  0.09,  label:  0.00,  diff:  0.09\n",
      "probs:  3.95,  label:  3.50,  diff:  0.45\n",
      "probs:  3.87,  label:  4.17,  diff: -0.30\n",
      "probs:  4.40,  label:  4.00,  diff:  0.40\n",
      "probs: -0.05,  label:  0.00,  diff: -0.05\n",
      "probs:  3.63,  label:  3.57,  diff:  0.06\n",
      "probs:  4.07,  label:  4.50,  diff: -0.43\n",
      "probs:  0.59,  label:  1.33,  diff: -0.74\n",
      "probs:  3.75,  label:  3.71,  diff:  0.04\n",
      "probs:  0.02,  label:  0.00,  diff:  0.02\n",
      "probs:  2.94,  label:  3.00,  diff: -0.06\n",
      "probs:  4.12,  label:  3.83,  diff:  0.29\n",
      "probs:  4.12,  label:  4.20,  diff: -0.08\n",
      "probs:  4.14,  label:  4.00,  diff:  0.14\n",
      "probs:  3.58,  label:  3.83,  diff: -0.25\n",
      "probs:  4.34,  label:  4.17,  diff:  0.17\n",
      "probs:  0.56,  label:  0.43,  diff:  0.13\n",
      "probs:  4.33,  label:  4.33,  diff: -0.00\n",
      "probs:  3.50,  label:  3.83,  diff: -0.34\n",
      "probs:  3.32,  label:  3.00,  diff:  0.32\n",
      "probs:  0.44,  label:  0.14,  diff:  0.30\n",
      "probs:  4.25,  label:  4.14,  diff:  0.11\n",
      "probs:  4.21,  label:  4.00,  diff:  0.21\n",
      "probs:  0.42,  label:  0.43,  diff: -0.00\n",
      "probs:  3.90,  label:  3.50,  diff:  0.40\n",
      "probs:  4.23,  label:  3.67,  diff:  0.57\n",
      "probs:  3.75,  label:  2.86,  diff:  0.89\n",
      "probs:  0.21,  label:  0.17,  diff:  0.04\n",
      "probs: -0.03,  label:  0.00,  diff: -0.03\n",
      "probs:  2.13,  label:  0.43,  diff:  1.70\n",
      "probs:  1.52,  label:  0.57,  diff:  0.94\n",
      "probs:  4.34,  label:  4.29,  diff:  0.06\n",
      "probs:  0.33,  label:  0.17,  diff:  0.16\n",
      "probs:  0.11,  label:  0.00,  diff:  0.11\n",
      "probs:  0.26,  label:  0.86,  diff: -0.60\n",
      "probs:  0.44,  label:  1.86,  diff: -1.42\n",
      "probs:  4.38,  label:  3.80,  diff:  0.58\n",
      "probs:  0.19,  label:  0.00,  diff:  0.19\n",
      "probs:  2.31,  label:  4.33,  diff: -2.02\n",
      "probs:  0.80,  label:  0.40,  diff:  0.40\n",
      "probs:  4.30,  label:  4.33,  diff: -0.03\n",
      "probs:  4.38,  label:  4.86,  diff: -0.47\n",
      "probs:  0.41,  label:  0.20,  diff:  0.21\n",
      "probs:  0.12,  label:  0.00,  diff:  0.12\n",
      "probs:  0.28,  label:  0.17,  diff:  0.11\n",
      "probs:  0.33,  label:  0.17,  diff:  0.16\n",
      "probs:  0.36,  label:  0.50,  diff: -0.14\n",
      "probs:  3.99,  label:  3.17,  diff:  0.82\n",
      "probs:  0.30,  label:  0.00,  diff:  0.30\n",
      "probs:  3.94,  label:  4.00,  diff: -0.06\n",
      "probs:  4.26,  label:  4.33,  diff: -0.07\n",
      "probs:  4.13,  label:  4.33,  diff: -0.21\n",
      "probs:  0.06,  label:  0.00,  diff:  0.06\n",
      "probs:  4.24,  label:  4.20,  diff:  0.04\n",
      "probs:  3.28,  label:  2.00,  diff:  1.28\n",
      "probs:  4.02,  label:  4.00,  diff:  0.02\n",
      "probs:  0.18,  label:  0.00,  diff:  0.18\n",
      "probs:  4.28,  label:  4.67,  diff: -0.38\n",
      "probs:  0.52,  label:  0.80,  diff: -0.28\n",
      "probs:  3.78,  label:  3.57,  diff:  0.21\n",
      "probs:  3.85,  label:  3.33,  diff:  0.52\n",
      "probs:  0.23,  label:  0.00,  diff:  0.23\n",
      "probs:  4.56,  label:  4.14,  diff:  0.42\n",
      "probs:  0.38,  label:  1.33,  diff: -0.96\n",
      "probs:  1.19,  label:  1.83,  diff: -0.64\n",
      "probs:  3.54,  label:  4.00,  diff: -0.46\n",
      "probs:  4.51,  label:  5.00,  diff: -0.49\n",
      "probs:  2.44,  label:  2.00,  diff:  0.44\n",
      "probs:  3.65,  label:  4.17,  diff: -0.51\n",
      "probs:  4.23,  label:  4.00,  diff:  0.23\n",
      "probs: -0.07,  label:  0.00,  diff: -0.07\n",
      "probs:  0.24,  label:  0.33,  diff: -0.09\n",
      "probs:  1.22,  label:  1.20,  diff:  0.02\n",
      "probs:  0.06,  label:  0.00,  diff:  0.06\n",
      "probs:  4.32,  label:  4.00,  diff:  0.32\n",
      "probs:  4.02,  label:  4.00,  diff:  0.02\n",
      "probs:  0.13,  label:  0.00,  diff:  0.13\n",
      "probs:  0.20,  label:  0.00,  diff:  0.20\n",
      "probs:  3.74,  label:  3.33,  diff:  0.41\n",
      "probs:  2.10,  label:  1.57,  diff:  0.53\n",
      "probs:  4.10,  label:  4.33,  diff: -0.23\n",
      "probs:  3.82,  label:  4.17,  diff: -0.35\n",
      "probs:  0.07,  label:  0.17,  diff: -0.09\n",
      "probs:  0.13,  label:  0.17,  diff: -0.04\n",
      "probs:  4.32,  label:  4.40,  diff: -0.08\n",
      "probs:  1.40,  label:  1.33,  diff:  0.06\n",
      "probs:  1.12,  label:  0.86,  diff:  0.27\n",
      "probs:  3.37,  label:  3.00,  diff:  0.37\n",
      "probs:  4.41,  label:  4.43,  diff: -0.02\n",
      "probs:  4.43,  label:  4.20,  diff:  0.23\n",
      "probs: -0.05,  label:  0.00,  diff: -0.05\n",
      "probs:  4.04,  label:  4.17,  diff: -0.13\n",
      "probs:  0.19,  label:  0.00,  diff:  0.19\n",
      "probs: -0.07,  label:  0.00,  diff: -0.07\n",
      "probs:  0.30,  label:  0.00,  diff:  0.30\n",
      "probs:  3.95,  label:  3.00,  diff:  0.95\n",
      "probs:  0.22,  label:  0.50,  diff: -0.28\n",
      "probs:  4.35,  label:  3.86,  diff:  0.50\n",
      "probs:  3.67,  label:  3.60,  diff:  0.07\n",
      "probs:  4.54,  label:  4.00,  diff:  0.54\n",
      "probs:  0.28,  label:  0.00,  diff:  0.28\n",
      "probs:  4.18,  label:  4.00,  diff:  0.18\n",
      "probs:  4.41,  label:  4.33,  diff:  0.08\n",
      "probs:  2.51,  label:  1.00,  diff:  1.51\n",
      "probs:  3.59,  label:  2.67,  diff:  0.92\n",
      "probs:  0.48,  label:  0.14,  diff:  0.34\n",
      "probs:  3.72,  label:  4.00,  diff: -0.28\n",
      "probs:  4.33,  label:  4.00,  diff:  0.33\n",
      "probs:  2.96,  label:  2.33,  diff:  0.63\n",
      "probs:  0.17,  label:  0.86,  diff: -0.69\n",
      "probs:  0.06,  label:  0.43,  diff: -0.37\n",
      "probs:  0.76,  label:  1.33,  diff: -0.57\n",
      "probs:  0.07,  label:  0.00,  diff:  0.07\n",
      "probs:  1.43,  label:  1.14,  diff:  0.29\n",
      "probs:  1.94,  label:  2.14,  diff: -0.20\n",
      "probs:  0.02,  label:  0.00,  diff:  0.02\n",
      "probs:  2.43,  label:  2.17,  diff:  0.26\n",
      "probs:  2.09,  label:  1.50,  diff:  0.59\n",
      "probs:  3.94,  label:  3.67,  diff:  0.27\n",
      "probs:  1.70,  label:  1.17,  diff:  0.53\n",
      "probs:  4.22,  label:  3.50,  diff:  0.72\n",
      "probs:  3.60,  label:  3.80,  diff: -0.20\n",
      "probs: -0.03,  label:  0.00,  diff: -0.03\n",
      "probs:  0.12,  label:  0.00,  diff:  0.12\n",
      "probs:  0.96,  label:  0.67,  diff:  0.29\n",
      "probs:  3.54,  label:  3.00,  diff:  0.54\n",
      "probs:  0.78,  label:  0.71,  diff:  0.06\n",
      "probs: -0.05,  label:  0.00,  diff: -0.05\n",
      "probs:  0.27,  label:  0.20,  diff:  0.07\n",
      "probs: -0.04,  label:  0.43,  diff: -0.47\n",
      "probs:  0.40,  label:  0.83,  diff: -0.43\n",
      "probs:  4.18,  label:  4.00,  diff:  0.18\n",
      "probs:  0.09,  label:  0.00,  diff:  0.09\n",
      "probs:  2.49,  label:  1.67,  diff:  0.82\n",
      "probs:  1.24,  label:  1.20,  diff:  0.04\n",
      "probs:  3.32,  label:  3.71,  diff: -0.40\n",
      "probs:  4.20,  label:  4.00,  diff:  0.20\n",
      "probs:  3.48,  label:  3.50,  diff: -0.02\n",
      "probs:  1.47,  label:  0.86,  diff:  0.61\n",
      "probs:  3.10,  label:  3.29,  diff: -0.18\n",
      "probs:  4.23,  label:  4.67,  diff: -0.43\n",
      "probs:  4.43,  label:  4.57,  diff: -0.14\n",
      "probs:  4.14,  label:  4.57,  diff: -0.43\n",
      "probs:  4.31,  label:  4.33,  diff: -0.03\n",
      "probs:  0.93,  label:  1.33,  diff: -0.41\n",
      "probs:  3.86,  label:  3.67,  diff:  0.20\n",
      "probs:  4.09,  label:  4.00,  diff:  0.09\n",
      "probs: -0.10,  label:  0.00,  diff: -0.10\n",
      "probs:  0.81,  label:  0.20,  diff:  0.61\n",
      "probs:  0.02,  label:  0.00,  diff:  0.02\n",
      "probs:  0.02,  label:  0.00,  diff:  0.02\n",
      "probs:  0.03,  label:  0.00,  diff:  0.03\n",
      "probs:  1.14,  label:  1.17,  diff: -0.02\n",
      "probs:  3.12,  label:  1.33,  diff:  1.79\n",
      "probs:  0.01,  label:  0.43,  diff: -0.42\n",
      "probs:  4.06,  label:  4.17,  diff: -0.11\n",
      "probs:  0.31,  label:  0.00,  diff:  0.31\n",
      "probs:  4.28,  label:  4.17,  diff:  0.11\n",
      "probs:  3.92,  label:  3.67,  diff:  0.25\n",
      "probs: -0.04,  label:  0.00,  diff: -0.04\n",
      "probs:  3.74,  label:  3.86,  diff: -0.12\n",
      "probs:  0.05,  label:  0.00,  diff:  0.05\n",
      "probs:  0.21,  label:  0.17,  diff:  0.04\n",
      "probs:  0.03,  label:  0.00,  diff:  0.03\n",
      "probs: -0.03,  label:  0.00,  diff: -0.03\n",
      "probs:  4.31,  label:  4.17,  diff:  0.14\n",
      "probs:  4.03,  label:  3.83,  diff:  0.19\n",
      "probs:  4.46,  label:  4.20,  diff:  0.26\n",
      "probs:  4.19,  label:  3.50,  diff:  0.69\n",
      "probs:  0.39,  label:  0.43,  diff: -0.04\n",
      "probs:  4.50,  label:  4.50,  diff: -0.00\n",
      "probs:  2.04,  label:  2.00,  diff:  0.04\n",
      "probs:  3.84,  label:  3.86,  diff: -0.02\n",
      "probs:  0.37,  label:  0.71,  diff: -0.35\n",
      "probs:  4.11,  label:  4.43,  diff: -0.32\n",
      "probs:  0.07,  label:  0.00,  diff:  0.07\n",
      "probs:  0.18,  label:  0.00,  diff:  0.18\n",
      "probs:  4.12,  label:  4.00,  diff:  0.12\n",
      "probs:  4.14,  label:  4.00,  diff:  0.14\n",
      "probs:  0.92,  label:  0.33,  diff:  0.58\n",
      "probs:  4.00,  label:  4.00,  diff: -0.00\n",
      "probs:  4.44,  label:  4.17,  diff:  0.28\n",
      "probs:  0.32,  label:  0.50,  diff: -0.18\n",
      "probs:  2.37,  label:  2.67,  diff: -0.29\n",
      "probs:  3.88,  label:  3.60,  diff:  0.28\n",
      "probs:  4.20,  label:  4.17,  diff:  0.03\n",
      "probs:  0.29,  label:  0.33,  diff: -0.04\n",
      "probs:  3.77,  label:  3.50,  diff:  0.27\n",
      "probs: -0.12,  label:  0.00,  diff: -0.12\n",
      "probs:  3.38,  label:  3.33,  diff:  0.05\n",
      "probs:  0.01,  label:  0.00,  diff:  0.01\n",
      "probs:  3.83,  label:  4.20,  diff: -0.37\n",
      "probs: -0.15,  label:  0.00,  diff: -0.15\n",
      "probs:  3.43,  label:  3.57,  diff: -0.14\n",
      "probs:  4.19,  label:  4.29,  diff: -0.09\n",
      "probs:  4.50,  label:  4.67,  diff: -0.16\n",
      "probs:  3.23,  label:  2.83,  diff:  0.40\n",
      "probs:  0.39,  label:  0.50,  diff: -0.11\n",
      "probs:  3.73,  label:  2.57,  diff:  1.16\n",
      "probs:  0.08,  label:  0.00,  diff:  0.08\n",
      "probs:  1.26,  label:  0.83,  diff:  0.43\n",
      "probs:  4.51,  label:  4.00,  diff:  0.51\n",
      "probs:  4.25,  label:  3.71,  diff:  0.54\n",
      "probs:  0.08,  label:  0.33,  diff: -0.25\n",
      "probs:  3.76,  label:  4.00,  diff: -0.24\n",
      "probs:  4.19,  label:  4.00,  diff:  0.19\n",
      "probs:  0.13,  label:  0.29,  diff: -0.15\n",
      "probs:  3.80,  label:  3.67,  diff:  0.13\n",
      "probs:  0.19,  label:  0.17,  diff:  0.03\n",
      "probs:  0.08,  label:  0.00,  diff:  0.08\n",
      "probs:  4.15,  label:  4.33,  diff: -0.18\n",
      "probs:  4.32,  label:  3.86,  diff:  0.46\n",
      "probs:  4.44,  label:  4.43,  diff:  0.01\n",
      "probs:  4.09,  label:  3.86,  diff:  0.24\n",
      "probs:  0.14,  label:  0.00,  diff:  0.14\n",
      "probs:  4.10,  label:  3.83,  diff:  0.27\n",
      "probs:  1.86,  label:  3.67,  diff: -1.81\n",
      "probs:  4.04,  label:  3.00,  diff:  1.04\n",
      "probs:  4.61,  label:  5.00,  diff: -0.39\n",
      "probs:  0.32,  label:  0.67,  diff: -0.34\n",
      "probs:  3.96,  label:  3.50,  diff:  0.46\n",
      "probs:  1.20,  label:  1.60,  diff: -0.40\n",
      "probs: -0.03,  label:  0.17,  diff: -0.19\n",
      "probs:  1.17,  label:  2.00,  diff: -0.83\n",
      "probs:  0.14,  label:  0.17,  diff: -0.02\n",
      "probs:  3.53,  label:  2.80,  diff:  0.73\n",
      "probs:  4.32,  label:  4.17,  diff:  0.15\n",
      "probs:  4.30,  label:  4.40,  diff: -0.10\n",
      "probs:  4.48,  label:  4.43,  diff:  0.05\n",
      "probs:  4.34,  label:  4.00,  diff:  0.34\n",
      "probs: -0.06,  label:  0.00,  diff: -0.06\n",
      "probs:  4.30,  label:  4.17,  diff:  0.13\n",
      "probs:  0.26,  label:  0.29,  diff: -0.03\n",
      "probs:  0.50,  label:  0.17,  diff:  0.34\n",
      "probs:  3.94,  label:  3.50,  diff:  0.44\n",
      "probs:  0.39,  label:  0.14,  diff:  0.24\n",
      "probs:  4.01,  label:  3.50,  diff:  0.51\n",
      "probs:  3.93,  label:  3.71,  diff:  0.22\n",
      "probs: -0.03,  label:  0.00,  diff: -0.03\n",
      "probs:  3.67,  label:  3.71,  diff: -0.04\n",
      "probs:  0.87,  label:  1.20,  diff: -0.33\n",
      "probs:  0.08,  label:  0.00,  diff:  0.08\n",
      "probs:  3.92,  label:  4.00,  diff: -0.08\n",
      "probs:  0.17,  label:  0.00,  diff:  0.17\n",
      "probs:  0.15,  label:  0.00,  diff:  0.15\n",
      "probs:  0.13,  label:  0.00,  diff:  0.13\n",
      "probs:  4.27,  label:  3.86,  diff:  0.42\n",
      "probs:  4.36,  label:  4.14,  diff:  0.22\n",
      "probs:  2.18,  label:  2.14,  diff:  0.04\n",
      "probs:  3.99,  label:  3.50,  diff:  0.49\n",
      "probs:  0.14,  label:  0.43,  diff: -0.29\n",
      "probs:  4.26,  label:  4.00,  diff:  0.26\n",
      "probs:  3.80,  label:  2.33,  diff:  1.46\n",
      "probs:  4.08,  label:  4.14,  diff: -0.07\n",
      "probs:  4.46,  label:  4.43,  diff:  0.03\n",
      "probs:  0.24,  label:  0.57,  diff: -0.33\n",
      "probs:  4.15,  label:  4.00,  diff:  0.15\n",
      "probs:  4.36,  label:  4.60,  diff: -0.24\n",
      "probs:  4.18,  label:  3.50,  diff:  0.68\n",
      "probs:  0.02,  label:  0.00,  diff:  0.02\n",
      "probs:  4.21,  label:  3.50,  diff:  0.71\n",
      "probs:  2.67,  label:  2.50,  diff:  0.17\n",
      "probs:  3.76,  label:  3.67,  diff:  0.09\n",
      "probs:  2.77,  label:  1.29,  diff:  1.48\n",
      "probs:  0.23,  label:  0.20,  diff:  0.03\n",
      "probs:  3.84,  label:  4.00,  diff: -0.16\n",
      "probs:  1.80,  label:  1.50,  diff:  0.30\n",
      "probs:  1.22,  label:  0.80,  diff:  0.42\n",
      "probs:  3.29,  label:  2.71,  diff:  0.58\n",
      "probs:  4.12,  label:  3.57,  diff:  0.55\n",
      "probs:  1.10,  label:  0.67,  diff:  0.43\n",
      "probs:  0.26,  label:  0.17,  diff:  0.09\n",
      "probs:  1.04,  label:  1.33,  diff: -0.30\n",
      "probs:  3.67,  label:  4.14,  diff: -0.48\n",
      "probs:  3.53,  label:  2.86,  diff:  0.67\n",
      "probs:  4.14,  label:  3.67,  diff:  0.47\n",
      "probs:  4.04,  label:  3.00,  diff:  1.04\n",
      "probs:  4.34,  label:  4.33,  diff:  0.01\n",
      "probs:  0.10,  label:  0.33,  diff: -0.23\n",
      "probs: -0.01,  label:  0.00,  diff: -0.01\n",
      "probs:  4.44,  label:  3.83,  diff:  0.60\n",
      "probs:  4.48,  label:  4.00,  diff:  0.48\n",
      "probs:  4.34,  label:  3.67,  diff:  0.67\n",
      "probs: -0.05,  label:  0.00,  diff: -0.05\n",
      "probs:  2.34,  label:  1.00,  diff:  1.34\n",
      "probs:  4.21,  label:  4.17,  diff:  0.05\n",
      "probs:  4.19,  label:  4.40,  diff: -0.21\n",
      "probs:  4.37,  label:  4.67,  diff: -0.29\n",
      "probs:  0.81,  label:  0.33,  diff:  0.48\n",
      "probs:  0.07,  label:  0.00,  diff:  0.07\n",
      "probs:  4.10,  label:  4.00,  diff:  0.10\n",
      "probs:  0.17,  label:  0.29,  diff: -0.12\n",
      "probs:  0.23,  label:  0.00,  diff:  0.23\n",
      "probs:  1.73,  label:  2.71,  diff: -0.98\n",
      "probs:  4.36,  label:  4.50,  diff: -0.14\n",
      "probs:  1.22,  label:  1.67,  diff: -0.44\n",
      "probs:  4.20,  label:  3.40,  diff:  0.80\n",
      "probs:  0.16,  label:  0.00,  diff:  0.16\n",
      "probs:  0.25,  label:  0.67,  diff: -0.41\n",
      "probs:  0.08,  label:  0.00,  diff:  0.08\n",
      "probs:  0.84,  label:  0.71,  diff:  0.13\n",
      "probs:  4.34,  label:  3.86,  diff:  0.48\n",
      "probs:  4.49,  label:  4.43,  diff:  0.06\n",
      "probs:  0.22,  label:  0.57,  diff: -0.35\n",
      "probs:  3.81,  label:  3.17,  diff:  0.65\n",
      "probs: -0.13,  label:  0.00,  diff: -0.13\n",
      "probs: -0.12,  label:  0.00,  diff: -0.12\n",
      "probs:  0.09,  label:  0.00,  diff:  0.09\n",
      "probs:  3.62,  label:  4.00,  diff: -0.38\n",
      "probs:  1.04,  label:  0.71,  diff:  0.33\n",
      "probs:  3.60,  label:  2.86,  diff:  0.74\n",
      "probs:  3.71,  label:  3.57,  diff:  0.14\n",
      "probs:  4.36,  label:  4.29,  diff:  0.08\n",
      "probs:  4.38,  label:  4.57,  diff: -0.19\n",
      "probs:  0.05,  label:  0.00,  diff:  0.05\n",
      "probs:  4.13,  label:  3.71,  diff:  0.41\n",
      "probs:  3.98,  label:  4.00,  diff: -0.02\n",
      "probs:  3.56,  label:  4.29,  diff: -0.72\n",
      "probs:  3.46,  label:  3.57,  diff: -0.11\n",
      "probs:  0.05,  label:  0.00,  diff:  0.05\n",
      "probs:  0.22,  label:  0.33,  diff: -0.11\n",
      "probs: -0.03,  label:  0.17,  diff: -0.20\n",
      "probs:  3.74,  label:  3.17,  diff:  0.57\n",
      "probs:  4.37,  label:  4.00,  diff:  0.37\n",
      "probs:  4.14,  label:  4.20,  diff: -0.06\n",
      "probs:  0.04,  label:  0.00,  diff:  0.04\n",
      "probs:  4.04,  label:  3.67,  diff:  0.38\n",
      "probs:  4.21,  label:  4.33,  diff: -0.12\n",
      "probs:  3.26,  label:  3.33,  diff: -0.07\n",
      "probs:  3.38,  label:  2.67,  diff:  0.72\n",
      "probs: -0.06,  label:  0.00,  diff: -0.06\n",
      "probs:  0.45,  label:  0.00,  diff:  0.45\n",
      "probs:  4.02,  label:  4.00,  diff:  0.02\n",
      "probs:  3.53,  label:  3.00,  diff:  0.53\n",
      "probs:  0.27,  label:  0.17,  diff:  0.11\n",
      "probs:  0.03,  label:  0.00,  diff:  0.03\n",
      "probs:  1.58,  label:  1.50,  diff:  0.08\n",
      "probs:  0.01,  label:  0.17,  diff: -0.15\n",
      "probs:  0.64,  label:  0.67,  diff: -0.03\n",
      "probs:  2.68,  label:  3.00,  diff: -0.32\n",
      "probs:  0.13,  label:  0.29,  diff: -0.16\n",
      "probs:  0.73,  label:  0.20,  diff:  0.53\n",
      "probs:  2.30,  label:  0.83,  diff:  1.47\n",
      "probs:  3.55,  label:  2.57,  diff:  0.98\n",
      "probs:  3.94,  label:  3.50,  diff:  0.44\n",
      "probs:  4.35,  label:  4.14,  diff:  0.21\n",
      "probs:  0.33,  label:  0.14,  diff:  0.18\n",
      "probs:  0.02,  label:  0.00,  diff:  0.02\n",
      "probs:  4.12,  label:  4.14,  diff: -0.02\n",
      "probs:  4.37,  label:  4.20,  diff:  0.17\n",
      "probs:  3.51,  label:  3.33,  diff:  0.18\n",
      "probs:  0.20,  label:  0.20,  diff: -0.00\n",
      "probs:  0.06,  label:  0.00,  diff:  0.06\n",
      "probs:  4.42,  label:  4.14,  diff:  0.28\n",
      "probs:  0.27,  label:  0.17,  diff:  0.10\n",
      "probs:  1.07,  label:  0.71,  diff:  0.36\n",
      "probs:  4.15,  label:  3.83,  diff:  0.32\n",
      "probs:  2.08,  label:  0.80,  diff:  1.28\n",
      "probs:  4.02,  label:  3.57,  diff:  0.45\n",
      "probs:  3.82,  label:  3.67,  diff:  0.15\n",
      "probs: -0.08,  label:  0.00,  diff: -0.08\n",
      "probs:  4.09,  label:  4.17,  diff: -0.07\n",
      "probs:  4.26,  label:  4.17,  diff:  0.09\n",
      "probs:  4.02,  label:  3.57,  diff:  0.45\n",
      "probs:  3.17,  label:  4.17,  diff: -1.00\n",
      "probs:  0.35,  label:  0.50,  diff: -0.15\n",
      "probs:  4.11,  label:  3.33,  diff:  0.78\n",
      "probs:  1.79,  label:  1.29,  diff:  0.50\n",
      "probs:  3.00,  label:  4.33,  diff: -1.33\n",
      "probs:  0.13,  label:  0.29,  diff: -0.15\n",
      "probs:  0.52,  label:  0.60,  diff: -0.08\n",
      "probs:  0.85,  label:  0.33,  diff:  0.52\n",
      "probs:  4.06,  label:  4.29,  diff: -0.22\n",
      "probs:  4.48,  label:  4.80,  diff: -0.32\n",
      "probs:  4.37,  label:  3.83,  diff:  0.54\n",
      "probs:  4.45,  label:  4.67,  diff: -0.21\n",
      "probs:  3.88,  label:  4.20,  diff: -0.32\n",
      "probs:  0.03,  label:  0.00,  diff:  0.03\n",
      "probs:  4.25,  label:  4.00,  diff:  0.25\n",
      "probs:  3.93,  label:  3.83,  diff:  0.10\n",
      "probs:  2.01,  label:  0.67,  diff:  1.34\n",
      "probs:  4.25,  label:  3.67,  diff:  0.59\n",
      "probs:  0.45,  label:  1.17,  diff: -0.72\n",
      "probs:  0.50,  label:  0.57,  diff: -0.07\n",
      "probs:  4.49,  label:  4.43,  diff:  0.06\n",
      "probs:  3.62,  label:  3.50,  diff:  0.12\n",
      "probs:  3.83,  label:  3.86,  diff: -0.03\n",
      "probs:  4.12,  label:  4.33,  diff: -0.22\n",
      "probs:  3.82,  label:  3.50,  diff:  0.32\n",
      "probs:  2.99,  label:  3.00,  diff: -0.01\n",
      "probs:  0.18,  label:  0.00,  diff:  0.18\n",
      "probs:  3.58,  label:  3.00,  diff:  0.58\n",
      "probs:  1.23,  label:  1.71,  diff: -0.48\n",
      "probs:  0.85,  label:  0.33,  diff:  0.51\n",
      "probs:  3.30,  label:  2.83,  diff:  0.46\n",
      "probs: -0.02,  label:  0.00,  diff: -0.02\n",
      "probs:  4.27,  label:  4.43,  diff: -0.15\n",
      "probs:  3.99,  label:  3.67,  diff:  0.32\n",
      "probs:  0.53,  label:  1.33,  diff: -0.81\n",
      "probs:  0.01,  label:  0.00,  diff:  0.01\n",
      "probs:  4.03,  label:  3.57,  diff:  0.46\n",
      "probs:  3.89,  label:  3.67,  diff:  0.22\n",
      "probs:  0.11,  label:  0.00,  diff:  0.11\n",
      "probs:  4.29,  label:  4.29,  diff:  0.00\n",
      "probs:  3.80,  label:  4.00,  diff: -0.20\n",
      "probs:  4.42,  label:  4.14,  diff:  0.28\n",
      "probs:  0.22,  label:  0.33,  diff: -0.12\n",
      "probs:  0.01,  label:  0.00,  diff:  0.01\n",
      "probs:  4.06,  label:  4.00,  diff:  0.06\n",
      "probs:  3.84,  label:  3.67,  diff:  0.17\n",
      "probs:  4.18,  label:  4.00,  diff:  0.18\n",
      "probs:  3.99,  label:  3.33,  diff:  0.65\n",
      "probs:  4.28,  label:  4.17,  diff:  0.12\n",
      "probs:  0.05,  label:  0.00,  diff:  0.05\n",
      "probs:  4.53,  label:  4.17,  diff:  0.37\n",
      "probs:  1.98,  label:  3.00,  diff: -1.02\n",
      "probs:  0.38,  label:  0.71,  diff: -0.34\n",
      "probs:  4.36,  label:  4.29,  diff:  0.07\n",
      "probs: -0.10,  label:  0.00,  diff: -0.10\n",
      "probs:  4.32,  label:  3.83,  diff:  0.49\n",
      "probs: -0.00,  label:  0.17,  diff: -0.17\n",
      "probs:  0.02,  label:  0.00,  diff:  0.02\n",
      "probs:  3.59,  label:  3.43,  diff:  0.17\n",
      "probs:  4.19,  label:  4.43,  diff: -0.24\n",
      "probs: -0.14,  label:  0.00,  diff: -0.14\n",
      "probs:  0.66,  label:  1.29,  diff: -0.63\n",
      "probs:  4.13,  label:  4.29,  diff: -0.16\n",
      "probs:  0.03,  label:  0.00,  diff:  0.03\n",
      "probs:  1.27,  label:  1.00,  diff:  0.27\n",
      "probs:  2.04,  label:  1.86,  diff:  0.19\n",
      "probs:  4.13,  label:  3.50,  diff:  0.63\n",
      "probs:  4.15,  label:  3.71,  diff:  0.44\n",
      "probs:  1.84,  label:  2.50,  diff: -0.66\n",
      "probs:  3.86,  label:  3.43,  diff:  0.43\n",
      "probs:  3.92,  label:  3.71,  diff:  0.21\n",
      "probs:  0.10,  label:  0.14,  diff: -0.04\n",
      "probs:  4.16,  label:  4.00,  diff:  0.16\n",
      "probs:  0.22,  label:  0.00,  diff:  0.22\n",
      "probs:  4.41,  label:  4.33,  diff:  0.08\n",
      "probs:  3.47,  label:  2.60,  diff:  0.87\n",
      "probs:  3.73,  label:  4.00,  diff: -0.27\n",
      "probs:  3.73,  label:  3.29,  diff:  0.45\n",
      "probs:  0.23,  label:  0.00,  diff:  0.23\n",
      "probs:  0.04,  label:  0.00,  diff:  0.04\n",
      "probs:  4.10,  label:  3.67,  diff:  0.44\n",
      "probs:  0.19,  label:  0.17,  diff:  0.02\n",
      "probs:  4.10,  label:  4.00,  diff:  0.10\n",
      "probs:  4.29,  label:  4.40,  diff: -0.11\n",
      "probs:  4.18,  label:  4.17,  diff:  0.02\n",
      "probs:  4.06,  label:  3.71,  diff:  0.35\n",
      "probs:  0.61,  label:  0.83,  diff: -0.22\n",
      "probs:  4.39,  label:  4.71,  diff: -0.33\n",
      "probs:  3.98,  label:  3.86,  diff:  0.12\n",
      "probs:  3.79,  label:  3.83,  diff: -0.04\n",
      "probs:  4.17,  label:  4.33,  diff: -0.16\n",
      "probs:  4.45,  label:  4.50,  diff: -0.05\n",
      "probs:  0.38,  label:  0.71,  diff: -0.33\n",
      "probs:  4.23,  label:  4.17,  diff:  0.07\n",
      "probs:  3.96,  label:  4.00,  diff: -0.04\n",
      "probs:  4.22,  label:  3.00,  diff:  1.22\n",
      "probs:  1.06,  label:  0.17,  diff:  0.90\n",
      "probs:  0.13,  label:  0.00,  diff:  0.13\n",
      "probs:  4.18,  label:  2.86,  diff:  1.32\n",
      "probs: -0.02,  label:  0.00,  diff: -0.02\n",
      "probs:  0.18,  label:  0.00,  diff:  0.18\n",
      "probs:  3.60,  label:  4.00,  diff: -0.40\n",
      "probs:  0.44,  label:  0.33,  diff:  0.10\n",
      "probs:  4.28,  label:  4.50,  diff: -0.22\n",
      "probs:  0.05,  label:  0.00,  diff:  0.05\n",
      "probs:  1.83,  label:  1.83,  diff:  0.00\n",
      "probs:  3.55,  label:  4.00,  diff: -0.45\n",
      "probs: -0.07,  label:  0.00,  diff: -0.07\n",
      "probs:  4.15,  label:  3.60,  diff:  0.55\n",
      "probs:  1.34,  label:  1.60,  diff: -0.26\n",
      "probs:  4.21,  label:  4.20,  diff:  0.01\n",
      "probs:  3.69,  label:  3.50,  diff:  0.19\n",
      "probs:  2.43,  label:  3.50,  diff: -1.07\n",
      "probs:  3.37,  label:  2.00,  diff:  1.37\n",
      "probs:  4.26,  label:  3.67,  diff:  0.59\n",
      "probs:  3.86,  label:  3.67,  diff:  0.19\n",
      "probs:  4.37,  label:  4.86,  diff: -0.49\n",
      "probs:  3.83,  label:  3.14,  diff:  0.68\n",
      "probs:  0.50,  label:  0.50,  diff: -0.00\n",
      "probs:  4.54,  label:  4.71,  diff: -0.17\n",
      "probs:  4.41,  label:  3.83,  diff:  0.58\n",
      "probs:  2.08,  label:  2.20,  diff: -0.12\n",
      "probs:  4.23,  label:  4.00,  diff:  0.23\n",
      "probs:  0.20,  label:  0.50,  diff: -0.30\n",
      "probs:  4.47,  label:  3.83,  diff:  0.64\n",
      "probs:  4.15,  label:  4.29,  diff: -0.13\n",
      "probs:  1.73,  label:  4.00,  diff: -2.27\n",
      "probs:  0.79,  label:  1.17,  diff: -0.38\n",
      "probs:  4.40,  label:  4.50,  diff: -0.10\n",
      "probs:  0.13,  label:  0.00,  diff:  0.13\n",
      "probs:  0.03,  label:  0.00,  diff:  0.03\n",
      "probs:  4.29,  label:  4.57,  diff: -0.29\n",
      "probs:  4.05,  label:  3.67,  diff:  0.39\n",
      "probs:  3.86,  label:  3.00,  diff:  0.86\n",
      "probs:  1.62,  label:  1.86,  diff: -0.24\n",
      "probs:  4.32,  label:  4.71,  diff: -0.39\n",
      "probs:  2.45,  label:  2.29,  diff:  0.17\n",
      "probs:  3.34,  label:  2.00,  diff:  1.34\n",
      "probs:  4.33,  label:  4.67,  diff: -0.33\n",
      "probs:  4.31,  label:  3.86,  diff:  0.46\n",
      "probs:  3.28,  label:  0.57,  diff:  2.71\n",
      "probs:  0.08,  label:  0.00,  diff:  0.08\n",
      "probs:  1.41,  label:  0.83,  diff:  0.57\n",
      "probs:  4.38,  label:  4.17,  diff:  0.21\n",
      "probs:  0.15,  label:  0.00,  diff:  0.15\n",
      "probs:  4.29,  label:  4.00,  diff:  0.29\n",
      "probs:  0.26,  label:  0.33,  diff: -0.08\n",
      "probs:  0.16,  label:  0.67,  diff: -0.51\n",
      "probs:  3.74,  label:  4.00,  diff: -0.26\n",
      "probs:  1.40,  label:  1.83,  diff: -0.44\n",
      "probs:  0.08,  label:  0.14,  diff: -0.07\n",
      "probs: -0.00,  label:  0.00,  diff: -0.00\n",
      "probs:  3.35,  label:  1.71,  diff:  1.64\n",
      "probs: -0.02,  label:  0.00,  diff: -0.02\n",
      "probs:  0.25,  label:  0.00,  diff:  0.25\n",
      "probs:  0.17,  label:  0.33,  diff: -0.17\n",
      "probs:  4.09,  label:  4.71,  diff: -0.63\n",
      "probs:  2.19,  label:  1.20,  diff:  0.99\n",
      "probs:  0.04,  label:  0.00,  diff:  0.04\n",
      "probs:  0.18,  label:  0.00,  diff:  0.18\n",
      "probs:  4.37,  label:  3.83,  diff:  0.54\n",
      "probs:  4.13,  label:  3.57,  diff:  0.56\n",
      "probs:  4.43,  label:  3.17,  diff:  1.26\n",
      "probs:  4.09,  label:  3.50,  diff:  0.59\n",
      "probs:  3.89,  label:  3.33,  diff:  0.56\n",
      "probs:  4.20,  label:  4.14,  diff:  0.06\n",
      "probs:  0.11,  label:  0.00,  diff:  0.11\n",
      "probs:  4.24,  label:  3.33,  diff:  0.91\n",
      "probs: -0.01,  label:  0.00,  diff: -0.01\n",
      "probs: -0.14,  label:  0.00,  diff: -0.14\n",
      "probs:  0.24,  label:  0.00,  diff:  0.24\n",
      "probs:  4.18,  label:  3.00,  diff:  1.18\n",
      "probs:  4.31,  label:  4.00,  diff:  0.31\n",
      "probs: -0.05,  label:  0.00,  diff: -0.05\n",
      "probs:  0.06,  label:  0.00,  diff:  0.06\n",
      "probs:  0.28,  label:  0.14,  diff:  0.14\n",
      "probs: -0.02,  label:  0.00,  diff: -0.02\n",
      "probs:  4.43,  label:  3.67,  diff:  0.76\n",
      "probs:  4.27,  label:  3.80,  diff:  0.47\n",
      "probs: -0.11,  label:  0.00,  diff: -0.11\n",
      "probs:  3.29,  label:  2.67,  diff:  0.62\n",
      "probs:  4.07,  label:  4.00,  diff:  0.07\n",
      "probs:  3.13,  label:  3.86,  diff: -0.73\n",
      "probs:  4.19,  label:  4.33,  diff: -0.15\n",
      "probs:  0.05,  label:  0.00,  diff:  0.05\n",
      "probs:  0.11,  label:  0.50,  diff: -0.39\n",
      "probs:  0.29,  label:  0.14,  diff:  0.15\n",
      "probs:  4.31,  label:  4.29,  diff:  0.03\n",
      "probs:  3.59,  label:  3.83,  diff: -0.24\n",
      "probs: -0.11,  label:  0.00,  diff: -0.11\n",
      "probs:  3.83,  label:  3.50,  diff:  0.33\n",
      "probs:  4.17,  label:  3.83,  diff:  0.33\n",
      "probs:  4.14,  label:  3.86,  diff:  0.28\n",
      "probs:  1.26,  label:  0.57,  diff:  0.69\n",
      "probs:  4.20,  label:  4.00,  diff:  0.20\n",
      "probs:  3.79,  label:  3.33,  diff:  0.46\n",
      "probs:  1.31,  label:  2.00,  diff: -0.69\n",
      "probs:  0.06,  label:  0.29,  diff: -0.23\n",
      "probs:  0.64,  label:  0.14,  diff:  0.50\n",
      "probs:  0.17,  label:  0.00,  diff:  0.17\n",
      "probs:  4.33,  label:  3.67,  diff:  0.66\n",
      "probs:  3.00,  label:  2.50,  diff:  0.50\n",
      "probs:  0.05,  label:  0.00,  diff:  0.05\n",
      "probs:  2.19,  label:  1.40,  diff:  0.79\n",
      "probs:  4.34,  label:  4.50,  diff: -0.16\n",
      "probs:  3.98,  label:  2.83,  diff:  1.15\n",
      "probs:  3.99,  label:  4.50,  diff: -0.51\n",
      "probs:  3.47,  label:  3.50,  diff: -0.03\n",
      "probs:  0.08,  label:  0.00,  diff:  0.08\n",
      "probs:  0.81,  label:  0.57,  diff:  0.24\n",
      "probs:  2.62,  label:  4.17,  diff: -1.55\n",
      "probs:  0.54,  label:  0.14,  diff:  0.40\n",
      "probs:  4.27,  label:  4.00,  diff:  0.27\n",
      "probs: -0.01,  label:  0.00,  diff: -0.01\n",
      "probs:  4.18,  label:  4.17,  diff:  0.01\n",
      "probs:  4.47,  label:  4.67,  diff: -0.20\n",
      "probs:  4.33,  label:  4.17,  diff:  0.17\n",
      "probs:  0.45,  label:  0.00,  diff:  0.45\n",
      "probs:  0.67,  label:  0.29,  diff:  0.38\n",
      "probs:  3.76,  label:  3.57,  diff:  0.19\n",
      "probs:  2.88,  label:  2.50,  diff:  0.38\n",
      "probs: -0.04,  label:  0.00,  diff: -0.04\n",
      "probs:  0.12,  label:  0.00,  diff:  0.12\n",
      "probs: -0.02,  label:  0.00,  diff: -0.02\n",
      "probs:  1.25,  label:  1.33,  diff: -0.08\n",
      "probs:  1.40,  label:  1.50,  diff: -0.10\n",
      "probs:  2.30,  label:  1.83,  diff:  0.46\n",
      "probs: -0.01,  label:  0.00,  diff: -0.01\n",
      "probs:  1.66,  label:  0.86,  diff:  0.80\n",
      "probs: -0.04,  label:  0.00,  diff: -0.04\n",
      "probs:  4.22,  label:  3.80,  diff:  0.42\n",
      "probs:  3.70,  label:  3.40,  diff:  0.30\n",
      "probs:  3.42,  label:  3.33,  diff:  0.08\n",
      "probs:  4.49,  label:  4.83,  diff: -0.35\n",
      "probs:  0.18,  label:  0.00,  diff:  0.18\n",
      "probs:  0.92,  label:  0.40,  diff:  0.52\n",
      "probs:  3.63,  label:  3.17,  diff:  0.46\n",
      "probs:  1.50,  label:  1.29,  diff:  0.22\n",
      "probs:  4.16,  label:  3.67,  diff:  0.50\n",
      "probs:  1.06,  label:  1.00,  diff:  0.06\n",
      "probs:  2.79,  label:  2.17,  diff:  0.62\n",
      "probs:  4.11,  label:  3.80,  diff:  0.31\n",
      "probs: -0.05,  label:  0.00,  diff: -0.05\n",
      "probs:  0.60,  label:  0.57,  diff:  0.03\n",
      "probs:  4.08,  label:  3.67,  diff:  0.41\n",
      "probs:  4.09,  label:  3.80,  diff:  0.29\n",
      "probs:  3.93,  label:  3.71,  diff:  0.22\n",
      "probs:  3.93,  label:  4.33,  diff: -0.40\n",
      "probs:  0.09,  label:  0.00,  diff:  0.09\n",
      "probs:  4.25,  label:  3.71,  diff:  0.54\n",
      "probs:  3.96,  label:  3.00,  diff:  0.96\n",
      "probs:  3.94,  label:  4.33,  diff: -0.40\n",
      "probs:  0.49,  label:  0.17,  diff:  0.32\n",
      "probs:  3.15,  label:  3.17,  diff: -0.01\n",
      "probs:  4.39,  label:  4.67,  diff: -0.28\n",
      "probs:  4.05,  label:  3.00,  diff:  1.05\n",
      "probs:  4.34,  label:  4.33,  diff:  0.01\n",
      "probs:  1.09,  label:  1.00,  diff:  0.09\n",
      "probs:  3.90,  label:  4.17,  diff: -0.27\n",
      "probs: -0.00,  label:  0.00,  diff: -0.00\n",
      "probs:  0.05,  label:  0.40,  diff: -0.35\n",
      "probs:  3.72,  label:  3.43,  diff:  0.29\n",
      "probs:  3.75,  label:  3.29,  diff:  0.47\n",
      "probs:  3.65,  label:  3.33,  diff:  0.32\n",
      "probs:  1.72,  label:  2.33,  diff: -0.61\n",
      "probs:  2.40,  label:  1.33,  diff:  1.07\n",
      "probs:  0.60,  label:  1.20,  diff: -0.60\n",
      "probs:  4.02,  label:  3.67,  diff:  0.35\n",
      "probs:  0.40,  label:  0.86,  diff: -0.46\n",
      "probs:  4.06,  label:  3.33,  diff:  0.72\n",
      "probs:  0.03,  label:  0.00,  diff:  0.03\n",
      "probs:  3.31,  label:  2.83,  diff:  0.47\n",
      "probs:  2.51,  label:  3.60,  diff: -1.09\n",
      "probs:  4.28,  label:  4.50,  diff: -0.22\n",
      "probs:  4.55,  label:  4.33,  diff:  0.21\n",
      "probs:  3.91,  label:  3.57,  diff:  0.34\n",
      "probs:  3.69,  label:  4.33,  diff: -0.64\n",
      "probs:  0.06,  label:  0.00,  diff:  0.06\n",
      "probs:  0.05,  label:  0.14,  diff: -0.09\n",
      "probs:  0.01,  label:  0.00,  diff:  0.01\n",
      "probs:  4.36,  label:  4.67,  diff: -0.31\n",
      "probs:  4.10,  label:  3.50,  diff:  0.60\n",
      "probs:  4.13,  label:  4.00,  diff:  0.13\n",
      "probs: -0.01,  label:  0.33,  diff: -0.35\n",
      "probs:  1.56,  label:  1.17,  diff:  0.40\n",
      "probs:  2.04,  label:  2.00,  diff:  0.04\n",
      "probs:  3.58,  label:  4.00,  diff: -0.42\n",
      "probs: -0.02,  label:  0.00,  diff: -0.02\n",
      "probs:  4.46,  label:  4.80,  diff: -0.34\n",
      "probs:  2.97,  label:  2.67,  diff:  0.30\n",
      "probs:  4.06,  label:  4.57,  diff: -0.51\n",
      "probs:  4.52,  label:  3.83,  diff:  0.68\n",
      "probs:  0.27,  label:  0.33,  diff: -0.06\n",
      "probs:  4.10,  label:  4.00,  diff:  0.10\n",
      "probs: -0.01,  label:  0.00,  diff: -0.01\n",
      "probs:  1.08,  label:  1.67,  diff: -0.59\n",
      "probs:  0.20,  label:  0.67,  diff: -0.46\n",
      "probs:  4.20,  label:  3.83,  diff:  0.36\n",
      "probs:  3.25,  label:  3.00,  diff:  0.25\n",
      "probs:  0.38,  label:  0.00,  diff:  0.38\n",
      "probs:  4.14,  label:  4.57,  diff: -0.44\n",
      "probs:  4.22,  label:  4.00,  diff:  0.22\n",
      "probs:  3.95,  label:  3.71,  diff:  0.23\n",
      "probs:  4.54,  label:  4.57,  diff: -0.03\n",
      "probs:  0.15,  label:  0.00,  diff:  0.15\n",
      "probs:  4.05,  label:  3.50,  diff:  0.55\n",
      "probs:  0.26,  label:  0.57,  diff: -0.31\n",
      "probs:  1.56,  label:  2.14,  diff: -0.58\n",
      "probs:  4.43,  label:  4.20,  diff:  0.23\n",
      "probs:  3.59,  label:  3.17,  diff:  0.43\n",
      "probs:  4.35,  label:  3.86,  diff:  0.49\n",
      "probs:  0.03,  label:  0.14,  diff: -0.12\n",
      "probs:  1.39,  label:  0.57,  diff:  0.81\n",
      "probs:  3.91,  label:  4.33,  diff: -0.43\n",
      "probs:  3.64,  label:  3.57,  diff:  0.07\n",
      "probs: -0.06,  label:  0.50,  diff: -0.56\n",
      "probs:  0.04,  label:  0.00,  diff:  0.04\n",
      "probs:  0.07,  label:  0.00,  diff:  0.07\n",
      "probs: -0.05,  label:  0.20,  diff: -0.25\n",
      "probs:  1.47,  label:  1.83,  diff: -0.36\n",
      "probs:  0.61,  label:  0.71,  diff: -0.10\n",
      "probs:  2.30,  label:  1.00,  diff:  1.30\n",
      "probs:  3.94,  label:  4.00,  diff: -0.06\n",
      "probs:  3.76,  label:  3.17,  diff:  0.59\n",
      "probs:  3.66,  label:  3.67,  diff: -0.00\n",
      "probs:  3.69,  label:  4.00,  diff: -0.31\n",
      "probs:  3.90,  label:  3.20,  diff:  0.70\n",
      "probs:  0.66,  label:  0.00,  diff:  0.66\n",
      "probs:  4.00,  label:  3.67,  diff:  0.33\n",
      "probs:  4.03,  label:  4.00,  diff:  0.03\n",
      "probs:  0.94,  label:  0.00,  diff:  0.94\n",
      "probs:  1.07,  label:  0.43,  diff:  0.64\n",
      "probs:  0.20,  label:  0.00,  diff:  0.20\n",
      "probs:  2.96,  label:  2.67,  diff:  0.30\n",
      "probs:  0.23,  label:  0.43,  diff: -0.20\n",
      "probs:  4.35,  label:  4.00,  diff:  0.35\n",
      "probs:  0.10,  label:  0.00,  diff:  0.10\n",
      "probs:  3.49,  label:  3.67,  diff: -0.17\n",
      "probs:  3.23,  label:  3.50,  diff: -0.27\n",
      "probs:  0.53,  label:  0.17,  diff:  0.36\n",
      "probs:  0.05,  label:  0.00,  diff:  0.05\n",
      "probs:  1.25,  label:  2.00,  diff: -0.75\n",
      "probs:  4.28,  label:  3.40,  diff:  0.88\n",
      "probs:  0.13,  label:  0.00,  diff:  0.13\n",
      "probs:  0.82,  label:  0.83,  diff: -0.01\n",
      "probs:  3.95,  label:  3.20,  diff:  0.75\n",
      "probs:  0.02,  label:  0.00,  diff:  0.02\n",
      "probs:  4.06,  label:  3.83,  diff:  0.23\n",
      "probs:  4.27,  label:  4.29,  diff: -0.02\n",
      "probs:  3.64,  label:  4.00,  diff: -0.36\n",
      "probs:  4.14,  label:  3.83,  diff:  0.30\n",
      "probs:  3.93,  label:  3.33,  diff:  0.59\n",
      "probs:  4.09,  label:  4.00,  diff:  0.09\n",
      "probs:  0.67,  label:  0.17,  diff:  0.51\n",
      "probs:  0.61,  label:  1.00,  diff: -0.39\n",
      "probs:  4.38,  label:  4.71,  diff: -0.33\n",
      "probs:  0.99,  label:  1.50,  diff: -0.51\n",
      "probs: -0.09,  label:  0.00,  diff: -0.09\n",
      "probs:  4.22,  label:  3.80,  diff:  0.42\n",
      "probs:  0.13,  label:  0.00,  diff:  0.13\n",
      "probs:  3.98,  label:  3.83,  diff:  0.14\n",
      "probs: -0.12,  label:  0.00,  diff: -0.12\n",
      "probs:  3.84,  label:  3.14,  diff:  0.70\n",
      "probs:  0.86,  label:  1.17,  diff: -0.31\n",
      "probs:  3.92,  label:  3.14,  diff:  0.78\n",
      "probs:  0.10,  label:  0.00,  diff:  0.10\n",
      "probs:  0.11,  label:  0.00,  diff:  0.11\n",
      "probs:  4.40,  label:  4.33,  diff:  0.06\n",
      "probs:  3.89,  label:  3.80,  diff:  0.09\n",
      "probs:  2.94,  label:  2.00,  diff:  0.94\n",
      "probs:  1.44,  label:  0.17,  diff:  1.28\n",
      "probs: -0.09,  label:  0.00,  diff: -0.09\n",
      "probs:  4.09,  label:  4.17,  diff: -0.08\n",
      "probs:  3.87,  label:  3.71,  diff:  0.16\n",
      "probs:  3.06,  label:  2.71,  diff:  0.35\n",
      "probs:  4.38,  label:  4.33,  diff:  0.05\n",
      "probs:  4.14,  label:  4.14,  diff:  0.00\n",
      "probs:  1.11,  label:  1.00,  diff:  0.11\n",
      "probs:  4.11,  label:  4.00,  diff:  0.11\n",
      "probs:  4.17,  label:  3.83,  diff:  0.34\n",
      "probs:  4.11,  label:  4.33,  diff: -0.22\n",
      "probs:  3.57,  label:  3.00,  diff:  0.57\n",
      "probs:  0.09,  label:  0.00,  diff:  0.09\n",
      "probs:  3.93,  label:  3.14,  diff:  0.79\n",
      "probs:  0.09,  label:  0.00,  diff:  0.09\n",
      "probs:  0.70,  label:  0.29,  diff:  0.42\n",
      "probs:  0.14,  label:  0.14,  diff: -0.00\n",
      "probs:  4.34,  label:  3.67,  diff:  0.67\n",
      "probs:  4.02,  label:  4.00,  diff:  0.02\n",
      "probs:  3.95,  label:  3.33,  diff:  0.62\n",
      "probs:  0.06,  label:  0.00,  diff:  0.06\n",
      "probs:  0.69,  label:  1.17,  diff: -0.48\n",
      "probs: -0.03,  label:  0.00,  diff: -0.03\n",
      "probs:  4.58,  label:  4.29,  diff:  0.29\n",
      "probs:  1.26,  label:  1.83,  diff: -0.58\n",
      "probs:  3.95,  label:  3.50,  diff:  0.45\n",
      "probs:  0.60,  label:  0.60,  diff: -0.00\n",
      "probs:  4.47,  label:  3.67,  diff:  0.80\n",
      "probs:  0.03,  label:  0.14,  diff: -0.12\n",
      "probs:  0.08,  label:  0.00,  diff:  0.08\n",
      "probs:  0.15,  label:  0.29,  diff: -0.14\n",
      "probs:  3.47,  label:  3.60,  diff: -0.13\n",
      "probs:  4.58,  label:  5.00,  diff: -0.42\n",
      "probs:  4.23,  label:  3.67,  diff:  0.57\n",
      "probs:  0.22,  label:  0.00,  diff:  0.22\n",
      "probs:  4.26,  label:  3.83,  diff:  0.42\n",
      "probs:  0.69,  label:  1.00,  diff: -0.31\n",
      "probs:  4.10,  label:  3.83,  diff:  0.26\n",
      "probs:  0.01,  label:  0.00,  diff:  0.01\n",
      "probs:  4.05,  label:  4.00,  diff:  0.05\n",
      "probs:  1.22,  label:  0.43,  diff:  0.79\n",
      "probs:  0.08,  label:  0.00,  diff:  0.08\n",
      "probs:  4.11,  label:  4.00,  diff:  0.11\n",
      "probs: -0.06,  label:  0.14,  diff: -0.20\n",
      "probs: -0.08,  label:  0.00,  diff: -0.08\n",
      "probs:  4.23,  label:  4.50,  diff: -0.27\n",
      "probs:  4.44,  label:  4.57,  diff: -0.13\n",
      "probs:  2.38,  label:  1.40,  diff:  0.98\n",
      "probs:  4.41,  label:  4.00,  diff:  0.41\n",
      "probs:  0.65,  label:  1.29,  diff: -0.64\n",
      "probs:  4.22,  label:  4.17,  diff:  0.05\n",
      "probs:  3.44,  label:  1.86,  diff:  1.58\n",
      "probs:  4.06,  label:  4.33,  diff: -0.27\n",
      "probs:  3.77,  label:  3.67,  diff:  0.11\n",
      "probs:  2.86,  label:  2.17,  diff:  0.70\n",
      "probs:  4.07,  label:  4.14,  diff: -0.07\n",
      "probs:  0.09,  label:  0.00,  diff:  0.09\n",
      "probs:  4.24,  label:  4.33,  diff: -0.09\n",
      "probs:  3.93,  label:  3.14,  diff:  0.78\n",
      "probs: -0.05,  label:  0.71,  diff: -0.76\n",
      "probs:  4.13,  label:  4.00,  diff:  0.13\n",
      "probs: -0.01,  label:  0.00,  diff: -0.01\n",
      "probs:  0.04,  label:  0.00,  diff:  0.04\n",
      "probs: -0.12,  label:  0.00,  diff: -0.12\n",
      "probs:  0.01,  label:  0.00,  diff:  0.01\n",
      "probs:  4.38,  label:  3.83,  diff:  0.55\n",
      "probs:  0.42,  label:  1.40,  diff: -0.98\n",
      "probs:  0.66,  label:  0.17,  diff:  0.49\n",
      "probs:  0.06,  label:  0.00,  diff:  0.06\n",
      "probs:  0.40,  label:  0.67,  diff: -0.27\n",
      "probs:  4.45,  label:  4.67,  diff: -0.21\n",
      "probs:  4.17,  label:  3.33,  diff:  0.84\n",
      "probs:  4.25,  label:  3.57,  diff:  0.68\n",
      "probs:  0.85,  label:  3.67,  diff: -2.81\n",
      "probs:  3.95,  label:  3.83,  diff:  0.12\n",
      "probs:  2.42,  label:  2.33,  diff:  0.09\n",
      "probs:  0.73,  label:  1.17,  diff: -0.44\n",
      "probs:  4.34,  label:  4.00,  diff:  0.34\n",
      "probs:  0.24,  label:  0.17,  diff:  0.08\n",
      "probs: -0.07,  label:  0.29,  diff: -0.36\n",
      "probs:  4.25,  label:  3.57,  diff:  0.68\n",
      "probs:  4.32,  label:  3.71,  diff:  0.61\n",
      "probs:  2.88,  label:  1.67,  diff:  1.21\n",
      "probs:  4.00,  label:  3.71,  diff:  0.28\n",
      "probs:  3.48,  label:  3.33,  diff:  0.15\n",
      "probs: -0.07,  label:  0.00,  diff: -0.07\n",
      "probs:  0.66,  label:  0.67,  diff: -0.01\n",
      "probs:  0.27,  label:  0.29,  diff: -0.01\n",
      "probs:  0.07,  label:  0.00,  diff:  0.07\n",
      "probs:  0.16,  label:  0.00,  diff:  0.16\n",
      "probs: -0.07,  label:  0.00,  diff: -0.07\n",
      "probs:  4.32,  label:  4.57,  diff: -0.25\n",
      "probs:  0.60,  label:  0.67,  diff: -0.06\n",
      "probs:  0.37,  label:  0.00,  diff:  0.37\n",
      "probs:  4.37,  label:  4.00,  diff:  0.37\n",
      "probs:  0.06,  label:  0.00,  diff:  0.06\n",
      "probs:  4.08,  label:  4.20,  diff: -0.12\n",
      "probs:  4.09,  label:  4.33,  diff: -0.24\n",
      "probs:  3.89,  label:  3.29,  diff:  0.60\n",
      "probs:  4.34,  label:  4.57,  diff: -0.23\n",
      "probs:  4.02,  label:  3.67,  diff:  0.35\n",
      "probs:  4.19,  label:  3.14,  diff:  1.05\n",
      "probs:  4.05,  label:  3.50,  diff:  0.55\n",
      "probs:  3.84,  label:  3.43,  diff:  0.41\n",
      "probs:  4.34,  label:  3.80,  diff:  0.54\n",
      "probs:  0.46,  label:  0.17,  diff:  0.29\n",
      "probs:  4.36,  label:  3.86,  diff:  0.50\n",
      "probs:  4.17,  label:  3.33,  diff:  0.84\n",
      "probs:  3.13,  label:  2.67,  diff:  0.46\n",
      "probs:  4.28,  label:  4.29,  diff: -0.01\n",
      "probs:  3.59,  label:  3.33,  diff:  0.25\n",
      "probs:  3.91,  label:  3.83,  diff:  0.08\n",
      "probs:  4.46,  label:  4.60,  diff: -0.14\n",
      "probs:  3.08,  label:  1.50,  diff:  1.58\n",
      "probs:  0.03,  label:  0.00,  diff:  0.03\n",
      "probs:  0.16,  label:  0.00,  diff:  0.16\n",
      "probs: -0.03,  label:  0.00,  diff: -0.03\n",
      "probs:  0.20,  label:  0.67,  diff: -0.47\n",
      "probs:  4.05,  label:  3.60,  diff:  0.45\n",
      "probs:  4.25,  label:  4.40,  diff: -0.15\n",
      "probs:  1.92,  label:  2.33,  diff: -0.42\n",
      "probs:  0.07,  label:  0.00,  diff:  0.07\n",
      "probs:  1.16,  label:  1.20,  diff: -0.04\n",
      "probs:  1.36,  label:  1.57,  diff: -0.21\n",
      "probs:  0.11,  label:  0.00,  diff:  0.11\n",
      "probs:  4.05,  label:  4.43,  diff: -0.37\n",
      "probs:  4.31,  label:  3.20,  diff:  1.11\n",
      "probs:  4.32,  label:  4.00,  diff:  0.32\n",
      "probs:  3.64,  label:  4.17,  diff: -0.53\n",
      "probs:  4.12,  label:  3.80,  diff:  0.32\n",
      "probs:  4.14,  label:  3.33,  diff:  0.81\n",
      "probs:  0.42,  label:  0.00,  diff:  0.42\n",
      "probs:  0.00,  label:  0.00,  diff:  0.00\n",
      "probs:  0.87,  label:  0.33,  diff:  0.54\n",
      "probs:  4.05,  label:  3.43,  diff:  0.62\n",
      "probs:  0.88,  label:  1.33,  diff: -0.45\n",
      "probs:  3.93,  label:  3.67,  diff:  0.26\n",
      "probs:  4.38,  label:  4.50,  diff: -0.12\n",
      "probs:  0.22,  label:  0.00,  diff:  0.22\n",
      "probs: -0.05,  label:  0.00,  diff: -0.05\n",
      "probs:  1.16,  label:  0.86,  diff:  0.31\n",
      "probs: -0.01,  label:  0.00,  diff: -0.01\n",
      "probs:  0.08,  label:  0.00,  diff:  0.08\n",
      "probs:  4.18,  label:  4.43,  diff: -0.24\n",
      "probs:  3.72,  label:  3.83,  diff: -0.11\n",
      "probs:  0.16,  label:  0.00,  diff:  0.16\n",
      "probs:  3.68,  label:  3.67,  diff:  0.01\n",
      "probs:  0.14,  label:  0.00,  diff:  0.14\n",
      "probs:  1.47,  label:  1.20,  diff:  0.27\n",
      "probs:  0.30,  label:  0.00,  diff:  0.30\n",
      "probs:  0.34,  label:  0.17,  diff:  0.17\n",
      "probs:  0.03,  label:  0.57,  diff: -0.54\n",
      "probs:  0.61,  label:  0.00,  diff:  0.61\n",
      "probs:  0.12,  label:  0.00,  diff:  0.12\n",
      "probs:  3.64,  label:  4.00,  diff: -0.36\n",
      "probs:  1.27,  label:  1.29,  diff: -0.02\n",
      "probs:  2.66,  label:  3.00,  diff: -0.34\n",
      "probs:  0.03,  label:  0.17,  diff: -0.13\n",
      "probs:  3.78,  label:  3.67,  diff:  0.12\n",
      "probs:  4.23,  label:  3.50,  diff:  0.73\n",
      "probs:  1.03,  label:  0.86,  diff:  0.17\n",
      "probs:  0.10,  label:  0.20,  diff: -0.10\n",
      "probs:  4.37,  label:  4.20,  diff:  0.17\n",
      "probs:  4.33,  label:  3.86,  diff:  0.47\n",
      "probs:  0.14,  label:  0.00,  diff:  0.14\n",
      "probs:  0.18,  label:  0.17,  diff:  0.01\n",
      "probs:  4.40,  label:  4.50,  diff: -0.10\n",
      "probs:  0.68,  label:  0.00,  diff:  0.68\n",
      "probs:  0.70,  label:  0.00,  diff:  0.70\n",
      "probs:  4.17,  label:  4.00,  diff:  0.17\n",
      "probs:  4.40,  label:  4.20,  diff:  0.20\n",
      "probs:  4.10,  label:  3.86,  diff:  0.24\n",
      "probs:  0.03,  label:  0.00,  diff:  0.03\n",
      "probs:  4.12,  label:  4.57,  diff: -0.45\n",
      "probs:  2.75,  label:  2.50,  diff:  0.25\n",
      "probs:  4.19,  label:  4.00,  diff:  0.19\n",
      "probs:  0.10,  label:  0.20,  diff: -0.10\n",
      "probs:  0.41,  label:  0.14,  diff:  0.27\n",
      "probs:  3.78,  label:  3.43,  diff:  0.35\n",
      "probs:  0.01,  label:  0.00,  diff:  0.01\n",
      "probs:  1.11,  label:  1.00,  diff:  0.11\n",
      "probs:  1.32,  label:  0.67,  diff:  0.65\n",
      "probs: -0.04,  label:  0.14,  diff: -0.18\n",
      "probs:  0.24,  label:  0.29,  diff: -0.04\n",
      "probs:  4.45,  label:  4.50,  diff: -0.05\n",
      "probs:  1.68,  label:  1.29,  diff:  0.39\n",
      "probs:  4.22,  label:  4.20,  diff:  0.02\n",
      "probs:  4.15,  label:  4.00,  diff:  0.15\n",
      "probs:  0.11,  label:  0.17,  diff: -0.06\n",
      "probs:  4.27,  label:  4.57,  diff: -0.30\n",
      "probs:  4.32,  label:  4.00,  diff:  0.32\n",
      "probs:  0.16,  label:  0.00,  diff:  0.16\n",
      "probs:  3.27,  label:  3.80,  diff: -0.53\n",
      "probs:  2.29,  label:  1.67,  diff:  0.62\n",
      "probs: -0.15,  label:  0.00,  diff: -0.15\n",
      "probs:  0.09,  label:  0.00,  diff:  0.09\n",
      "probs:  0.23,  label:  0.50,  diff: -0.27\n",
      "probs:  4.19,  label:  4.33,  diff: -0.14\n",
      "probs: -0.11,  label:  0.00,  diff: -0.11\n",
      "probs:  2.87,  label:  1.67,  diff:  1.21\n",
      "probs:  2.91,  label:  2.17,  diff:  0.74\n",
      "probs:  4.40,  label:  4.50,  diff: -0.10\n",
      "probs:  0.86,  label:  1.00,  diff: -0.14\n",
      "probs:  3.98,  label:  4.17,  diff: -0.18\n",
      "probs:  2.27,  label:  1.60,  diff:  0.67\n",
      "probs: -0.05,  label:  0.00,  diff: -0.05\n",
      "probs:  4.36,  label:  5.00,  diff: -0.64\n",
      "probs:  4.16,  label:  4.57,  diff: -0.42\n",
      "probs:  0.74,  label:  1.29,  diff: -0.55\n",
      "probs:  3.35,  label:  2.33,  diff:  1.01\n",
      "probs:  4.26,  label:  4.33,  diff: -0.07\n",
      "probs:  0.01,  label:  0.00,  diff:  0.01\n",
      "probs:  3.89,  label:  2.57,  diff:  1.32\n",
      "probs:  3.49,  label:  3.43,  diff:  0.07\n",
      "probs:  4.39,  label:  4.43,  diff: -0.04\n",
      "probs:  0.11,  label:  0.00,  diff:  0.11\n",
      "probs:  0.18,  label:  0.14,  diff:  0.04\n",
      "probs:  1.13,  label:  1.83,  diff: -0.71\n",
      "probs:  4.22,  label:  3.50,  diff:  0.72\n",
      "probs:  4.37,  label:  4.60,  diff: -0.23\n",
      "probs: -0.11,  label:  0.00,  diff: -0.11\n",
      "probs:  4.17,  label:  3.50,  diff:  0.67\n",
      "probs:  3.81,  label:  3.17,  diff:  0.65\n",
      "probs:  4.26,  label:  4.50,  diff: -0.24\n",
      "probs:  0.72,  label:  0.50,  diff:  0.22\n",
      "probs: -0.06,  label:  0.00,  diff: -0.06\n",
      "probs:  1.65,  label:  1.67,  diff: -0.02\n",
      "probs:  0.05,  label:  0.00,  diff:  0.05\n",
      "probs:  0.27,  label:  0.57,  diff: -0.30\n",
      "probs:  0.57,  label:  1.14,  diff: -0.57\n",
      "probs:  3.50,  label:  3.43,  diff:  0.07\n",
      "probs:  1.27,  label:  1.14,  diff:  0.13\n",
      "probs: -0.04,  label:  0.00,  diff: -0.04\n",
      "probs:  4.15,  label:  3.33,  diff:  0.82\n",
      "probs:  0.65,  label:  0.80,  diff: -0.15\n",
      "probs:  0.06,  label:  0.00,  diff:  0.06\n",
      "probs:  0.55,  label:  0.67,  diff: -0.12\n",
      "probs:  0.00,  label:  0.20,  diff: -0.20\n",
      "probs:  2.97,  label:  2.86,  diff:  0.12\n",
      "probs:  4.60,  label:  5.00,  diff: -0.40\n",
      "probs:  0.21,  label:  0.14,  diff:  0.06\n",
      "probs:  4.10,  label:  4.17,  diff: -0.07\n",
      "probs:  3.82,  label:  3.71,  diff:  0.10\n",
      "probs:  3.86,  label:  3.43,  diff:  0.44\n",
      "probs:  0.17,  label:  0.00,  diff:  0.17\n",
      "probs:  4.15,  label:  3.57,  diff:  0.57\n",
      "probs:  0.04,  label:  0.00,  diff:  0.04\n",
      "probs:  3.88,  label:  3.50,  diff:  0.38\n",
      "probs:  3.71,  label:  3.00,  diff:  0.71\n",
      "probs:  4.20,  label:  3.83,  diff:  0.36\n",
      "probs:  3.66,  label:  4.17,  diff: -0.51\n",
      "probs:  4.15,  label:  3.17,  diff:  0.99\n",
      "probs:  3.27,  label:  3.83,  diff: -0.56\n",
      "probs:  0.05,  label:  0.00,  diff:  0.05\n",
      "probs:  4.37,  label:  4.33,  diff:  0.03\n",
      "probs:  0.54,  label:  0.80,  diff: -0.26\n",
      "probs:  0.01,  label:  0.00,  diff:  0.01\n",
      "probs:  2.96,  label:  3.86,  diff: -0.89\n",
      "probs:  4.52,  label:  4.29,  diff:  0.23\n",
      "probs:  0.92,  label:  0.33,  diff:  0.58\n",
      "probs:  0.65,  label:  0.14,  diff:  0.51\n",
      "probs:  4.51,  label:  4.83,  diff: -0.32\n",
      "probs:  3.25,  label:  1.60,  diff:  1.65\n",
      "probs:  3.85,  label:  3.83,  diff:  0.02\n",
      "probs:  3.60,  label:  3.14,  diff:  0.45\n",
      "probs:  4.37,  label:  4.71,  diff: -0.35\n",
      "probs:  4.28,  label:  4.67,  diff: -0.38\n",
      "probs:  3.94,  label:  3.67,  diff:  0.28\n",
      "probs:  1.08,  label:  2.00,  diff: -0.92\n",
      "probs:  3.88,  label:  3.67,  diff:  0.21\n",
      "probs:  1.09,  label:  0.33,  diff:  0.76\n",
      "probs:  0.29,  label:  0.29,  diff:  0.01\n",
      "probs:  4.05,  label:  4.14,  diff: -0.09\n",
      "probs:  4.45,  label:  4.00,  diff:  0.45\n",
      "probs:  4.19,  label:  4.57,  diff: -0.38\n",
      "probs:  4.15,  label:  3.67,  diff:  0.49\n",
      "probs:  0.06,  label:  0.57,  diff: -0.51\n",
      "probs:  0.34,  label:  0.17,  diff:  0.17\n",
      "probs:  2.23,  label:  2.40,  diff: -0.17\n",
      "probs:  0.26,  label:  0.50,  diff: -0.24\n",
      "probs:  0.07,  label:  0.00,  diff:  0.07\n",
      "probs:  1.47,  label:  2.00,  diff: -0.53\n",
      "probs: -0.10,  label:  0.00,  diff: -0.10\n",
      "probs:  0.14,  label:  0.00,  diff:  0.14\n",
      "probs:  0.82,  label:  0.67,  diff:  0.16\n",
      "probs:  4.17,  label:  4.00,  diff:  0.17\n",
      "probs:  0.54,  label:  0.00,  diff:  0.54\n",
      "probs:  0.29,  label:  0.00,  diff:  0.29\n",
      "probs:  0.16,  label:  0.00,  diff:  0.16\n",
      "probs:  4.20,  label:  4.17,  diff:  0.04\n",
      "probs:  3.82,  label:  4.00,  diff: -0.18\n",
      "probs:  4.22,  label:  4.00,  diff:  0.22\n",
      "probs:  0.01,  label:  0.00,  diff:  0.01\n",
      "probs:  4.13,  label:  3.83,  diff:  0.30\n",
      "probs:  0.08,  label:  0.20,  diff: -0.12\n",
      "probs:  4.23,  label:  3.43,  diff:  0.80\n",
      "probs:  4.38,  label:  4.86,  diff: -0.47\n",
      "probs:  0.39,  label:  0.17,  diff:  0.22\n",
      "probs:  0.13,  label:  0.00,  diff:  0.13\n",
      "probs:  0.99,  label:  0.50,  diff:  0.49\n",
      "probs:  1.52,  label:  0.67,  diff:  0.86\n",
      "probs:  1.52,  label:  0.50,  diff:  1.02\n",
      "probs:  4.27,  label:  3.57,  diff:  0.70\n",
      "probs:  0.07,  label:  0.00,  diff:  0.07\n",
      "probs:  0.20,  label:  0.00,  diff:  0.20\n",
      "probs:  4.45,  label:  4.67,  diff: -0.22\n",
      "probs:  4.38,  label:  4.17,  diff:  0.22\n",
      "probs:  1.46,  label:  0.86,  diff:  0.60\n",
      "probs:  4.20,  label:  4.33,  diff: -0.14\n",
      "probs:  3.91,  label:  4.17,  diff: -0.26\n",
      "probs:  1.81,  label:  1.50,  diff:  0.31\n",
      "probs:  4.39,  label:  3.57,  diff:  0.81\n",
      "probs: -0.11,  label:  0.00,  diff: -0.11\n",
      "probs:  4.22,  label:  4.00,  diff:  0.22\n",
      "probs:  3.98,  label:  4.40,  diff: -0.42\n",
      "probs:  4.38,  label:  4.40,  diff: -0.02\n",
      "probs:  4.37,  label:  4.33,  diff:  0.03\n",
      "probs:  1.82,  label:  0.67,  diff:  1.16\n",
      "probs: -0.05,  label:  0.00,  diff: -0.05\n",
      "probs:  4.35,  label:  4.57,  diff: -0.22\n",
      "probs:  0.12,  label:  0.00,  diff:  0.12\n",
      "probs:  4.10,  label:  3.67,  diff:  0.43\n",
      "probs:  0.03,  label:  0.14,  diff: -0.11\n",
      "probs:  4.13,  label:  2.83,  diff:  1.30\n",
      "probs:  0.20,  label:  0.43,  diff: -0.23\n",
      "probs:  0.29,  label:  0.57,  diff: -0.28\n",
      "probs:  4.31,  label:  4.17,  diff:  0.15\n",
      "probs:  0.08,  label:  0.00,  diff:  0.08\n",
      "probs:  4.10,  label:  3.00,  diff:  1.10\n",
      "probs:  4.31,  label:  3.86,  diff:  0.46\n",
      "probs:  3.46,  label:  3.86,  diff: -0.40\n",
      "probs:  0.08,  label:  0.00,  diff:  0.08\n",
      "probs:  4.52,  label:  4.00,  diff:  0.52\n",
      "probs:  3.92,  label:  4.00,  diff: -0.08\n",
      "probs:  0.12,  label:  0.00,  diff:  0.12\n",
      "probs:  0.06,  label:  0.33,  diff: -0.27\n",
      "probs:  0.17,  label:  0.17,  diff: -0.00\n",
      "probs:  2.54,  label:  1.60,  diff:  0.94\n",
      "probs:  3.82,  label:  1.14,  diff:  2.68\n",
      "probs:  3.70,  label:  3.71,  diff: -0.01\n",
      "probs:  3.70,  label:  3.00,  diff:  0.70\n",
      "probs:  3.31,  label:  3.29,  diff:  0.03\n",
      "probs:  0.05,  label:  0.00,  diff:  0.05\n",
      "probs:  4.31,  label:  4.33,  diff: -0.02\n",
      "probs:  3.83,  label:  3.43,  diff:  0.41\n",
      "probs:  4.31,  label:  4.43,  diff: -0.12\n",
      "probs:  0.27,  label:  0.43,  diff: -0.16\n",
      "probs:  1.93,  label:  1.80,  diff:  0.13\n",
      "probs:  4.08,  label:  3.57,  diff:  0.51\n",
      "probs:  2.75,  label:  1.14,  diff:  1.61\n",
      "probs:  4.26,  label:  4.00,  diff:  0.26\n",
      "probs:  4.22,  label:  4.67,  diff: -0.45\n",
      "probs:  0.39,  label:  1.67,  diff: -1.28\n",
      "probs: -0.01,  label:  0.00,  diff: -0.01\n",
      "probs:  0.63,  label:  0.67,  diff: -0.04\n",
      "probs:  4.09,  label:  4.17,  diff: -0.08\n",
      "probs:  4.27,  label:  3.57,  diff:  0.70\n",
      "probs:  1.41,  label:  0.50,  diff:  0.91\n",
      "probs: -0.07,  label:  0.17,  diff: -0.24\n",
      "probs:  4.00,  label:  3.80,  diff:  0.20\n",
      "probs:  3.95,  label:  3.83,  diff:  0.11\n",
      "probs:  4.08,  label:  3.17,  diff:  0.91\n",
      "probs:  1.23,  label:  1.14,  diff:  0.09\n",
      "probs:  4.40,  label:  4.67,  diff: -0.27\n",
      "probs:  0.30,  label:  0.33,  diff: -0.03\n",
      "probs:  4.58,  label:  4.40,  diff:  0.18\n",
      "probs:  0.18,  label:  0.40,  diff: -0.22\n",
      "probs:  0.74,  label:  0.57,  diff:  0.16\n",
      "probs:  0.02,  label:  0.00,  diff:  0.02\n",
      "probs:  3.63,  label:  3.14,  diff:  0.49\n",
      "probs:  0.31,  label:  0.00,  diff:  0.31\n",
      "probs:  3.76,  label:  3.29,  diff:  0.48\n",
      "probs:  0.79,  label:  1.00,  diff: -0.21\n",
      "probs:  3.69,  label:  3.20,  diff:  0.49\n",
      "probs: -0.12,  label:  0.00,  diff: -0.12\n",
      "probs:  4.20,  label:  3.43,  diff:  0.77\n",
      "probs: -0.10,  label:  0.00,  diff: -0.10\n",
      "probs: -0.03,  label:  0.00,  diff: -0.03\n",
      "probs:  3.90,  label:  4.00,  diff: -0.10\n",
      "probs:  4.33,  label:  4.33,  diff: -0.01\n",
      "probs:  3.63,  label:  3.43,  diff:  0.20\n",
      "probs: -0.00,  label:  0.40,  diff: -0.40\n",
      "probs:  2.46,  label:  2.20,  diff:  0.26\n",
      "probs:  0.27,  label:  0.43,  diff: -0.16\n",
      "probs:  0.04,  label:  0.00,  diff:  0.04\n",
      "probs:  4.40,  label:  4.00,  diff:  0.40\n",
      "probs:  0.08,  label:  0.43,  diff: -0.35\n",
      "probs:  0.05,  label:  0.00,  diff:  0.05\n",
      "probs:  0.05,  label:  0.00,  diff:  0.05\n",
      "probs:  0.89,  label:  0.67,  diff:  0.22\n",
      "probs:  4.12,  label:  4.14,  diff: -0.02\n",
      "probs:  2.14,  label:  1.33,  diff:  0.81\n",
      "probs:  0.04,  label:  0.17,  diff: -0.12\n",
      "probs: -0.10,  label:  0.00,  diff: -0.10\n",
      "probs:  4.07,  label:  4.00,  diff:  0.07\n",
      "probs:  0.25,  label:  0.57,  diff: -0.32\n",
      "probs:  3.92,  label:  3.57,  diff:  0.35\n",
      "probs:  0.72,  label:  0.83,  diff: -0.11\n",
      "probs:  4.37,  label:  3.86,  diff:  0.52\n",
      "probs:  3.92,  label:  3.86,  diff:  0.06\n",
      "probs:  2.21,  label:  1.83,  diff:  0.38\n",
      "probs:  0.93,  label:  0.71,  diff:  0.21\n",
      "probs:  3.64,  label:  3.14,  diff:  0.50\n",
      "probs:  3.43,  label:  2.83,  diff:  0.59\n",
      "probs:  2.60,  label:  2.00,  diff:  0.60\n",
      "probs:  3.88,  label:  3.00,  diff:  0.88\n",
      "probs:  2.34,  label:  1.20,  diff:  1.14\n",
      "probs:  4.37,  label:  3.71,  diff:  0.65\n",
      "probs:  3.66,  label:  3.83,  diff: -0.17\n",
      "probs:  0.20,  label:  0.00,  diff:  0.20\n",
      "probs:  2.86,  label:  2.43,  diff:  0.43\n",
      "probs:  4.44,  label:  4.71,  diff: -0.27\n",
      "probs:  3.98,  label:  3.43,  diff:  0.55\n",
      "probs:  4.44,  label:  5.00,  diff: -0.56\n",
      "probs:  0.24,  label:  0.00,  diff:  0.24\n",
      "probs:  0.11,  label:  0.00,  diff:  0.11\n",
      "probs: -0.02,  label:  0.43,  diff: -0.45\n",
      "probs:  4.05,  label:  3.00,  diff:  1.05\n",
      "probs:  3.32,  label:  3.71,  diff: -0.39\n",
      "probs:  0.77,  label:  0.00,  diff:  0.77\n",
      "probs:  4.06,  label:  4.71,  diff: -0.65\n",
      "probs:  4.01,  label:  3.57,  diff:  0.43\n",
      "probs:  4.02,  label:  3.43,  diff:  0.59\n",
      "probs:  4.19,  label:  4.00,  diff:  0.19\n",
      "probs:  3.84,  label:  3.86,  diff: -0.02\n",
      "probs:  2.92,  label:  2.29,  diff:  0.64\n",
      "probs:  3.30,  label:  2.00,  diff:  1.30\n",
      "probs:  0.08,  label:  0.00,  diff:  0.08\n",
      "probs:  4.12,  label:  3.83,  diff:  0.29\n",
      "probs:  0.17,  label:  0.00,  diff:  0.17\n",
      "probs:  0.82,  label:  1.00,  diff: -0.18\n",
      "probs:  4.27,  label:  4.17,  diff:  0.11\n",
      "probs:  3.82,  label:  1.33,  diff:  2.49\n",
      "probs:  0.08,  label:  0.00,  diff:  0.08\n",
      "probs:  3.12,  label:  1.86,  diff:  1.26\n",
      "probs:  4.22,  label:  4.57,  diff: -0.36\n",
      "probs:  4.08,  label:  3.33,  diff:  0.75\n",
      "probs:  4.38,  label:  4.00,  diff:  0.38\n",
      "probs:  1.05,  label:  1.17,  diff: -0.11\n",
      "probs:  4.35,  label:  3.83,  diff:  0.52\n",
      "probs:  3.96,  label:  4.33,  diff: -0.37\n",
      "probs:  4.24,  label:  3.67,  diff:  0.57\n",
      "probs:  4.03,  label:  4.17,  diff: -0.14\n",
      "probs:  4.28,  label:  4.57,  diff: -0.29\n",
      "probs:  0.21,  label:  0.00,  diff:  0.21\n",
      "probs: -0.04,  label:  0.00,  diff: -0.04\n",
      "probs:  4.01,  label:  4.00,  diff:  0.01\n",
      "probs:  0.16,  label:  0.29,  diff: -0.12\n",
      "probs:  0.41,  label:  0.20,  diff:  0.21\n",
      "probs:  0.08,  label:  0.00,  diff:  0.08\n",
      "probs: -0.04,  label:  0.00,  diff: -0.04\n",
      "probs:  3.66,  label:  3.33,  diff:  0.33\n",
      "probs:  0.16,  label:  0.33,  diff: -0.17\n",
      "probs: -0.03,  label:  0.00,  diff: -0.03\n",
      "probs:  0.05,  label:  0.00,  diff:  0.05\n",
      "probs:  0.08,  label:  0.00,  diff:  0.08\n",
      "probs:  4.38,  label:  3.40,  diff:  0.98\n",
      "probs:  4.02,  label:  3.83,  diff:  0.19\n",
      "probs:  0.26,  label:  0.00,  diff:  0.26\n",
      "probs:  4.15,  label:  3.50,  diff:  0.65\n",
      "probs:  4.09,  label:  4.50,  diff: -0.41\n",
      "probs:  4.27,  label:  4.33,  diff: -0.06\n",
      "probs:  3.92,  label:  4.17,  diff: -0.24\n",
      "probs:  3.81,  label:  3.43,  diff:  0.38\n",
      "probs:  3.50,  label:  3.00,  diff:  0.50\n",
      "probs:  4.16,  label:  4.00,  diff:  0.16\n",
      "probs:  1.19,  label:  1.00,  diff:  0.19\n",
      "probs:  4.17,  label:  3.83,  diff:  0.33\n",
      "probs:  3.81,  label:  2.80,  diff:  1.01\n",
      "probs:  3.49,  label:  4.33,  diff: -0.84\n",
      "probs:  0.81,  label:  0.67,  diff:  0.15\n",
      "probs:  0.55,  label:  0.86,  diff: -0.31\n",
      "probs:  0.06,  label:  0.20,  diff: -0.14\n",
      "probs:  4.30,  label:  3.43,  diff:  0.87\n",
      "probs:  4.28,  label:  4.00,  diff:  0.28\n",
      "probs:  0.01,  label:  0.00,  diff:  0.01\n",
      "probs:  3.99,  label:  4.33,  diff: -0.34\n",
      "probs:  0.14,  label:  0.00,  diff:  0.14\n",
      "probs:  0.38,  label:  0.43,  diff: -0.05\n",
      "probs:  4.23,  label:  3.67,  diff:  0.56\n",
      "probs:  0.10,  label:  0.00,  diff:  0.10\n",
      "probs:  3.86,  label:  3.00,  diff:  0.86\n",
      "probs:  3.90,  label:  3.50,  diff:  0.40\n",
      "probs:  3.34,  label:  3.17,  diff:  0.17\n",
      "probs:  4.23,  label:  3.83,  diff:  0.40\n",
      "probs:  4.07,  label:  4.20,  diff: -0.13\n",
      "probs:  4.42,  label:  4.83,  diff: -0.42\n",
      "probs:  0.08,  label:  0.33,  diff: -0.25\n",
      "probs: -0.04,  label:  0.00,  diff: -0.04\n",
      "probs:  0.33,  label:  0.00,  diff:  0.33\n",
      "probs:  4.05,  label:  3.17,  diff:  0.88\n",
      "probs:  3.54,  label:  3.14,  diff:  0.40\n",
      "probs:  4.23,  label:  4.00,  diff:  0.23\n",
      "probs:  0.16,  label:  0.33,  diff: -0.17\n",
      "probs:  0.48,  label:  1.00,  diff: -0.52\n",
      "probs:  4.45,  label:  4.00,  diff:  0.45\n",
      "probs:  3.58,  label:  3.00,  diff:  0.58\n",
      "probs:  0.05,  label:  0.00,  diff:  0.05\n",
      "probs:  0.15,  label:  0.00,  diff:  0.15\n",
      "probs:  0.12,  label:  0.14,  diff: -0.02\n",
      "probs:  3.80,  label:  3.29,  diff:  0.51\n",
      "probs:  0.74,  label:  2.29,  diff: -1.55\n",
      "probs:  4.27,  label:  4.00,  diff:  0.27\n",
      "probs:  0.91,  label:  1.57,  diff: -0.66\n",
      "probs: -0.02,  label:  0.33,  diff: -0.35\n",
      "probs:  1.63,  label:  2.17,  diff: -0.54\n",
      "probs:  1.28,  label:  1.57,  diff: -0.30\n",
      "probs:  4.45,  label:  4.57,  diff: -0.12\n",
      "probs:  0.11,  label:  0.40,  diff: -0.29\n",
      "probs:  4.13,  label:  3.43,  diff:  0.70\n",
      "probs:  4.12,  label:  3.00,  diff:  1.12\n",
      "probs:  3.18,  label:  3.60,  diff: -0.42\n",
      "probs:  4.49,  label:  4.50,  diff: -0.01\n",
      "probs:  4.22,  label:  4.40,  diff: -0.18\n",
      "probs:  4.39,  label:  3.29,  diff:  1.11\n",
      "probs:  4.46,  label:  4.33,  diff:  0.13\n",
      "probs:  1.06,  label:  1.00,  diff:  0.06\n",
      "probs:  4.06,  label:  3.29,  diff:  0.78\n",
      "probs:  4.34,  label:  4.00,  diff:  0.34\n",
      "probs:  4.41,  label:  4.33,  diff:  0.07\n",
      "probs:  4.25,  label:  4.00,  diff:  0.25\n",
      "probs:  0.18,  label:  0.33,  diff: -0.15\n",
      "probs:  4.46,  label:  4.40,  diff:  0.06\n",
      "probs:  1.74,  label:  2.00,  diff: -0.26\n",
      "probs:  0.12,  label:  0.43,  diff: -0.31\n",
      "probs:  4.30,  label:  3.83,  diff:  0.46\n",
      "probs:  3.56,  label:  2.67,  diff:  0.90\n",
      "probs:  3.70,  label:  3.67,  diff:  0.04\n",
      "probs:  4.12,  label:  4.17,  diff: -0.05\n",
      "probs:  4.10,  label:  3.83,  diff:  0.27\n",
      "probs:  3.03,  label:  3.00,  diff:  0.03\n",
      "probs:  4.46,  label:  4.50,  diff: -0.04\n",
      "probs:  1.10,  label:  1.71,  diff: -0.61\n",
      "probs:  2.56,  label:  0.86,  diff:  1.71\n",
      "probs:  3.94,  label:  3.20,  diff:  0.74\n",
      "probs:  4.10,  label:  3.71,  diff:  0.38\n",
      "probs:  3.78,  label:  3.33,  diff:  0.44\n",
      "probs:  3.96,  label:  4.17,  diff: -0.21\n",
      "probs:  1.38,  label:  1.17,  diff:  0.21\n",
      "probs:  4.20,  label:  3.67,  diff:  0.53\n",
      "probs:  3.42,  label:  2.29,  diff:  1.13\n",
      "probs:  4.53,  label:  4.29,  diff:  0.24\n",
      "probs:  0.82,  label:  0.20,  diff:  0.62\n",
      "probs:  3.79,  label:  3.29,  diff:  0.50\n",
      "probs:  3.81,  label:  4.17,  diff: -0.36\n",
      "probs:  3.93,  label:  3.17,  diff:  0.76\n",
      "probs:  0.54,  label:  0.50,  diff:  0.04\n",
      "probs:  0.99,  label:  1.20,  diff: -0.21\n",
      "probs:  0.07,  label:  0.00,  diff:  0.07\n",
      "probs:  3.67,  label:  3.29,  diff:  0.39\n",
      "probs:  4.11,  label:  3.86,  diff:  0.25\n",
      "probs:  4.52,  label:  4.57,  diff: -0.05\n",
      "probs:  3.64,  label:  2.00,  diff:  1.64\n",
      "probs:  0.01,  label:  0.00,  diff:  0.01\n",
      "probs:  0.00,  label:  0.00,  diff:  0.00\n",
      "probs:  0.15,  label:  0.20,  diff: -0.05\n",
      "probs:  3.97,  label:  3.50,  diff:  0.47\n",
      "probs:  0.25,  label:  0.00,  diff:  0.25\n",
      "probs:  0.33,  label:  0.17,  diff:  0.16\n",
      "probs:  3.55,  label:  3.60,  diff: -0.05\n",
      "probs:  1.20,  label:  1.00,  diff:  0.20\n",
      "probs:  1.93,  label:  1.67,  diff:  0.27\n",
      "probs:  0.03,  label:  0.00,  diff:  0.03\n",
      "probs:  4.05,  label:  4.00,  diff:  0.05\n",
      "probs:  3.99,  label:  4.67,  diff: -0.67\n",
      "probs:  3.63,  label:  3.83,  diff: -0.21\n",
      "probs:  0.16,  label:  0.00,  diff:  0.16\n",
      "probs:  3.97,  label:  3.33,  diff:  0.64\n",
      "probs:  2.72,  label:  2.71,  diff:  0.01\n",
      "probs:  4.32,  label:  3.71,  diff:  0.60\n",
      "probs:  3.01,  label:  3.14,  diff: -0.13\n",
      "probs:  4.02,  label:  3.57,  diff:  0.45\n",
      "probs:  1.28,  label:  1.33,  diff: -0.05\n",
      "probs: -0.02,  label:  0.00,  diff: -0.02\n",
      "probs:  1.94,  label:  1.00,  diff:  0.94\n",
      "probs:  4.34,  label:  4.33,  diff:  0.01\n",
      "probs:  4.02,  label:  3.67,  diff:  0.36\n",
      "probs:  4.15,  label:  3.86,  diff:  0.30\n",
      "probs:  2.30,  label:  2.14,  diff:  0.16\n",
      "probs: -0.03,  label:  0.14,  diff: -0.17\n",
      "probs:  3.81,  label:  3.43,  diff:  0.38\n",
      "probs:  0.08,  label:  0.00,  diff:  0.08\n",
      "probs:  0.27,  label:  0.67,  diff: -0.39\n",
      "probs:  4.44,  label:  4.60,  diff: -0.16\n",
      "probs:  4.03,  label:  3.86,  diff:  0.17\n",
      "probs:  4.18,  label:  4.17,  diff:  0.01\n",
      "probs:  1.15,  label:  0.83,  diff:  0.31\n",
      "probs:  0.33,  label:  0.50,  diff: -0.17\n",
      "probs:  0.07,  label:  0.00,  diff:  0.07\n",
      "probs:  3.91,  label:  3.17,  diff:  0.75\n",
      "probs:  0.11,  label:  0.17,  diff: -0.06\n",
      "probs:  0.00,  label:  0.00,  diff:  0.00\n",
      "probs: -0.04,  label:  0.00,  diff: -0.04\n",
      "probs:  0.05,  label:  0.00,  diff:  0.05\n",
      "probs:  3.95,  label:  3.83,  diff:  0.11\n",
      "probs:  0.10,  label:  0.80,  diff: -0.70\n",
      "probs:  4.23,  label:  4.29,  diff: -0.06\n",
      "probs: -0.00,  label:  0.00,  diff: -0.00\n",
      "probs:  4.26,  label:  3.83,  diff:  0.42\n",
      "probs:  0.60,  label:  0.60,  diff:  0.00\n",
      "probs:  3.60,  label:  3.00,  diff:  0.60\n",
      "probs:  0.26,  label:  0.60,  diff: -0.34\n",
      "probs:  2.97,  label:  2.83,  diff:  0.13\n",
      "probs:  3.76,  label:  3.43,  diff:  0.33\n",
      "probs:  4.42,  label:  4.17,  diff:  0.25\n",
      "probs:  3.80,  label:  3.67,  diff:  0.13\n",
      "probs: -0.14,  label:  0.00,  diff: -0.14\n",
      "probs:  0.56,  label:  0.50,  diff:  0.06\n",
      "probs:  4.01,  label:  3.33,  diff:  0.68\n",
      "probs: -0.04,  label:  0.00,  diff: -0.04\n",
      "probs:  4.23,  label:  4.60,  diff: -0.37\n",
      "probs:  4.49,  label:  4.67,  diff: -0.17\n",
      "probs:  0.21,  label:  0.00,  diff:  0.21\n",
      "probs:  0.60,  label:  0.43,  diff:  0.17\n",
      "probs:  4.15,  label:  4.14,  diff:  0.01\n",
      "probs: -0.17,  label:  0.00,  diff: -0.17\n",
      "probs:  4.03,  label:  4.33,  diff: -0.30\n",
      "probs:  4.00,  label:  4.17,  diff: -0.17\n",
      "probs:  4.50,  label:  4.83,  diff: -0.34\n",
      "probs:  4.04,  label:  3.33,  diff:  0.71\n",
      "probs: -0.04,  label:  0.33,  diff: -0.37\n",
      "probs:  4.26,  label:  4.43,  diff: -0.17\n",
      "probs:  4.49,  label:  5.00,  diff: -0.51\n",
      "probs:  0.04,  label:  0.00,  diff:  0.04\n",
      "probs: -0.09,  label:  0.00,  diff: -0.09\n",
      "probs:  3.83,  label:  3.71,  diff:  0.12\n",
      "probs:  4.18,  label:  3.50,  diff:  0.68\n",
      "probs:  4.25,  label:  4.67,  diff: -0.41\n",
      "probs:  1.95,  label:  2.60,  diff: -0.65\n",
      "probs:  0.39,  label:  0.71,  diff: -0.32\n",
      "probs:  0.10,  label:  0.00,  diff:  0.10\n",
      "probs:  0.85,  label:  0.17,  diff:  0.68\n",
      "probs: -0.02,  label:  0.00,  diff: -0.02\n",
      "probs:  3.94,  label:  4.00,  diff: -0.06\n",
      "probs:  0.06,  label:  0.33,  diff: -0.28\n",
      "probs:  3.77,  label:  3.71,  diff:  0.06\n",
      "probs:  3.97,  label:  3.00,  diff:  0.97\n",
      "probs:  3.34,  label:  2.29,  diff:  1.05\n",
      "probs:  4.31,  label:  4.33,  diff: -0.03\n",
      "probs:  4.05,  label:  3.71,  diff:  0.34\n",
      "probs:  4.40,  label:  4.33,  diff:  0.07\n",
      "probs: -0.01,  label:  0.00,  diff: -0.01\n",
      "probs:  4.15,  label:  4.57,  diff: -0.42\n",
      "probs:  3.83,  label:  3.50,  diff:  0.33\n",
      "probs:  1.53,  label:  1.00,  diff:  0.53\n",
      "probs:  4.36,  label:  4.00,  diff:  0.36\n",
      "probs:  0.22,  label:  0.00,  diff:  0.22\n",
      "probs:  4.33,  label:  4.40,  diff: -0.07\n",
      "probs:  4.13,  label:  4.00,  diff:  0.13\n",
      "probs:  0.17,  label:  0.00,  diff:  0.17\n",
      "probs:  4.16,  label:  4.20,  diff: -0.04\n",
      "probs:  2.00,  label:  2.67,  diff: -0.67\n",
      "probs: -0.01,  label:  0.00,  diff: -0.01\n",
      "probs:  3.88,  label:  3.86,  diff:  0.02\n",
      "probs:  4.38,  label:  4.17,  diff:  0.21\n",
      "probs:  0.56,  label:  0.50,  diff:  0.06\n",
      "probs:  4.40,  label:  4.33,  diff:  0.07\n",
      "probs:  0.17,  label:  0.43,  diff: -0.26\n",
      "probs:  4.23,  label:  4.14,  diff:  0.09\n",
      "probs:  3.84,  label:  2.86,  diff:  0.99\n",
      "probs:  0.02,  label:  0.83,  diff: -0.81\n",
      "probs:  0.09,  label:  0.00,  diff:  0.09\n",
      "probs:  4.23,  label:  4.50,  diff: -0.27\n",
      "probs: -0.03,  label:  0.00,  diff: -0.03\n",
      "probs:  1.11,  label:  1.33,  diff: -0.22\n",
      "probs:  3.87,  label:  3.67,  diff:  0.20\n",
      "probs:  3.97,  label:  4.29,  diff: -0.31\n",
      "probs:  4.46,  label:  4.17,  diff:  0.30\n",
      "probs:  4.21,  label:  4.50,  diff: -0.29\n",
      "probs:  0.05,  label:  0.00,  diff:  0.05\n",
      "probs:  0.19,  label:  0.50,  diff: -0.31\n",
      "probs:  3.94,  label:  3.00,  diff:  0.94\n",
      "probs:  4.26,  label:  3.29,  diff:  0.98\n",
      "probs:  3.55,  label:  2.29,  diff:  1.26\n",
      "probs:  3.85,  label:  4.29,  diff: -0.44\n",
      "probs:  1.60,  label:  1.71,  diff: -0.12\n",
      "probs:  4.12,  label:  4.43,  diff: -0.31\n",
      "probs:  0.22,  label:  0.00,  diff:  0.22\n",
      "probs:  0.99,  label:  1.83,  diff: -0.84\n",
      "probs:  4.51,  label:  4.83,  diff: -0.32\n",
      "probs:  0.52,  label:  0.33,  diff:  0.19\n",
      "probs:  3.85,  label:  4.14,  diff: -0.29\n",
      "probs:  0.36,  label:  0.00,  diff:  0.36\n",
      "probs:  4.06,  label:  4.00,  diff:  0.06\n",
      "probs:  4.36,  label:  4.29,  diff:  0.08\n",
      "probs:  0.15,  label:  0.00,  diff:  0.15\n",
      "probs:  4.13,  label:  3.29,  diff:  0.84\n",
      "probs: -0.06,  label:  0.17,  diff: -0.22\n",
      "probs:  4.11,  label:  3.86,  diff:  0.25\n",
      "probs:  4.32,  label:  4.33,  diff: -0.01\n",
      "probs:  0.11,  label:  0.00,  diff:  0.11\n",
      "probs:  3.88,  label:  4.29,  diff: -0.41\n",
      "probs:  1.45,  label:  1.33,  diff:  0.12\n",
      "probs:  4.03,  label:  4.43,  diff: -0.40\n",
      "probs: -0.01,  label:  0.00,  diff: -0.01\n",
      "probs: -0.06,  label:  0.00,  diff: -0.06\n",
      "probs:  0.97,  label:  0.86,  diff:  0.12\n",
      "probs:  0.64,  label:  0.29,  diff:  0.35\n",
      "probs:  4.31,  label:  3.29,  diff:  1.03\n",
      "probs:  1.40,  label:  0.67,  diff:  0.73\n",
      "probs: -0.02,  label:  0.33,  diff: -0.35\n",
      "probs:  0.53,  label:  0.14,  diff:  0.39\n",
      "probs:  0.49,  label:  0.29,  diff:  0.21\n",
      "probs:  0.24,  label:  0.43,  diff: -0.19\n",
      "probs:  3.61,  label:  3.00,  diff:  0.61\n",
      "probs:  4.47,  label:  4.00,  diff:  0.47\n",
      "probs: -0.11,  label:  0.00,  diff: -0.11\n",
      "probs:  1.94,  label:  0.83,  diff:  1.10\n",
      "probs:  1.69,  label:  1.17,  diff:  0.52\n",
      "probs: -0.10,  label:  0.00,  diff: -0.10\n",
      "probs:  0.09,  label:  0.00,  diff:  0.09\n",
      "probs:  0.19,  label:  0.00,  diff:  0.19\n",
      "probs:  0.08,  label:  0.00,  diff:  0.08\n",
      "probs:  0.16,  label:  0.00,  diff:  0.16\n",
      "probs:  4.18,  label:  3.60,  diff:  0.58\n",
      "probs:  4.09,  label:  4.00,  diff:  0.09\n",
      "probs:  2.22,  label:  2.00,  diff:  0.22\n",
      "probs:  1.87,  label:  0.86,  diff:  1.01\n",
      "probs:  4.23,  label:  4.00,  diff:  0.23\n",
      "probs:  3.04,  label:  2.57,  diff:  0.47\n",
      "probs:  0.07,  label:  0.14,  diff: -0.07\n",
      "probs:  1.73,  label:  1.17,  diff:  0.57\n",
      "probs:  1.58,  label:  0.29,  diff:  1.30\n",
      "probs:  3.58,  label:  4.17,  diff: -0.59\n",
      "probs:  4.02,  label:  3.67,  diff:  0.35\n",
      "probs:  0.82,  label:  0.86,  diff: -0.04\n",
      "probs:  4.35,  label:  4.00,  diff:  0.35\n",
      "probs:  3.00,  label:  2.20,  diff:  0.80\n",
      "probs:  3.72,  label:  2.50,  diff:  1.22\n",
      "probs:  4.44,  label:  3.83,  diff:  0.60\n",
      "probs:  4.18,  label:  3.50,  diff:  0.68\n",
      "probs:  4.42,  label:  4.60,  diff: -0.18\n",
      "probs:  4.08,  label:  2.14,  diff:  1.94\n",
      "probs:  0.15,  label:  0.71,  diff: -0.56\n",
      "probs:  4.05,  label:  3.33,  diff:  0.72\n",
      "probs:  3.27,  label:  3.86,  diff: -0.58\n",
      "probs:  3.87,  label:  4.00,  diff: -0.13\n",
      "probs:  3.82,  label:  4.67,  diff: -0.84\n",
      "probs: -0.02,  label:  0.00,  diff: -0.02\n",
      "probs: -0.09,  label:  0.14,  diff: -0.23\n",
      "probs:  3.97,  label:  3.86,  diff:  0.11\n",
      "probs:  0.43,  label:  0.17,  diff:  0.26\n",
      "probs:  3.68,  label:  3.00,  diff:  0.68\n",
      "probs:  3.05,  label:  2.17,  diff:  0.88\n",
      "probs:  0.04,  label:  0.14,  diff: -0.10\n",
      "probs:  4.26,  label:  4.17,  diff:  0.10\n",
      "probs:  1.28,  label:  1.00,  diff:  0.28\n",
      "probs:  2.39,  label:  2.50,  diff: -0.11\n",
      "probs: -0.07,  label:  0.00,  diff: -0.07\n",
      "probs:  0.05,  label:  0.00,  diff:  0.05\n",
      "probs:  3.87,  label:  3.83,  diff:  0.04\n",
      "probs:  3.42,  label:  3.00,  diff:  0.42\n",
      "probs: -0.06,  label:  0.00,  diff: -0.06\n",
      "probs:  1.51,  label:  0.50,  diff:  1.01\n",
      "probs: -0.06,  label:  0.00,  diff: -0.06\n",
      "probs:  0.33,  label:  0.33,  diff: -0.01\n",
      "probs:  2.20,  label:  2.17,  diff:  0.03\n",
      "probs:  4.26,  label:  4.00,  diff:  0.26\n",
      "probs:  4.04,  label:  4.40,  diff: -0.36\n",
      "probs:  4.37,  label:  4.83,  diff: -0.47\n",
      "probs:  0.10,  label:  0.17,  diff: -0.07\n",
      "probs:  3.91,  label:  4.20,  diff: -0.29\n",
      "probs:  0.13,  label:  0.00,  diff:  0.13\n",
      "probs:  0.16,  label:  0.29,  diff: -0.13\n",
      "probs:  4.00,  label:  4.43,  diff: -0.42\n",
      "probs:  0.85,  label:  1.43,  diff: -0.57\n",
      "probs:  0.13,  label:  0.00,  diff:  0.13\n",
      "probs:  0.25,  label:  0.17,  diff:  0.08\n",
      "probs:  4.36,  label:  3.80,  diff:  0.56\n",
      "probs:  4.53,  label:  4.14,  diff:  0.38\n",
      "probs:  4.27,  label:  4.00,  diff:  0.27\n",
      "probs:  3.68,  label:  3.67,  diff:  0.01\n",
      "probs:  3.86,  label:  4.33,  diff: -0.47\n",
      "probs:  0.16,  label:  0.00,  diff:  0.16\n",
      "probs: -0.05,  label:  0.00,  diff: -0.05\n",
      "probs:  0.08,  label:  0.00,  diff:  0.08\n",
      "probs:  2.06,  label:  3.00,  diff: -0.94\n",
      "probs:  4.17,  label:  4.33,  diff: -0.16\n",
      "probs: -0.07,  label:  0.00,  diff: -0.07\n",
      "probs:  0.24,  label:  0.00,  diff:  0.24\n",
      "probs:  0.34,  label:  0.00,  diff:  0.34\n",
      "probs:  0.13,  label:  0.00,  diff:  0.13\n",
      "probs:  4.18,  label:  4.14,  diff:  0.03\n",
      "probs: -0.03,  label:  0.00,  diff: -0.03\n",
      "probs:  2.47,  label:  2.00,  diff:  0.47\n",
      "probs:  3.92,  label:  4.20,  diff: -0.28\n",
      "probs:  3.15,  label:  3.00,  diff:  0.15\n",
      "probs:  1.43,  label:  3.50,  diff: -2.07\n",
      "probs: -0.15,  label:  0.00,  diff: -0.15\n",
      "probs:  0.09,  label:  0.00,  diff:  0.09\n",
      "probs: -0.00,  label:  0.17,  diff: -0.17\n",
      "probs: -0.14,  label:  0.00,  diff: -0.14\n",
      "probs:  4.28,  label:  4.43,  diff: -0.15\n",
      "probs:  0.00,  label:  0.00,  diff:  0.00\n",
      "probs:  4.01,  label:  4.14,  diff: -0.13\n",
      "probs:  4.00,  label:  3.20,  diff:  0.80\n",
      "probs:  4.14,  label:  4.17,  diff: -0.03\n",
      "probs:  1.86,  label:  1.33,  diff:  0.53\n",
      "probs:  0.42,  label:  0.14,  diff:  0.28\n",
      "probs:  4.23,  label:  4.00,  diff:  0.23\n",
      "probs:  0.59,  label:  0.57,  diff:  0.02\n",
      "probs:  0.07,  label:  0.00,  diff:  0.07\n",
      "probs:  4.14,  label:  4.00,  diff:  0.14\n",
      "probs:  4.02,  label:  3.50,  diff:  0.52\n",
      "probs:  2.81,  label:  0.83,  diff:  1.97\n",
      "probs:  4.22,  label:  4.00,  diff:  0.22\n",
      "probs:  3.77,  label:  3.60,  diff:  0.17\n",
      "probs:  3.76,  label:  3.00,  diff:  0.76\n",
      "probs:  4.09,  label:  3.00,  diff:  1.09\n",
      "probs:  0.29,  label:  0.43,  diff: -0.14\n",
      "probs:  3.82,  label:  3.17,  diff:  0.65\n",
      "probs:  3.68,  label:  4.00,  diff: -0.32\n",
      "probs:  4.31,  label:  4.17,  diff:  0.14\n",
      "probs: -0.03,  label:  0.00,  diff: -0.03\n",
      "probs:  2.67,  label:  1.00,  diff:  1.67\n",
      "probs:  0.77,  label:  0.33,  diff:  0.44\n",
      "probs:  2.35,  label:  3.67,  diff: -1.31\n",
      "probs:  4.26,  label:  3.57,  diff:  0.69\n",
      "probs:  0.08,  label:  0.00,  diff:  0.08\n",
      "probs:  4.29,  label:  4.17,  diff:  0.13\n",
      "probs:  3.97,  label:  4.33,  diff: -0.37\n",
      "probs:  1.43,  label:  0.86,  diff:  0.57\n",
      "probs:  4.51,  label:  4.57,  diff: -0.07\n",
      "probs:  4.47,  label:  3.71,  diff:  0.76\n",
      "probs:  0.18,  label:  0.00,  diff:  0.18\n",
      "probs:  4.07,  label:  3.60,  diff:  0.47\n",
      "probs:  4.03,  label:  3.86,  diff:  0.17\n",
      "probs:  4.31,  label:  4.50,  diff: -0.19\n",
      "probs:  2.69,  label:  1.83,  diff:  0.86\n",
      "probs:  4.33,  label:  3.83,  diff:  0.50\n",
      "probs:  0.05,  label:  0.00,  diff:  0.05\n",
      "probs:  1.16,  label:  1.67,  diff: -0.51\n",
      "probs:  0.20,  label:  0.00,  diff:  0.20\n",
      "probs:  1.09,  label:  1.67,  diff: -0.58\n",
      "probs:  0.22,  label:  0.00,  diff:  0.22\n",
      "probs:  0.05,  label:  0.00,  diff:  0.05\n",
      "probs: -0.02,  label:  0.00,  diff: -0.02\n",
      "probs:  3.96,  label:  3.67,  diff:  0.30\n",
      "probs:  0.42,  label:  0.71,  diff: -0.29\n",
      "probs:  3.91,  label:  3.43,  diff:  0.49\n",
      "probs:  4.22,  label:  4.00,  diff:  0.22\n",
      "probs:  0.33,  label:  0.67,  diff: -0.34\n",
      "probs:  4.15,  label:  4.00,  diff:  0.15\n",
      "probs: -0.06,  label:  0.00,  diff: -0.06\n",
      "probs:  3.09,  label:  3.17,  diff: -0.08\n",
      "probs:  3.77,  label:  3.29,  diff:  0.49\n",
      "probs:  0.55,  label:  0.14,  diff:  0.41\n",
      "probs:  0.13,  label:  0.50,  diff: -0.37\n",
      "probs:  3.27,  label:  3.71,  diff: -0.45\n",
      "probs:  2.34,  label:  2.83,  diff: -0.49\n",
      "probs:  1.31,  label:  1.00,  diff:  0.31\n",
      "probs:  3.81,  label:  3.57,  diff:  0.24\n",
      "probs:  4.30,  label:  4.33,  diff: -0.04\n",
      "probs:  0.20,  label:  0.57,  diff: -0.37\n",
      "probs:  3.87,  label:  3.29,  diff:  0.58\n",
      "probs:  1.01,  label:  1.20,  diff: -0.19\n",
      "probs:  1.84,  label:  0.83,  diff:  1.01\n",
      "probs:  0.12,  label:  0.00,  diff:  0.12\n",
      "probs:  4.01,  label:  4.43,  diff: -0.42\n",
      "probs:  3.84,  label:  4.14,  diff: -0.30\n",
      "probs:  0.23,  label:  0.40,  diff: -0.17\n",
      "probs:  0.11,  label:  0.00,  diff:  0.11\n",
      "probs:  4.46,  label:  4.33,  diff:  0.13\n",
      "probs:  3.66,  label:  1.43,  diff:  2.23\n",
      "probs:  0.33,  label:  0.14,  diff:  0.18\n",
      "probs:  0.84,  label:  0.29,  diff:  0.55\n",
      "probs:  4.35,  label:  3.83,  diff:  0.52\n",
      "probs:  4.54,  label:  4.20,  diff:  0.34\n",
      "probs:  4.18,  label:  3.33,  diff:  0.84\n",
      "probs:  4.49,  label:  4.60,  diff: -0.11\n",
      "probs:  4.10,  label:  3.60,  diff:  0.50\n",
      "probs:  3.79,  label:  2.71,  diff:  1.08\n",
      "probs: -0.04,  label:  0.29,  diff: -0.32\n",
      "probs:  4.20,  label:  3.50,  diff:  0.70\n",
      "probs:  4.23,  label:  3.83,  diff:  0.40\n",
      "probs:  4.33,  label:  4.67,  diff: -0.34\n",
      "probs:  4.40,  label:  4.57,  diff: -0.17\n",
      "probs:  4.08,  label:  4.00,  diff:  0.08\n",
      "probs:  3.33,  label:  2.40,  diff:  0.93\n",
      "probs:  4.15,  label:  4.14,  diff:  0.01\n",
      "probs:  3.56,  label:  3.50,  diff:  0.06\n",
      "probs:  3.69,  label:  3.33,  diff:  0.35\n",
      "probs: -0.09,  label:  0.00,  diff: -0.09\n",
      "probs:  4.44,  label:  4.83,  diff: -0.40\n",
      "probs:  0.21,  label:  0.00,  diff:  0.21\n",
      "probs:  3.66,  label:  3.57,  diff:  0.09\n",
      "probs:  0.82,  label:  0.86,  diff: -0.04\n",
      "probs:  0.33,  label:  0.50,  diff: -0.17\n",
      "probs:  2.39,  label:  1.17,  diff:  1.22\n",
      "probs:  0.51,  label:  0.71,  diff: -0.20\n",
      "probs:  4.14,  label:  3.00,  diff:  1.14\n",
      "probs:  4.28,  label:  3.86,  diff:  0.42\n",
      "probs:  3.94,  label:  3.57,  diff:  0.37\n",
      "probs:  4.14,  label:  3.50,  diff:  0.64\n",
      "probs:  4.05,  label:  4.33,  diff: -0.28\n",
      "probs:  4.47,  label:  4.50,  diff: -0.03\n",
      "probs:  4.06,  label:  3.50,  diff:  0.56\n",
      "probs:  4.03,  label:  4.00,  diff:  0.03\n",
      "probs:  3.44,  label:  2.83,  diff:  0.61\n",
      "probs:  2.87,  label:  2.83,  diff:  0.03\n",
      "probs:  3.51,  label:  3.00,  diff:  0.51\n",
      "probs:  3.99,  label:  3.83,  diff:  0.16\n",
      "probs:  3.99,  label:  4.14,  diff: -0.15\n",
      "probs:  4.28,  label:  4.40,  diff: -0.12\n",
      "probs:  4.05,  label:  4.14,  diff: -0.09\n",
      "probs:  3.43,  label:  2.57,  diff:  0.86\n",
      "probs:  3.83,  label:  4.17,  diff: -0.34\n",
      "probs:  2.30,  label:  2.20,  diff:  0.10\n",
      "probs:  0.05,  label:  0.00,  diff:  0.05\n",
      "probs:  1.39,  label:  2.00,  diff: -0.61\n",
      "probs:  4.52,  label:  4.50,  diff:  0.02\n",
      "probs:  3.92,  label:  3.67,  diff:  0.25\n",
      "probs: -0.06,  label:  0.00,  diff: -0.06\n",
      "probs:  0.36,  label:  0.00,  diff:  0.36\n",
      "probs:  4.42,  label:  4.60,  diff: -0.18\n",
      "probs:  1.72,  label:  2.00,  diff: -0.28\n",
      "probs:  4.11,  label:  3.67,  diff:  0.44\n",
      "probs:  4.08,  label:  3.80,  diff:  0.28\n",
      "probs:  3.95,  label:  3.83,  diff:  0.11\n",
      "probs: -0.01,  label:  0.00,  diff: -0.01\n",
      "probs:  0.40,  label:  0.00,  diff:  0.40\n",
      "probs:  0.03,  label:  0.00,  diff:  0.03\n",
      "probs: -0.01,  label:  0.00,  diff: -0.01\n",
      "probs:  3.74,  label:  3.86,  diff: -0.12\n",
      "probs:  0.06,  label:  0.00,  diff:  0.06\n",
      "probs: -0.01,  label:  0.00,  diff: -0.01\n",
      "probs:  4.05,  label:  4.00,  diff:  0.05\n",
      "probs:  4.25,  label:  4.33,  diff: -0.09\n",
      "probs:  4.19,  label:  4.29,  diff: -0.09\n",
      "probs:  1.93,  label:  1.67,  diff:  0.27\n",
      "probs:  3.57,  label:  4.14,  diff: -0.58\n",
      "probs: -0.03,  label:  0.00,  diff: -0.03\n",
      "probs:  4.18,  label:  4.00,  diff:  0.18\n",
      "probs:  0.33,  label:  0.17,  diff:  0.17\n",
      "probs:  4.15,  label:  4.17,  diff: -0.02\n",
      "probs:  3.87,  label:  3.67,  diff:  0.20\n",
      "probs:  4.23,  label:  4.33,  diff: -0.10\n",
      "probs:  4.34,  label:  4.43,  diff: -0.09\n",
      "probs:  0.14,  label:  0.00,  diff:  0.14\n",
      "probs:  4.18,  label:  3.67,  diff:  0.52\n",
      "probs:  4.01,  label:  4.20,  diff: -0.19\n",
      "probs:  4.37,  label:  4.57,  diff: -0.20\n",
      "probs:  2.20,  label:  3.33,  diff: -1.14\n",
      "probs:  0.36,  label:  0.33,  diff:  0.02\n",
      "probs:  1.46,  label:  1.43,  diff:  0.03\n",
      "probs:  4.20,  label:  3.86,  diff:  0.35\n",
      "probs:  0.07,  label:  0.00,  diff:  0.07\n",
      "probs:  2.76,  label:  3.00,  diff: -0.24\n",
      "probs:  0.12,  label:  0.00,  diff:  0.12\n",
      "probs:  3.78,  label:  3.00,  diff:  0.78\n",
      "probs:  3.79,  label:  3.33,  diff:  0.45\n",
      "probs:  0.52,  label:  0.40,  diff:  0.12\n",
      "probs:  0.03,  label:  0.00,  diff:  0.03\n",
      "probs:  1.59,  label:  3.00,  diff: -1.41\n",
      "probs: -0.08,  label:  0.00,  diff: -0.08\n",
      "probs:  4.02,  label:  2.33,  diff:  1.69\n",
      "probs:  2.93,  label:  3.33,  diff: -0.40\n",
      "probs:  3.74,  label:  3.33,  diff:  0.40\n",
      "probs:  4.08,  label:  4.20,  diff: -0.12\n",
      "probs:  4.30,  label:  4.50,  diff: -0.20\n",
      "probs:  4.26,  label:  4.50,  diff: -0.24\n",
      "probs:  3.78,  label:  4.00,  diff: -0.22\n",
      "probs:  0.34,  label:  2.17,  diff: -1.83\n",
      "probs:  1.38,  label:  1.14,  diff:  0.23\n",
      "probs:  0.43,  label:  0.83,  diff: -0.40\n",
      "probs:  4.01,  label:  3.57,  diff:  0.44\n",
      "probs:  4.28,  label:  4.00,  diff:  0.28\n",
      "probs:  4.10,  label:  3.00,  diff:  1.10\n",
      "probs:  4.10,  label:  3.83,  diff:  0.27\n",
      "probs:  3.14,  label:  2.43,  diff:  0.71\n",
      "probs:  1.20,  label:  0.71,  diff:  0.49\n",
      "probs:  0.07,  label:  0.33,  diff: -0.26\n",
      "probs:  4.33,  label:  4.83,  diff: -0.50\n",
      "probs:  4.33,  label:  4.67,  diff: -0.34\n",
      "probs:  4.04,  label:  4.00,  diff:  0.04\n",
      "probs:  3.28,  label:  2.71,  diff:  0.56\n",
      "probs:  3.81,  label:  3.17,  diff:  0.64\n",
      "probs:  3.13,  label:  3.83,  diff: -0.70\n",
      "probs:  4.19,  label:  3.60,  diff:  0.59\n",
      "probs:  3.43,  label:  3.17,  diff:  0.27\n",
      "probs: -0.02,  label:  0.00,  diff: -0.02\n",
      "probs:  2.51,  label:  1.20,  diff:  1.31\n",
      "probs:  0.05,  label:  0.00,  diff:  0.05\n",
      "probs:  4.22,  label:  4.00,  diff:  0.22\n",
      "probs:  3.97,  label:  3.67,  diff:  0.31\n",
      "probs: -0.15,  label:  0.00,  diff: -0.15\n",
      "probs:  4.31,  label:  4.14,  diff:  0.17\n",
      "probs:  4.12,  label:  3.33,  diff:  0.79\n",
      "probs:  3.81,  label:  3.86,  diff: -0.05\n",
      "probs:  4.11,  label:  3.86,  diff:  0.25\n",
      "probs:  4.43,  label:  3.67,  diff:  0.77\n",
      "probs:  4.21,  label:  4.33,  diff: -0.12\n",
      "probs:  4.29,  label:  3.86,  diff:  0.43\n",
      "probs:  3.93,  label:  3.17,  diff:  0.77\n",
      "probs: -0.06,  label:  0.00,  diff: -0.06\n",
      "probs:  2.85,  label:  2.20,  diff:  0.65\n",
      "probs:  4.52,  label:  4.57,  diff: -0.05\n",
      "probs:  0.03,  label:  0.17,  diff: -0.14\n",
      "probs:  4.15,  label:  3.83,  diff:  0.32\n",
      "probs:  4.19,  label:  4.29,  diff: -0.10\n",
      "probs:  4.19,  label:  4.00,  diff:  0.19\n",
      "probs:  1.77,  label:  2.33,  diff: -0.57\n",
      "probs:  4.24,  label:  3.60,  diff:  0.64\n",
      "probs:  0.00,  label:  0.00,  diff:  0.00\n",
      "probs:  4.05,  label:  4.00,  diff:  0.05\n",
      "probs:  3.50,  label:  3.17,  diff:  0.33\n",
      "probs:  3.00,  label:  1.67,  diff:  1.33\n",
      "probs:  4.38,  label:  4.43,  diff: -0.05\n",
      "probs:  4.20,  label:  3.67,  diff:  0.53\n",
      "probs:  4.28,  label:  4.29,  diff: -0.00\n",
      "probs:  0.18,  label:  0.00,  diff:  0.18\n",
      "probs:  3.45,  label:  3.33,  diff:  0.11\n",
      "probs:  3.92,  label:  3.50,  diff:  0.42\n",
      "probs:  0.13,  label:  0.00,  diff:  0.13\n",
      "probs:  4.20,  label:  4.33,  diff: -0.13\n",
      "probs:  4.19,  label:  4.00,  diff:  0.19\n",
      "probs:  4.37,  label:  4.00,  diff:  0.37\n",
      "probs:  1.75,  label:  2.33,  diff: -0.59\n",
      "probs:  3.74,  label:  3.43,  diff:  0.31\n",
      "probs:  4.35,  label:  4.29,  diff:  0.07\n",
      "probs:  4.12,  label:  3.86,  diff:  0.26\n",
      "probs:  3.39,  label:  2.83,  diff:  0.56\n",
      "probs:  3.66,  label:  3.00,  diff:  0.66\n",
      "probs:  4.37,  label:  4.43,  diff: -0.06\n",
      "probs:  0.21,  label:  0.14,  diff:  0.07\n",
      "probs:  3.78,  label:  4.43,  diff: -0.64\n",
      "probs:  4.33,  label:  4.17,  diff:  0.16\n",
      "probs: -0.03,  label:  0.00,  diff: -0.03\n",
      "probs:  0.17,  label:  0.00,  diff:  0.17\n",
      "probs:  3.63,  label:  2.83,  diff:  0.80\n",
      "probs:  4.01,  label:  3.86,  diff:  0.15\n",
      "probs:  4.27,  label:  4.17,  diff:  0.11\n",
      "probs: -0.03,  label:  0.00,  diff: -0.03\n",
      "probs:  0.09,  label:  0.33,  diff: -0.24\n",
      "probs:  4.07,  label:  3.83,  diff:  0.24\n",
      "probs:  4.00,  label:  3.57,  diff:  0.43\n",
      "probs:  3.81,  label:  4.00,  diff: -0.19\n",
      "probs:  4.02,  label:  2.71,  diff:  1.31\n",
      "probs:  0.35,  label:  0.17,  diff:  0.18\n",
      "probs:  4.19,  label:  4.17,  diff:  0.03\n",
      "probs: -0.07,  label:  0.00,  diff: -0.07\n",
      "probs:  4.16,  label:  4.14,  diff:  0.02\n",
      "probs:  0.43,  label:  0.00,  diff:  0.43\n",
      "probs:  4.16,  label:  4.43,  diff: -0.27\n",
      "probs:  0.41,  label:  1.57,  diff: -1.17\n",
      "probs:  3.72,  label:  3.86,  diff: -0.13\n",
      "probs:  4.03,  label:  3.60,  diff:  0.43\n",
      "probs:  4.39,  label:  4.17,  diff:  0.23\n",
      "probs:  3.60,  label:  3.33,  diff:  0.27\n",
      "probs:  0.73,  label:  0.67,  diff:  0.06\n",
      "probs:  0.11,  label:  0.57,  diff: -0.46\n",
      "probs:  0.65,  label:  0.50,  diff:  0.15\n",
      "probs:  0.01,  label:  0.00,  diff:  0.01\n",
      "probs:  3.82,  label:  2.67,  diff:  1.15\n",
      "probs:  4.33,  label:  4.33,  diff: -0.00\n",
      "probs:  4.27,  label:  4.00,  diff:  0.27\n",
      "probs:  4.23,  label:  3.50,  diff:  0.73\n",
      "probs:  4.19,  label:  4.17,  diff:  0.02\n",
      "probs: -0.07,  label:  0.00,  diff: -0.07\n",
      "probs:  0.33,  label:  0.57,  diff: -0.24\n",
      "probs:  3.90,  label:  4.67,  diff: -0.77\n",
      "probs:  3.98,  label:  3.17,  diff:  0.82\n",
      "probs:  4.06,  label:  4.14,  diff: -0.09\n",
      "probs:  3.14,  label:  3.57,  diff: -0.43\n",
      "probs:  3.19,  label:  4.17,  diff: -0.97\n",
      "probs:  0.04,  label:  0.00,  diff:  0.04\n",
      "probs:  0.81,  label:  0.33,  diff:  0.47\n",
      "probs:  3.57,  label:  4.17,  diff: -0.60\n",
      "probs:  3.85,  label:  4.00,  diff: -0.15\n",
      "probs:  1.52,  label:  1.00,  diff:  0.52\n",
      "probs:  0.00,  label:  0.00,  diff:  0.00\n",
      "probs:  3.90,  label:  4.20,  diff: -0.30\n",
      "probs:  3.15,  label:  4.00,  diff: -0.85\n",
      "probs:  2.11,  label:  3.60,  diff: -1.49\n",
      "probs:  4.35,  label:  4.14,  diff:  0.21\n",
      "probs:  0.71,  label:  0.67,  diff:  0.04\n",
      "probs:  2.34,  label:  2.67,  diff: -0.33\n",
      "probs:  3.42,  label:  3.29,  diff:  0.13\n",
      "probs:  4.09,  label:  4.33,  diff: -0.24\n",
      "probs:  4.36,  label:  3.67,  diff:  0.69\n",
      "probs:  4.46,  label:  4.00,  diff:  0.46\n",
      "probs:  0.05,  label:  0.00,  diff:  0.05\n",
      "probs:  0.02,  label:  0.14,  diff: -0.13\n",
      "probs:  0.14,  label:  0.00,  diff:  0.14\n",
      "probs:  4.33,  label:  4.29,  diff:  0.05\n",
      "probs:  0.19,  label:  0.00,  diff:  0.19\n",
      "probs:  4.14,  label:  4.20,  diff: -0.06\n",
      "probs:  0.35,  label:  0.29,  diff:  0.07\n",
      "probs:  3.59,  label:  2.29,  diff:  1.30\n",
      "probs:  0.15,  label:  0.17,  diff: -0.01\n",
      "probs:  0.23,  label:  0.83,  diff: -0.60\n",
      "probs:  3.82,  label:  2.67,  diff:  1.16\n",
      "probs:  0.01,  label:  0.00,  diff:  0.01\n",
      "probs:  1.94,  label:  0.71,  diff:  1.23\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(probs)):\n",
    "    print(f\"probs: {probs[i][0]:5.2f},  label: {labels[i]:5.2f},  diff: {(probs[i] - labels[i])[0]:5.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "6dbc3106",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "e6f24019",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.23966944"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_squared_error(probs.flatten(), labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afbd094f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "7fd32261",
   "metadata": {},
   "outputs": [],
   "source": [
    "s1 = tokenizer_krbert_sub([['코딩 못하는 개발자도 취직 가능할까요?ㅠㅠ', '포도빛 향기에 취해만 가는데']],\n",
    "                            truncation = True,\n",
    "                            padding = \"longest\",\n",
    "                            max_length=128,\n",
    "                            return_tensors = \"pt\")\n",
    "\n",
    "s2 = tokenizer_krbert_sub([['가스비가 너무 많이 나왔어요.', '가스비가 왜 이렇게 많이 나왔어!']],\n",
    "                            truncation = True,\n",
    "                            padding = \"longest\",\n",
    "                            max_length=128,\n",
    "                            return_tensors = \"pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "df99cef8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': tensor([[   2, 5453, 3213, 1000,  549, 1623, 1844,    5,    3, 5453, 3213, 1464,\n",
       "         1559,  549, 1623, 2875, 1218,    3]], device='cuda:0'), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1]],\n",
       "       device='cuda:0'), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]],\n",
       "       device='cuda:0')}"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s1.to(device)\n",
    "s2.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "d5970a09",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.1058]], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    print(model(**s1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "8c82e7aa",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[4.0434]], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    print(model(**s2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f13b2877",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11ff3a0b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
